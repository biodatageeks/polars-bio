{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"polars-bio","text":""},{"location":"#next-gen-python-dataframe-operations-for-genomics","title":"Next-gen Python DataFrame operations for genomics!","text":"<p>polars-bio is a blazing fast Python DataFrame library for genomics\ud83e\uddec  built on top of Apache DataFusion, Apache Arrow and  polars. It is designed to be easy to use, fast and memory efficient with a focus on genomics data.</p> <p></p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>optimized for performance and memory efficiency for large-scale genomics datasets analyses both when reading input data and performing operations</li> <li>popular genomics operations with a DataFrame API (both Pandas and polars)</li> <li>SQL-powered bioinformatic data querying or manipulation/pre-processing</li> <li>native parallel engine powered by Apache DataFusion and sequila-native</li> <li>out-of-core/streaming processing (for data too large to fit into a computer's main memory)  with Apache DataFusion and polars</li> <li>support for federated and streamed reading data from cloud storages (e.g. S3, GCS) with Apache OpenDAL  enabling processing large-scale genomics data without materializing in memory</li> <li>zero-copy data exchange with Apache Arrow</li> <li>bioinformatics file formats with noodles</li> <li>fast overlap operations with COITrees: Cache Oblivious Interval Trees</li> <li>pre-built wheel packages for Linux, Windows and MacOS (arm64 and x86_64) available on PyPI</li> </ul>"},{"location":"#performance-benchmarks","title":"Performance benchmarks","text":"<p>See quick start for the installation options.</p>"},{"location":"#citing","title":"Citing","text":"<p>If you use polars-bio in your work, please cite:</p> <pre><code>@article {Wiewiorka2025.03.21.644629,\n    author = {Wiewiorka, Marek and Khamutou, Pavel and Zbysinski, Marek and Gambin, Tomasz},\n    title = {polars-bio - fast, scalable and out-of-core operations on large genomic interval datasets},\n    elocation-id = {2025.03.21.644629},\n    year = {2025},\n    doi = {10.1101/2025.03.21.644629},\n    publisher = {Cold Spring Harbor Laboratory},\n    URL = {https://www.biorxiv.org/content/early/2025/03/25/2025.03.21.644629},\n    eprint = {https://www.biorxiv.org/content/early/2025/03/25/2025.03.21.644629.full.pdf},\n    journal = {bioRxiv}\n}\n</code></pre>"},{"location":"#performance-benchmarks_1","title":"Performance benchmarks","text":""},{"location":"#single-thread","title":"Single-thread \ud83c\udfc3\u200d","text":""},{"location":"#parallel","title":"Parallel \ud83c\udfc3\u200d\ud83c\udfc3\u200d","text":""},{"location":"api/","title":"\u2699\ufe0f API reference","text":"<p>polars-bio API is grouped into the following categories:</p> <ul> <li>File I/O: Reading files in various biological formats from local and cloud storage.</li> <li>Data Processing: Exposing end user to the rich SQL programming interface powered by Apache Datafusion for operations, such as sorting, filtering and other transformations on input bioinformatic datasets registered as tables. You can easily query and process file formats such as VCF, GFF, BAM, FASTQ using SQL syntax.</li> <li>Interval Operations: Functions for performing common interval operations, such as overlap, nearest, coverage.</li> </ul> <p>There are 2 ways of using polars-bio API:</p> <ul> <li>using <code>polars_bio</code> module</li> </ul> <p>Example</p> <pre><code>import polars_bio as pb\npb.read_fastq(\"gs://genomics-public-data/platinum-genomes/fastq/ERR194146.fastq.gz\").limit(1).collect()\n</code></pre> <ul> <li>directly on a Polars LazyFrame under a registered <code>pb</code> namespace</li> </ul> <p>Example</p> <p></p><pre><code> &gt;&gt;&gt; type(df)\n &lt;class 'polars.lazyframe.frame.LazyFrame'&gt;\n</code></pre> <pre><code>   import polars_bio as pb\n   df.pb.sort().limit(5).collect()\n</code></pre><p></p> <p>Tip</p> <ol> <li>Not all are available in both ways.</li> <li>You can of course use both ways in the same script.</li> </ol>"},{"location":"api/#polars_bio.data_input","title":"<code>data_input</code>","text":"Source code in <code>polars_bio/io.py</code> <pre><code>class IOOperations:\n    @staticmethod\n    def read_fasta(\n        path: str,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n\n        Read a FASTA file into a DataFrame.\n\n        Parameters:\n            path: The path to the FASTA file.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the FASTA file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n            projection_pushdown: Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.\n\n        !!! Example\n            ```shell\n            wget https://www.ebi.ac.uk/ena/browser/api/fasta/BK006935.2?download=true -O /tmp/test.fasta\n            ```\n\n            ```python\n            import polars_bio as pb\n            pb.read_fasta(\"/tmp/test.fasta\").limit(1)\n            ```\n            ```shell\n             shape: (1, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 name                    \u2506 description                     \u2506 sequence                        \u2502\n            \u2502 ---                     \u2506 ---                             \u2506 ---                             \u2502\n            \u2502 str                     \u2506 str                             \u2506 str                             \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 ENA|BK006935|BK006935.2 \u2506 TPA_inf: Saccharomyces cerevis\u2026 \u2506 CCACACCACACCCACACACCCACACACCAC\u2026 \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n        \"\"\"\n        return IOOperations.scan_fasta(\n            path,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            compression_type,\n            projection_pushdown,\n        ).collect()\n\n    @staticmethod\n    def scan_fasta(\n        path: str,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n\n        Lazily read a FASTA file into a LazyFrame.\n\n        Parameters:\n            path: The path to the FASTA file.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the FASTA file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! Example\n            ```shell\n            wget https://www.ebi.ac.uk/ena/browser/api/fasta/BK006935.2?download=true -O /tmp/test.fasta\n            ```\n\n            ```python\n            import polars_bio as pb\n            pb.scan_fasta(\"/tmp/test.fasta\").limit(1).collect()\n            ```\n            ```shell\n             shape: (1, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 name                    \u2506 description                     \u2506 sequence                        \u2502\n            \u2502 ---                     \u2506 ---                             \u2506 ---                             \u2502\n            \u2502 str                     \u2506 str                             \u2506 str                             \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 ENA|BK006935|BK006935.2 \u2506 TPA_inf: Saccharomyces cerevis\u2026 \u2506 CCACACCACACCCACACACCCACACACCAC\u2026 \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n        fasta_read_options = FastaReadOptions(\n            object_storage_options=object_storage_options\n        )\n        read_options = ReadOptions(fasta_read_options=fasta_read_options)\n        return _read_file(path, InputFormat.Fasta, read_options, projection_pushdown)\n\n    @staticmethod\n    def read_vcf(\n        path: str,\n        info_fields: Union[list[str], None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Read a VCF file into a DataFrame.\n\n        Parameters:\n            path: The path to the VCF file.\n            info_fields: List of INFO field names to include. If *None*, all INFO fields will be detected automatically from the VCF header. Use this to limit fields for better performance.\n            thread_num: The number of threads to use for reading the VCF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! note\n            VCF reader uses **1-based** coordinate system for the `start` and `end` columns.\n        \"\"\"\n        return IOOperations.scan_vcf(\n            path,\n            info_fields,\n            thread_num,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            compression_type,\n            projection_pushdown,\n        ).collect()\n\n    @staticmethod\n    def scan_vcf(\n        path: str,\n        info_fields: Union[list[str], None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n        Lazily read a VCF file into a LazyFrame.\n\n        Parameters:\n            path: The path to the VCF file.\n            info_fields: List of INFO field names to include. If *None*, all INFO fields will be detected automatically from the VCF header. Use this to limit fields for better performance.\n            thread_num: The number of threads to use for reading the VCF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! note\n            VCF reader uses **1-based** coordinate system for the `start` and `end` columns.\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        # Use provided info_fields or autodetect from VCF header\n        if info_fields is not None:\n            initial_info_fields = info_fields\n        else:\n            # Get all info fields from VCF header for proper projection pushdown\n            all_info_fields = None\n            try:\n                vcf_schema_df = IOOperations.describe_vcf(\n                    path,\n                    allow_anonymous=allow_anonymous,\n                    enable_request_payer=enable_request_payer,\n                    compression_type=compression_type,\n                )\n                # Use column name 'name' not 'id' based on the schema output\n                all_info_fields = vcf_schema_df.select(\"name\").to_series().to_list()\n            except Exception:\n                # Fallback to None if unable to get info fields\n                all_info_fields = None\n\n            # Always start with all info fields to establish full schema\n            # The callback will re-register with only requested info fields for optimization\n            initial_info_fields = all_info_fields\n\n        vcf_read_options = VcfReadOptions(\n            info_fields=initial_info_fields,\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(vcf_read_options=vcf_read_options)\n        return _read_file(path, InputFormat.Vcf, read_options, projection_pushdown)\n\n    @staticmethod\n    def read_gff(\n        path: str,\n        attr_fields: Union[list[str], None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n        predicate_pushdown: bool = False,\n        parallel: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Read a GFF file into a DataFrame.\n\n        Parameters:\n            path: The path to the GFF file.\n            attr_fields: List of attribute field names to extract as separate columns. If *None*, attributes will be kept as a nested structure. Use this to extract specific attributes like 'ID', 'gene_name', 'gene_type', etc. as direct columns for easier access.\n            thread_num: The number of threads to use for reading the GFF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the GFF file. If not specified, it will be detected automatically..\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n            predicate_pushdown: Enable predicate pushdown optimization to push filter conditions down to the DataFusion table provider level, reducing data processing and I/O.\n            parallel: Whether to use the parallel reader for BGZF-compressed local files (uses BGZF chunk-level parallelism similar to FASTQ).\n\n        !!! note\n            GFF reader uses **1-based** coordinate system for the `start` and `end` columns.\n        \"\"\"\n        return IOOperations.scan_gff(\n            path,\n            attr_fields,\n            thread_num,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            compression_type,\n            projection_pushdown,\n            predicate_pushdown,\n            parallel,\n        ).collect()\n\n    @staticmethod\n    def scan_gff(\n        path: str,\n        attr_fields: Union[list[str], None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n        predicate_pushdown: bool = False,\n        parallel: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n        Lazily read a GFF file into a LazyFrame.\n\n        Parameters:\n            path: The path to the GFF file.\n            attr_fields: List of attribute field names to extract as separate columns. If *None*, attributes will be kept as a nested structure. Use this to extract specific attributes like 'ID', 'gene_name', 'gene_type', etc. as direct columns for easier access.\n            thread_num: The number of threads to use for reading the GFF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large-scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the GFF file. If not specified, it will be detected automatically.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n            predicate_pushdown: Enable predicate pushdown optimization to push filter conditions down to the DataFusion table provider level, reducing data processing and I/O.\n            parallel: Whether to use the parallel reader for BGZF-compressed local files (use BGZF chunk-level parallelism similar to FASTQ).\n\n        !!! note\n            GFF reader uses **1-based** coordinate system for the `start` and `end` columns.\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        gff_read_options = GffReadOptions(\n            attr_fields=attr_fields,\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n            parallel=parallel,\n        )\n        read_options = ReadOptions(gff_read_options=gff_read_options)\n        return _read_file(\n            path, InputFormat.Gff, read_options, projection_pushdown, predicate_pushdown\n        )\n\n    @staticmethod\n    def read_bam(\n        path: str,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        projection_pushdown: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Read a BAM file into a DataFrame.\n\n        Parameters:\n            path: The path to the BAM file.\n            thread_num: The number of threads to use for reading the BAM file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large-scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large-scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! note\n            BAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n        \"\"\"\n        return IOOperations.scan_bam(\n            path,\n            thread_num,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            projection_pushdown,\n        ).collect()\n\n    @staticmethod\n    def scan_bam(\n        path: str,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        projection_pushdown: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n        Lazily read a BAM file into a LazyFrame.\n\n        Parameters:\n            path: The path to the BAM file.\n            thread_num: The number of threads to use for reading the BAM file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! note\n            BAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=\"auto\",\n        )\n\n        bam_read_options = BamReadOptions(\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(bam_read_options=bam_read_options)\n        return _read_file(path, InputFormat.Bam, read_options, projection_pushdown)\n\n    @staticmethod\n    def read_cram(\n        path: str,\n        reference_path: str = None,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        projection_pushdown: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Read a CRAM file into a DataFrame.\n\n        Parameters:\n            path: The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).\n            reference_path: Optional path to external FASTA reference file (**local path only**, cloud storage not supported). If not provided, the CRAM file must contain embedded reference sequences. The FASTA file must have an accompanying index file (.fai) in the same directory. Create the index using: `samtools faidx reference.fasta`\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries: The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            projection_pushdown: Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.\n\n        !!! note\n            CRAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n        !!! example \"Using External Reference\"\n            ```python\n            import polars_bio as pb\n\n            # Read CRAM with external reference\n            df = pb.read_cram(\n                \"/path/to/file.cram\",\n                reference_path=\"/path/to/reference.fasta\"\n            )\n            ```\n\n        !!! example \"Public CRAM File Example\"\n            Download and read a public CRAM file from 42basepairs:\n            ```bash\n            # Download the CRAM file and reference\n            wget https://42basepairs.com/download/s3/gatk-test-data/wgs_cram/NA12878_20k_hg38/NA12878.cram\n            wget https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\n\n            # Create FASTA index (required)\n            samtools faidx Homo_sapiens_assembly38.fasta\n            ```\n\n            ```python\n            import polars_bio as pb\n\n            # Read first 5 reads from the CRAM file\n            df = pb.scan_cram(\n                \"NA12878.cram\",\n                reference_path=\"Homo_sapiens_assembly38.fasta\"\n            ).limit(5).collect()\n\n            print(df.select([\"name\", \"chrom\", \"start\", \"end\", \"cigar\"]))\n            ```\n\n        !!! example \"Creating CRAM with Embedded Reference\"\n            To create a CRAM file with embedded reference using samtools:\n            ```bash\n            samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n            ```\n\n        Returns:\n            A Polars DataFrame with the following schema:\n                - name: Read name (String)\n                - chrom: Chromosome/contig name (String)\n                - start: Alignment start position, 1-based (UInt32)\n                - end: Alignment end position, 1-based (UInt32)\n                - flags: SAM flags (UInt32)\n                - cigar: CIGAR string (String)\n                - mapping_quality: Mapping quality (UInt32)\n                - mate_chrom: Mate chromosome/contig name (String)\n                - mate_start: Mate alignment start position, 1-based (UInt32)\n                - sequence: Read sequence (String)\n                - quality_scores: Base quality scores (String)\n        \"\"\"\n        return IOOperations.scan_cram(\n            path,\n            reference_path,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            projection_pushdown,\n        ).collect()\n\n    @staticmethod\n    def scan_cram(\n        path: str,\n        reference_path: str = None,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        projection_pushdown: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n        Lazily read a CRAM file into a LazyFrame.\n\n        Parameters:\n            path: The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).\n            reference_path: Optional path to external FASTA reference file (**local path only**, cloud storage not supported). If not provided, the CRAM file must contain embedded reference sequences. The FASTA file must have an accompanying index file (.fai) in the same directory. Create the index using: `samtools faidx reference.fasta`\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries: The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            projection_pushdown: Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.\n\n        !!! note\n            CRAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n        !!! example \"Using External Reference\"\n            ```python\n            import polars_bio as pb\n\n            # Lazy scan CRAM with external reference\n            lf = pb.scan_cram(\n                \"/path/to/file.cram\",\n                reference_path=\"/path/to/reference.fasta\"\n            )\n\n            # Apply transformations and collect\n            df = lf.filter(pl.col(\"chrom\") == \"chr1\").collect()\n            ```\n\n        !!! example \"Public CRAM File Example\"\n            Download and read a public CRAM file from 42basepairs:\n            ```bash\n            # Download the CRAM file and reference\n            wget https://42basepairs.com/download/s3/gatk-test-data/wgs_cram/NA12878_20k_hg38/NA12878.cram\n            wget https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\n\n            # Create FASTA index (required)\n            samtools faidx Homo_sapiens_assembly38.fasta\n            ```\n\n            ```python\n            import polars_bio as pb\n            import polars as pl\n\n            # Lazy scan and filter for chromosome 20 reads\n            df = pb.scan_cram(\n                \"NA12878.cram\",\n                reference_path=\"Homo_sapiens_assembly38.fasta\"\n            ).filter(\n                pl.col(\"chrom\") == \"chr20\"\n            ).select(\n                [\"name\", \"chrom\", \"start\", \"end\", \"mapping_quality\"]\n            ).limit(10).collect()\n\n            print(df)\n            ```\n\n        !!! example \"Creating CRAM with Embedded Reference\"\n            To create a CRAM file with embedded reference using samtools:\n            ```bash\n            samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n            ```\n\n        Returns:\n            A Polars LazyFrame with the following schema:\n                - name: Read name (String)\n                - chrom: Chromosome/contig name (String)\n                - start: Alignment start position, 1-based (UInt32)\n                - end: Alignment end position, 1-based (UInt32)\n                - flags: SAM flags (UInt32)\n                - cigar: CIGAR string (String)\n                - mapping_quality: Mapping quality (UInt32)\n                - mate_chrom: Mate chromosome/contig name (String)\n                - mate_start: Mate alignment start position, 1-based (UInt32)\n                - sequence: Read sequence (String)\n                - quality_scores: Base quality scores (String)\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=\"auto\",\n        )\n\n        cram_read_options = CramReadOptions(\n            reference_path=reference_path,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(cram_read_options=cram_read_options)\n        return _read_file(path, InputFormat.Cram, read_options, projection_pushdown)\n\n    @staticmethod\n    def read_fastq(\n        path: str,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        parallel: bool = False,\n        projection_pushdown: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Read a FASTQ file into a DataFrame.\n\n        Parameters:\n            path: The path to the FASTQ file.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n            parallel: Whether to use the parallel reader for BGZF compressed files stored **locally**. GZI index is **required**.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n        \"\"\"\n        return IOOperations.scan_fastq(\n            path,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            compression_type,\n            parallel,\n            projection_pushdown,\n        ).collect()\n\n    @staticmethod\n    def scan_fastq(\n        path: str,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        parallel: bool = False,\n        projection_pushdown: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n        Lazily read a FASTQ file into a LazyFrame.\n\n        Parameters:\n            path: The path to the FASTQ file.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n            parallel: Whether to use the parallel reader for BGZF compressed files stored **locally**. GZI index is **required**.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        fastq_read_options = FastqReadOptions(\n            object_storage_options=object_storage_options, parallel=parallel\n        )\n        read_options = ReadOptions(fastq_read_options=fastq_read_options)\n        return _read_file(path, InputFormat.Fastq, read_options, projection_pushdown)\n\n    @staticmethod\n    def read_bed(\n        path: str,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Read a BED file into a DataFrame.\n\n        Parameters:\n            path: The path to the BED file.\n            thread_num: The number of threads to use for reading the BED file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the BED file. If not specified, it will be detected automatically based on the file extension. BGZF compressions is supported ('bgz').\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! Note\n            Only **BED4** format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name.\n            Also unlike other text formats, **GZIP** compression is not supported.\n\n        !!! note\n            BED reader uses **1-based** coordinate system for the `start`, `end`.\n        \"\"\"\n        return IOOperations.scan_bed(\n            path,\n            thread_num,\n            chunk_size,\n            concurrent_fetches,\n            allow_anonymous,\n            enable_request_payer,\n            max_retries,\n            timeout,\n            compression_type,\n            projection_pushdown,\n        ).collect()\n\n    @staticmethod\n    def scan_bed(\n        path: str,\n        thread_num: int = 1,\n        chunk_size: int = 8,\n        concurrent_fetches: int = 1,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        max_retries: int = 5,\n        timeout: int = 300,\n        compression_type: str = \"auto\",\n        projection_pushdown: bool = False,\n    ) -&gt; pl.LazyFrame:\n        \"\"\"\n        Lazily read a BED file into a LazyFrame.\n\n        Parameters:\n            path: The path to the BED file.\n            thread_num: The number of threads to use for reading the BED file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            compression_type: The compression type of the BED file. If not specified, it will be detected automatically based on the file extension. BGZF compressions is supported ('bgz').\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        !!! Note\n            Only **BED4** format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name.\n            Also unlike other text formats, **GZIP** compression is not supported.\n\n        !!! note\n            BED reader uses **1-based** coordinate system for the `start`, `end`.\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        bed_read_options = BedReadOptions(\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(bed_read_options=bed_read_options)\n        return _read_file(path, InputFormat.Bed, read_options, projection_pushdown)\n\n    @staticmethod\n    def read_table(path: str, schema: Dict = None, **kwargs) -&gt; pl.DataFrame:\n        \"\"\"\n         Read a tab-delimited (i.e. BED) file into a Polars DataFrame.\n         Tries to be compatible with Bioframe's [read_table](https://bioframe.readthedocs.io/en/latest/guide-io.html)\n         but faster. Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n\n        Parameters:\n            path: The path to the file.\n            schema: Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n        \"\"\"\n        return IOOperations.scan_table(path, schema, **kwargs).collect()\n\n    @staticmethod\n    def scan_table(path: str, schema: Dict = None, **kwargs) -&gt; pl.LazyFrame:\n        \"\"\"\n         Lazily read a tab-delimited (i.e. BED) file into a Polars LazyFrame.\n         Tries to be compatible with Bioframe's [read_table](https://bioframe.readthedocs.io/en/latest/guide-io.html)\n         but faster and lazy. Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n\n        Parameters:\n            path: The path to the file.\n            schema: Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n        \"\"\"\n        df = pl.scan_csv(path, separator=\"\\t\", has_header=False, **kwargs)\n        if schema is not None:\n            columns = SCHEMAS[schema]\n            if len(columns) != len(df.collect_schema()):\n                raise ValueError(\n                    f\"Schema incompatible with the input. Expected {len(columns)} columns in a schema, got {len(df.collect_schema())} in the input data file. Please provide a valid schema.\"\n                )\n            for i, c in enumerate(columns):\n                df = df.rename({f\"column_{i+1}\": c})\n        return df\n\n    @staticmethod\n    def describe_vcf(\n        path: str,\n        allow_anonymous: bool = True,\n        enable_request_payer: bool = False,\n        compression_type: str = \"auto\",\n    ) -&gt; pl.DataFrame:\n        \"\"\"\n        Describe VCF INFO schema.\n\n        Parameters:\n            path: The path to the VCF file.\n            allow_anonymous: Whether to allow anonymous access to object storage (GCS and S3 supported).\n            enable_request_payer: Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n        \"\"\"\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=8,\n            concurrent_fetches=1,\n            max_retries=1,\n            timeout=10,\n            compression_type=compression_type,\n        )\n        return py_describe_vcf(ctx, path, object_storage_options).to_polars()\n\n    @staticmethod\n    def from_polars(name: str, df: Union[pl.DataFrame, pl.LazyFrame]) -&gt; None:\n        \"\"\"\n        Register a Polars DataFrame as a DataFusion table.\n\n        Parameters:\n            name: The name of the table.\n            df: The Polars DataFrame.\n        \"\"\"\n        reader = (\n            df.to_arrow()\n            if isinstance(df, pl.DataFrame)\n            else df.collect().to_arrow().to_reader()\n        )\n        py_from_polars(ctx, name, reader)\n</code></pre>"},{"location":"api/#polars_bio.data_input.describe_vcf","title":"<code>describe_vcf(path, allow_anonymous=True, enable_request_payer=False, compression_type='auto')</code>  <code>staticmethod</code>","text":"<p>Describe VCF INFO schema.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the VCF file.</p> required <code>allow_anonymous</code> <code>bool</code> <p>Whether to allow anonymous access to object storage (GCS and S3 supported).</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>compression_type</code> <code>str</code> <p>The compression type of the VCF file. If not specified, it will be detected automatically..</p> <code>'auto'</code> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef describe_vcf(\n    path: str,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    compression_type: str = \"auto\",\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Describe VCF INFO schema.\n\n    Parameters:\n        path: The path to the VCF file.\n        allow_anonymous: Whether to allow anonymous access to object storage (GCS and S3 supported).\n        enable_request_payer: Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=8,\n        concurrent_fetches=1,\n        max_retries=1,\n        timeout=10,\n        compression_type=compression_type,\n    )\n    return py_describe_vcf(ctx, path, object_storage_options).to_polars()\n</code></pre>"},{"location":"api/#polars_bio.data_input.from_polars","title":"<code>from_polars(name, df)</code>  <code>staticmethod</code>","text":"<p>Register a Polars DataFrame as a DataFusion table.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the table.</p> required <code>df</code> <code>Union[DataFrame, LazyFrame]</code> <p>The Polars DataFrame.</p> required Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef from_polars(name: str, df: Union[pl.DataFrame, pl.LazyFrame]) -&gt; None:\n    \"\"\"\n    Register a Polars DataFrame as a DataFusion table.\n\n    Parameters:\n        name: The name of the table.\n        df: The Polars DataFrame.\n    \"\"\"\n    reader = (\n        df.to_arrow()\n        if isinstance(df, pl.DataFrame)\n        else df.collect().to_arrow().to_reader()\n    )\n    py_from_polars(ctx, name, reader)\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_bam","title":"<code>read_bam(path, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Read a BAM file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the BAM file.</p> required <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the BAM file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large-scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large-scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Note</p> <p>BAM reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>, <code>mate_start</code>, <code>mate_end</code> columns.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_bam(\n    path: str,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    projection_pushdown: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Read a BAM file into a DataFrame.\n\n    Parameters:\n        path: The path to the BAM file.\n        thread_num: The number of threads to use for reading the BAM file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large-scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large-scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! note\n        BAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n    \"\"\"\n    return IOOperations.scan_bam(\n        path,\n        thread_num,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        projection_pushdown,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_bed","title":"<code>read_bed(path, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Read a BED file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the BED file.</p> required <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the BED file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the BED file. If not specified, it will be detected automatically based on the file extension. BGZF compressions is supported ('bgz').</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Note</p> <p>Only BED4 format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name. Also unlike other text formats, GZIP compression is not supported.</p> <p>Note</p> <p>BED reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_bed(\n    path: str,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Read a BED file into a DataFrame.\n\n    Parameters:\n        path: The path to the BED file.\n        thread_num: The number of threads to use for reading the BED file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the BED file. If not specified, it will be detected automatically based on the file extension. BGZF compressions is supported ('bgz').\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! Note\n        Only **BED4** format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name.\n        Also unlike other text formats, **GZIP** compression is not supported.\n\n    !!! note\n        BED reader uses **1-based** coordinate system for the `start`, `end`.\n    \"\"\"\n    return IOOperations.scan_bed(\n        path,\n        thread_num,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        compression_type,\n        projection_pushdown,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_cram","title":"<code>read_cram(path, reference_path=None, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Read a CRAM file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).</p> required <code>reference_path</code> <code>str</code> <p>Optional path to external FASTA reference file (local path only, cloud storage not supported). If not provided, the CRAM file must contain embedded reference sequences. The FASTA file must have an accompanying index file (.fai) in the same directory. Create the index using: <code>samtools faidx reference.fasta</code></p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.</p> <code>False</code> <p>Note</p> <p>CRAM reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>, <code>mate_start</code>, <code>mate_end</code> columns.</p> <p>Using External Reference</p> <pre><code>import polars_bio as pb\n\n# Read CRAM with external reference\ndf = pb.read_cram(\n    \"/path/to/file.cram\",\n    reference_path=\"/path/to/reference.fasta\"\n)\n</code></pre> <p>Public CRAM File Example</p> <p>Download and read a public CRAM file from 42basepairs: </p><pre><code># Download the CRAM file and reference\nwget https://42basepairs.com/download/s3/gatk-test-data/wgs_cram/NA12878_20k_hg38/NA12878.cram\nwget https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\n\n# Create FASTA index (required)\nsamtools faidx Homo_sapiens_assembly38.fasta\n</code></pre><p></p> <pre><code>import polars_bio as pb\n\n# Read first 5 reads from the CRAM file\ndf = pb.scan_cram(\n    \"NA12878.cram\",\n    reference_path=\"Homo_sapiens_assembly38.fasta\"\n).limit(5).collect()\n\nprint(df.select([\"name\", \"chrom\", \"start\", \"end\", \"cigar\"]))\n</code></pre> <p>Creating CRAM with Embedded Reference</p> <p>To create a CRAM file with embedded reference using samtools: </p><pre><code>samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n</code></pre><p></p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A Polars DataFrame with the following schema: - name: Read name (String) - chrom: Chromosome/contig name (String) - start: Alignment start position, 1-based (UInt32) - end: Alignment end position, 1-based (UInt32) - flags: SAM flags (UInt32) - cigar: CIGAR string (String) - mapping_quality: Mapping quality (UInt32) - mate_chrom: Mate chromosome/contig name (String) - mate_start: Mate alignment start position, 1-based (UInt32) - sequence: Read sequence (String) - quality_scores: Base quality scores (String)</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_cram(\n    path: str,\n    reference_path: str = None,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    projection_pushdown: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Read a CRAM file into a DataFrame.\n\n    Parameters:\n        path: The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).\n        reference_path: Optional path to external FASTA reference file (**local path only**, cloud storage not supported). If not provided, the CRAM file must contain embedded reference sequences. The FASTA file must have an accompanying index file (.fai) in the same directory. Create the index using: `samtools faidx reference.fasta`\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries: The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        projection_pushdown: Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.\n\n    !!! note\n        CRAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n    !!! example \"Using External Reference\"\n        ```python\n        import polars_bio as pb\n\n        # Read CRAM with external reference\n        df = pb.read_cram(\n            \"/path/to/file.cram\",\n            reference_path=\"/path/to/reference.fasta\"\n        )\n        ```\n\n    !!! example \"Public CRAM File Example\"\n        Download and read a public CRAM file from 42basepairs:\n        ```bash\n        # Download the CRAM file and reference\n        wget https://42basepairs.com/download/s3/gatk-test-data/wgs_cram/NA12878_20k_hg38/NA12878.cram\n        wget https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\n\n        # Create FASTA index (required)\n        samtools faidx Homo_sapiens_assembly38.fasta\n        ```\n\n        ```python\n        import polars_bio as pb\n\n        # Read first 5 reads from the CRAM file\n        df = pb.scan_cram(\n            \"NA12878.cram\",\n            reference_path=\"Homo_sapiens_assembly38.fasta\"\n        ).limit(5).collect()\n\n        print(df.select([\"name\", \"chrom\", \"start\", \"end\", \"cigar\"]))\n        ```\n\n    !!! example \"Creating CRAM with Embedded Reference\"\n        To create a CRAM file with embedded reference using samtools:\n        ```bash\n        samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n        ```\n\n    Returns:\n        A Polars DataFrame with the following schema:\n            - name: Read name (String)\n            - chrom: Chromosome/contig name (String)\n            - start: Alignment start position, 1-based (UInt32)\n            - end: Alignment end position, 1-based (UInt32)\n            - flags: SAM flags (UInt32)\n            - cigar: CIGAR string (String)\n            - mapping_quality: Mapping quality (UInt32)\n            - mate_chrom: Mate chromosome/contig name (String)\n            - mate_start: Mate alignment start position, 1-based (UInt32)\n            - sequence: Read sequence (String)\n            - quality_scores: Base quality scores (String)\n    \"\"\"\n    return IOOperations.scan_cram(\n        path,\n        reference_path,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        projection_pushdown,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_fasta","title":"<code>read_fasta(path, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Read a FASTA file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the FASTA file.</p> required <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the FASTA file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.</p> <code>False</code> <p>Example</p> <pre><code>wget https://www.ebi.ac.uk/ena/browser/api/fasta/BK006935.2?download=true -O /tmp/test.fasta\n</code></pre> <p></p><pre><code>import polars_bio as pb\npb.read_fasta(\"/tmp/test.fasta\").limit(1)\n</code></pre> <pre><code> shape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                    \u2506 description                     \u2506 sequence                        \u2502\n\u2502 ---                     \u2506 ---                             \u2506 ---                             \u2502\n\u2502 str                     \u2506 str                             \u2506 str                             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 ENA|BK006935|BK006935.2 \u2506 TPA_inf: Saccharomyces cerevis\u2026 \u2506 CCACACCACACCCACACACCCACACACCAC\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre><p></p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_fasta(\n    path: str,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n\n    Read a FASTA file into a DataFrame.\n\n    Parameters:\n        path: The path to the FASTA file.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the FASTA file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n        projection_pushdown: Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.\n\n    !!! Example\n        ```shell\n        wget https://www.ebi.ac.uk/ena/browser/api/fasta/BK006935.2?download=true -O /tmp/test.fasta\n        ```\n\n        ```python\n        import polars_bio as pb\n        pb.read_fasta(\"/tmp/test.fasta\").limit(1)\n        ```\n        ```shell\n         shape: (1, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 name                    \u2506 description                     \u2506 sequence                        \u2502\n        \u2502 ---                     \u2506 ---                             \u2506 ---                             \u2502\n        \u2502 str                     \u2506 str                             \u2506 str                             \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 ENA|BK006935|BK006935.2 \u2506 TPA_inf: Saccharomyces cerevis\u2026 \u2506 CCACACCACACCCACACACCCACACACCAC\u2026 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n    \"\"\"\n    return IOOperations.scan_fasta(\n        path,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        compression_type,\n        projection_pushdown,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_fastq","title":"<code>read_fastq(path, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', parallel=False, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Read a FASTQ file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the FASTQ file.</p> required <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').</p> <code>'auto'</code> <code>parallel</code> <code>bool</code> <p>Whether to use the parallel reader for BGZF compressed files stored locally. GZI index is required.</p> <code>False</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_fastq(\n    path: str,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    parallel: bool = False,\n    projection_pushdown: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Read a FASTQ file into a DataFrame.\n\n    Parameters:\n        path: The path to the FASTQ file.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n        parallel: Whether to use the parallel reader for BGZF compressed files stored **locally**. GZI index is **required**.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n    \"\"\"\n    return IOOperations.scan_fastq(\n        path,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        compression_type,\n        parallel,\n        projection_pushdown,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_gff","title":"<code>read_gff(path, attr_fields=None, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False, predicate_pushdown=False, parallel=False)</code>  <code>staticmethod</code>","text":"<p>Read a GFF file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the GFF file.</p> required <code>attr_fields</code> <code>Union[list[str], None]</code> <p>List of attribute field names to extract as separate columns. If None, attributes will be kept as a nested structure. Use this to extract specific attributes like 'ID', 'gene_name', 'gene_type', etc. as direct columns for easier access.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the GFF file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the GFF file. If not specified, it will be detected automatically..</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <code>predicate_pushdown</code> <code>bool</code> <p>Enable predicate pushdown optimization to push filter conditions down to the DataFusion table provider level, reducing data processing and I/O.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to use the parallel reader for BGZF-compressed local files (uses BGZF chunk-level parallelism similar to FASTQ).</p> <code>False</code> <p>Note</p> <p>GFF reader uses 1-based coordinate system for the <code>start</code> and <code>end</code> columns.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_gff(\n    path: str,\n    attr_fields: Union[list[str], None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n    predicate_pushdown: bool = False,\n    parallel: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Read a GFF file into a DataFrame.\n\n    Parameters:\n        path: The path to the GFF file.\n        attr_fields: List of attribute field names to extract as separate columns. If *None*, attributes will be kept as a nested structure. Use this to extract specific attributes like 'ID', 'gene_name', 'gene_type', etc. as direct columns for easier access.\n        thread_num: The number of threads to use for reading the GFF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the GFF file. If not specified, it will be detected automatically..\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n        predicate_pushdown: Enable predicate pushdown optimization to push filter conditions down to the DataFusion table provider level, reducing data processing and I/O.\n        parallel: Whether to use the parallel reader for BGZF-compressed local files (uses BGZF chunk-level parallelism similar to FASTQ).\n\n    !!! note\n        GFF reader uses **1-based** coordinate system for the `start` and `end` columns.\n    \"\"\"\n    return IOOperations.scan_gff(\n        path,\n        attr_fields,\n        thread_num,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        compression_type,\n        projection_pushdown,\n        predicate_pushdown,\n        parallel,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_table","title":"<code>read_table(path, schema=None, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Read a tab-delimited (i.e. BED) file into a Polars DataFrame.  Tries to be compatible with Bioframe's read_table  but faster. Schema should follow the Bioframe's schema format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the file.</p> required <code>schema</code> <code>Dict</code> <p>Schema should follow the Bioframe's schema format.</p> <code>None</code> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_table(path: str, schema: Dict = None, **kwargs) -&gt; pl.DataFrame:\n    \"\"\"\n     Read a tab-delimited (i.e. BED) file into a Polars DataFrame.\n     Tries to be compatible with Bioframe's [read_table](https://bioframe.readthedocs.io/en/latest/guide-io.html)\n     but faster. Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n\n    Parameters:\n        path: The path to the file.\n        schema: Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n    \"\"\"\n    return IOOperations.scan_table(path, schema, **kwargs).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.read_vcf","title":"<code>read_vcf(path, info_fields=None, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Read a VCF file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the VCF file.</p> required <code>info_fields</code> <code>Union[list[str], None]</code> <p>List of INFO field names to include. If None, all INFO fields will be detected automatically from the VCF header. Use this to limit fields for better performance.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the VCF file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the VCF file. If not specified, it will be detected automatically..</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Note</p> <p>VCF reader uses 1-based coordinate system for the <code>start</code> and <code>end</code> columns.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef read_vcf(\n    path: str,\n    info_fields: Union[list[str], None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Read a VCF file into a DataFrame.\n\n    Parameters:\n        path: The path to the VCF file.\n        info_fields: List of INFO field names to include. If *None*, all INFO fields will be detected automatically from the VCF header. Use this to limit fields for better performance.\n        thread_num: The number of threads to use for reading the VCF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! note\n        VCF reader uses **1-based** coordinate system for the `start` and `end` columns.\n    \"\"\"\n    return IOOperations.scan_vcf(\n        path,\n        info_fields,\n        thread_num,\n        chunk_size,\n        concurrent_fetches,\n        allow_anonymous,\n        enable_request_payer,\n        max_retries,\n        timeout,\n        compression_type,\n        projection_pushdown,\n    ).collect()\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_bam","title":"<code>scan_bam(path, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a BAM file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the BAM file.</p> required <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the BAM file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Note</p> <p>BAM reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>, <code>mate_start</code>, <code>mate_end</code> columns.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_bam(\n    path: str,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    projection_pushdown: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Lazily read a BAM file into a LazyFrame.\n\n    Parameters:\n        path: The path to the BAM file.\n        thread_num: The number of threads to use for reading the BAM file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! note\n        BAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=\"auto\",\n    )\n\n    bam_read_options = BamReadOptions(\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(bam_read_options=bam_read_options)\n    return _read_file(path, InputFormat.Bam, read_options, projection_pushdown)\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_bed","title":"<code>scan_bed(path, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a BED file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the BED file.</p> required <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the BED file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the BED file. If not specified, it will be detected automatically based on the file extension. BGZF compressions is supported ('bgz').</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Note</p> <p>Only BED4 format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name. Also unlike other text formats, GZIP compression is not supported.</p> <p>Note</p> <p>BED reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_bed(\n    path: str,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Lazily read a BED file into a LazyFrame.\n\n    Parameters:\n        path: The path to the BED file.\n        thread_num: The number of threads to use for reading the BED file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the BED file. If not specified, it will be detected automatically based on the file extension. BGZF compressions is supported ('bgz').\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! Note\n        Only **BED4** format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name.\n        Also unlike other text formats, **GZIP** compression is not supported.\n\n    !!! note\n        BED reader uses **1-based** coordinate system for the `start`, `end`.\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    bed_read_options = BedReadOptions(\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(bed_read_options=bed_read_options)\n    return _read_file(path, InputFormat.Bed, read_options, projection_pushdown)\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_cram","title":"<code>scan_cram(path, reference_path=None, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a CRAM file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).</p> required <code>reference_path</code> <code>str</code> <p>Optional path to external FASTA reference file (local path only, cloud storage not supported). If not provided, the CRAM file must contain embedded reference sequences. The FASTA file must have an accompanying index file (.fai) in the same directory. Create the index using: <code>samtools faidx reference.fasta</code></p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.</p> <code>False</code> <p>Note</p> <p>CRAM reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>, <code>mate_start</code>, <code>mate_end</code> columns.</p> <p>Using External Reference</p> <pre><code>import polars_bio as pb\n\n# Lazy scan CRAM with external reference\nlf = pb.scan_cram(\n    \"/path/to/file.cram\",\n    reference_path=\"/path/to/reference.fasta\"\n)\n\n# Apply transformations and collect\ndf = lf.filter(pl.col(\"chrom\") == \"chr1\").collect()\n</code></pre> <p>Public CRAM File Example</p> <p>Download and read a public CRAM file from 42basepairs: </p><pre><code># Download the CRAM file and reference\nwget https://42basepairs.com/download/s3/gatk-test-data/wgs_cram/NA12878_20k_hg38/NA12878.cram\nwget https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\n\n# Create FASTA index (required)\nsamtools faidx Homo_sapiens_assembly38.fasta\n</code></pre><p></p> <pre><code>import polars_bio as pb\nimport polars as pl\n\n# Lazy scan and filter for chromosome 20 reads\ndf = pb.scan_cram(\n    \"NA12878.cram\",\n    reference_path=\"Homo_sapiens_assembly38.fasta\"\n).filter(\n    pl.col(\"chrom\") == \"chr20\"\n).select(\n    [\"name\", \"chrom\", \"start\", \"end\", \"mapping_quality\"]\n).limit(10).collect()\n\nprint(df)\n</code></pre> <p>Creating CRAM with Embedded Reference</p> <p>To create a CRAM file with embedded reference using samtools: </p><pre><code>samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n</code></pre><p></p> <p>Returns:</p> Type Description <code>LazyFrame</code> <p>A Polars LazyFrame with the following schema: - name: Read name (String) - chrom: Chromosome/contig name (String) - start: Alignment start position, 1-based (UInt32) - end: Alignment end position, 1-based (UInt32) - flags: SAM flags (UInt32) - cigar: CIGAR string (String) - mapping_quality: Mapping quality (UInt32) - mate_chrom: Mate chromosome/contig name (String) - mate_start: Mate alignment start position, 1-based (UInt32) - sequence: Read sequence (String) - quality_scores: Base quality scores (String)</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_cram(\n    path: str,\n    reference_path: str = None,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    projection_pushdown: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Lazily read a CRAM file into a LazyFrame.\n\n    Parameters:\n        path: The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).\n        reference_path: Optional path to external FASTA reference file (**local path only**, cloud storage not supported). If not provided, the CRAM file must contain embedded reference sequences. The FASTA file must have an accompanying index file (.fai) in the same directory. Create the index using: `samtools faidx reference.fasta`\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries: The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        projection_pushdown: Enable column projection pushdown optimization. When True, only requested columns are processed at the DataFusion execution level, improving performance and reducing memory usage.\n\n    !!! note\n        CRAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n    !!! example \"Using External Reference\"\n        ```python\n        import polars_bio as pb\n\n        # Lazy scan CRAM with external reference\n        lf = pb.scan_cram(\n            \"/path/to/file.cram\",\n            reference_path=\"/path/to/reference.fasta\"\n        )\n\n        # Apply transformations and collect\n        df = lf.filter(pl.col(\"chrom\") == \"chr1\").collect()\n        ```\n\n    !!! example \"Public CRAM File Example\"\n        Download and read a public CRAM file from 42basepairs:\n        ```bash\n        # Download the CRAM file and reference\n        wget https://42basepairs.com/download/s3/gatk-test-data/wgs_cram/NA12878_20k_hg38/NA12878.cram\n        wget https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\n\n        # Create FASTA index (required)\n        samtools faidx Homo_sapiens_assembly38.fasta\n        ```\n\n        ```python\n        import polars_bio as pb\n        import polars as pl\n\n        # Lazy scan and filter for chromosome 20 reads\n        df = pb.scan_cram(\n            \"NA12878.cram\",\n            reference_path=\"Homo_sapiens_assembly38.fasta\"\n        ).filter(\n            pl.col(\"chrom\") == \"chr20\"\n        ).select(\n            [\"name\", \"chrom\", \"start\", \"end\", \"mapping_quality\"]\n        ).limit(10).collect()\n\n        print(df)\n        ```\n\n    !!! example \"Creating CRAM with Embedded Reference\"\n        To create a CRAM file with embedded reference using samtools:\n        ```bash\n        samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n        ```\n\n    Returns:\n        A Polars LazyFrame with the following schema:\n            - name: Read name (String)\n            - chrom: Chromosome/contig name (String)\n            - start: Alignment start position, 1-based (UInt32)\n            - end: Alignment end position, 1-based (UInt32)\n            - flags: SAM flags (UInt32)\n            - cigar: CIGAR string (String)\n            - mapping_quality: Mapping quality (UInt32)\n            - mate_chrom: Mate chromosome/contig name (String)\n            - mate_start: Mate alignment start position, 1-based (UInt32)\n            - sequence: Read sequence (String)\n            - quality_scores: Base quality scores (String)\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=\"auto\",\n    )\n\n    cram_read_options = CramReadOptions(\n        reference_path=reference_path,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(cram_read_options=cram_read_options)\n    return _read_file(path, InputFormat.Cram, read_options, projection_pushdown)\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_fasta","title":"<code>scan_fasta(path, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a FASTA file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the FASTA file.</p> required <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the FASTA file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Example</p> <pre><code>wget https://www.ebi.ac.uk/ena/browser/api/fasta/BK006935.2?download=true -O /tmp/test.fasta\n</code></pre> <p></p><pre><code>import polars_bio as pb\npb.scan_fasta(\"/tmp/test.fasta\").limit(1).collect()\n</code></pre> <pre><code> shape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                    \u2506 description                     \u2506 sequence                        \u2502\n\u2502 ---                     \u2506 ---                             \u2506 ---                             \u2502\n\u2502 str                     \u2506 str                             \u2506 str                             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 ENA|BK006935|BK006935.2 \u2506 TPA_inf: Saccharomyces cerevis\u2026 \u2506 CCACACCACACCCACACACCCACACACCAC\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre><p></p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_fasta(\n    path: str,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n\n    Lazily read a FASTA file into a LazyFrame.\n\n    Parameters:\n        path: The path to the FASTA file.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the FASTA file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! Example\n        ```shell\n        wget https://www.ebi.ac.uk/ena/browser/api/fasta/BK006935.2?download=true -O /tmp/test.fasta\n        ```\n\n        ```python\n        import polars_bio as pb\n        pb.scan_fasta(\"/tmp/test.fasta\").limit(1).collect()\n        ```\n        ```shell\n         shape: (1, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 name                    \u2506 description                     \u2506 sequence                        \u2502\n        \u2502 ---                     \u2506 ---                             \u2506 ---                             \u2502\n        \u2502 str                     \u2506 str                             \u2506 str                             \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 ENA|BK006935|BK006935.2 \u2506 TPA_inf: Saccharomyces cerevis\u2026 \u2506 CCACACCACACCCACACACCCACACACCAC\u2026 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n    fasta_read_options = FastaReadOptions(\n        object_storage_options=object_storage_options\n    )\n    read_options = ReadOptions(fasta_read_options=fasta_read_options)\n    return _read_file(path, InputFormat.Fasta, read_options, projection_pushdown)\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_fastq","title":"<code>scan_fastq(path, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', parallel=False, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a FASTQ file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the FASTQ file.</p> required <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').</p> <code>'auto'</code> <code>parallel</code> <code>bool</code> <p>Whether to use the parallel reader for BGZF compressed files stored locally. GZI index is required.</p> <code>False</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_fastq(\n    path: str,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    parallel: bool = False,\n    projection_pushdown: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Lazily read a FASTQ file into a LazyFrame.\n\n    Parameters:\n        path: The path to the FASTQ file.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compressions are supported ('bgz', 'gz').\n        parallel: Whether to use the parallel reader for BGZF compressed files stored **locally**. GZI index is **required**.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    fastq_read_options = FastqReadOptions(\n        object_storage_options=object_storage_options, parallel=parallel\n    )\n    read_options = ReadOptions(fastq_read_options=fastq_read_options)\n    return _read_file(path, InputFormat.Fastq, read_options, projection_pushdown)\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_gff","title":"<code>scan_gff(path, attr_fields=None, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False, predicate_pushdown=False, parallel=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a GFF file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the GFF file.</p> required <code>attr_fields</code> <code>Union[list[str], None]</code> <p>List of attribute field names to extract as separate columns. If None, attributes will be kept as a nested structure. Use this to extract specific attributes like 'ID', 'gene_name', 'gene_type', etc. as direct columns for easier access.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the GFF file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large-scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the GFF file. If not specified, it will be detected automatically.</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <code>predicate_pushdown</code> <code>bool</code> <p>Enable predicate pushdown optimization to push filter conditions down to the DataFusion table provider level, reducing data processing and I/O.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to use the parallel reader for BGZF-compressed local files (use BGZF chunk-level parallelism similar to FASTQ).</p> <code>False</code> <p>Note</p> <p>GFF reader uses 1-based coordinate system for the <code>start</code> and <code>end</code> columns.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_gff(\n    path: str,\n    attr_fields: Union[list[str], None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n    predicate_pushdown: bool = False,\n    parallel: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Lazily read a GFF file into a LazyFrame.\n\n    Parameters:\n        path: The path to the GFF file.\n        attr_fields: List of attribute field names to extract as separate columns. If *None*, attributes will be kept as a nested structure. Use this to extract specific attributes like 'ID', 'gene_name', 'gene_type', etc. as direct columns for easier access.\n        thread_num: The number of threads to use for reading the GFF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large-scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the GFF file. If not specified, it will be detected automatically.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n        predicate_pushdown: Enable predicate pushdown optimization to push filter conditions down to the DataFusion table provider level, reducing data processing and I/O.\n        parallel: Whether to use the parallel reader for BGZF-compressed local files (use BGZF chunk-level parallelism similar to FASTQ).\n\n    !!! note\n        GFF reader uses **1-based** coordinate system for the `start` and `end` columns.\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    gff_read_options = GffReadOptions(\n        attr_fields=attr_fields,\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n        parallel=parallel,\n    )\n    read_options = ReadOptions(gff_read_options=gff_read_options)\n    return _read_file(\n        path, InputFormat.Gff, read_options, projection_pushdown, predicate_pushdown\n    )\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_table","title":"<code>scan_table(path, schema=None, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Lazily read a tab-delimited (i.e. BED) file into a Polars LazyFrame.  Tries to be compatible with Bioframe's read_table  but faster and lazy. Schema should follow the Bioframe's schema format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the file.</p> required <code>schema</code> <code>Dict</code> <p>Schema should follow the Bioframe's schema format.</p> <code>None</code> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_table(path: str, schema: Dict = None, **kwargs) -&gt; pl.LazyFrame:\n    \"\"\"\n     Lazily read a tab-delimited (i.e. BED) file into a Polars LazyFrame.\n     Tries to be compatible with Bioframe's [read_table](https://bioframe.readthedocs.io/en/latest/guide-io.html)\n     but faster and lazy. Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n\n    Parameters:\n        path: The path to the file.\n        schema: Schema should follow the Bioframe's schema [format](https://github.com/open2c/bioframe/blob/2b685eebef393c2c9e6220dcf550b3630d87518e/bioframe/io/schemas.py#L174).\n    \"\"\"\n    df = pl.scan_csv(path, separator=\"\\t\", has_header=False, **kwargs)\n    if schema is not None:\n        columns = SCHEMAS[schema]\n        if len(columns) != len(df.collect_schema()):\n            raise ValueError(\n                f\"Schema incompatible with the input. Expected {len(columns)} columns in a schema, got {len(df.collect_schema())} in the input data file. Please provide a valid schema.\"\n            )\n        for i, c in enumerate(columns):\n            df = df.rename({f\"column_{i+1}\": c})\n    return df\n</code></pre>"},{"location":"api/#polars_bio.data_input.scan_vcf","title":"<code>scan_vcf(path, info_fields=None, thread_num=1, chunk_size=8, concurrent_fetches=1, allow_anonymous=True, enable_request_payer=False, max_retries=5, timeout=300, compression_type='auto', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Lazily read a VCF file into a LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the VCF file.</p> required <code>info_fields</code> <code>Union[list[str], None]</code> <p>List of INFO field names to include. If None, all INFO fields will be detected automatically from the VCF header. Use this to limit fields for better performance.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the VCF file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.</p> <code>8</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.</p> <code>1</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>compression_type</code> <code>str</code> <p>The compression type of the VCF file. If not specified, it will be detected automatically..</p> <code>'auto'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Note</p> <p>VCF reader uses 1-based coordinate system for the <code>start</code> and <code>end</code> columns.</p> Source code in <code>polars_bio/io.py</code> <pre><code>@staticmethod\ndef scan_vcf(\n    path: str,\n    info_fields: Union[list[str], None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 8,\n    concurrent_fetches: int = 1,\n    allow_anonymous: bool = True,\n    enable_request_payer: bool = False,\n    max_retries: int = 5,\n    timeout: int = 300,\n    compression_type: str = \"auto\",\n    projection_pushdown: bool = False,\n) -&gt; pl.LazyFrame:\n    \"\"\"\n    Lazily read a VCF file into a LazyFrame.\n\n    Parameters:\n        path: The path to the VCF file.\n        info_fields: List of INFO field names to include. If *None*, all INFO fields will be detected automatically from the VCF header. Use this to limit fields for better performance.\n        thread_num: The number of threads to use for reading the VCF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. The default is 8 MB. For large scale operations, it is recommended to increase this value to 64.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. The default is 1. For large scale operations, it is recommended to increase this value to 8 or even more.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    !!! note\n        VCF reader uses **1-based** coordinate system for the `start` and `end` columns.\n    \"\"\"\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    # Use provided info_fields or autodetect from VCF header\n    if info_fields is not None:\n        initial_info_fields = info_fields\n    else:\n        # Get all info fields from VCF header for proper projection pushdown\n        all_info_fields = None\n        try:\n            vcf_schema_df = IOOperations.describe_vcf(\n                path,\n                allow_anonymous=allow_anonymous,\n                enable_request_payer=enable_request_payer,\n                compression_type=compression_type,\n            )\n            # Use column name 'name' not 'id' based on the schema output\n            all_info_fields = vcf_schema_df.select(\"name\").to_series().to_list()\n        except Exception:\n            # Fallback to None if unable to get info fields\n            all_info_fields = None\n\n        # Always start with all info fields to establish full schema\n        # The callback will re-register with only requested info fields for optimization\n        initial_info_fields = all_info_fields\n\n    vcf_read_options = VcfReadOptions(\n        info_fields=initial_info_fields,\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(vcf_read_options=vcf_read_options)\n    return _read_file(path, InputFormat.Vcf, read_options, projection_pushdown)\n</code></pre>"},{"location":"api/#polars_bio.data_processing","title":"<code>data_processing</code>","text":"Source code in <code>polars_bio/sql.py</code> <pre><code>class SQL:\n    @staticmethod\n    def register_vcf(\n        path: str,\n        name: Union[str, None] = None,\n        info_fields: Union[list[str], None] = None,\n        thread_num: Union[int, None] = None,\n        chunk_size: int = 64,\n        concurrent_fetches: int = 8,\n        allow_anonymous: bool = True,\n        max_retries: int = 5,\n        timeout: int = 300,\n        enable_request_payer: bool = False,\n        compression_type: str = \"auto\",\n    ) -&gt; None:\n        \"\"\"\n        Register a VCF file as a Datafusion table.\n\n        Parameters:\n            path: The path to the VCF file.\n            name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n            info_fields: List of INFO field names to register. If *None*, all INFO fields will be detected automatically from the VCF header. Use this to limit registration to specific fields for better performance.\n            thread_num: The number of threads to use for reading the VCF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n        !!! note\n            VCF reader uses **1-based** coordinate system for the `start` and `end` columns.\n\n        !!! Example\n              ```python\n              import polars_bio as pb\n              pb.register_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\")\n              ```\n             ```shell\n             INFO:polars_bio:Table: gnomad_v4_1_sv_sites_gz registered for path: /tmp/gnomad.v4.1.sv.sites.vcf.gz\n             ```\n        !!! tip\n            `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the VCF file. As a rule of thumb for large scale operations (reading a whole VCF), it is recommended to the default values.\n        \"\"\"\n\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        # Use provided info_fields or autodetect from VCF header\n        if info_fields is not None:\n            all_info_fields = info_fields\n        else:\n            # Get all info fields from VCF header for automatic field detection\n            all_info_fields = None\n            try:\n                from .io import IOOperations\n\n                vcf_schema_df = IOOperations.describe_vcf(\n                    path,\n                    allow_anonymous=allow_anonymous,\n                    enable_request_payer=enable_request_payer,\n                    compression_type=compression_type,\n                )\n                all_info_fields = vcf_schema_df.select(\"name\").to_series().to_list()\n            except Exception:\n                # Fallback to empty list if unable to get info fields\n                all_info_fields = []\n\n        vcf_read_options = VcfReadOptions(\n            info_fields=all_info_fields,\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(vcf_read_options=vcf_read_options)\n        py_register_table(ctx, path, name, InputFormat.Vcf, read_options)\n\n    @staticmethod\n    def register_gff(\n        path: str,\n        name: Union[str, None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 64,\n        concurrent_fetches: int = 8,\n        allow_anonymous: bool = True,\n        max_retries: int = 5,\n        timeout: int = 300,\n        enable_request_payer: bool = False,\n        compression_type: str = \"auto\",\n        parallel: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Register a GFF file as a Datafusion table.\n\n        Parameters:\n            path: The path to the GFF file.\n            name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n            thread_num: The number of threads to use for reading the GFF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            compression_type: The compression type of the GFF file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compression is supported ('bgz' and 'gz').\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            parallel: Whether to use the parallel reader for BGZF-compressed local files. Default is False.\n        !!! note\n            GFF reader uses **1-based** coordinate system for the `start` and `end` columns.\n\n        !!! Example\n            ```shell\n            wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/gencode.v38.annotation.gff3.gz -O /tmp/gencode.v38.annotation.gff3.gz\n            ```\n            ```python\n            import polars_bio as pb\n            pb.register_gff(\"/tmp/gencode.v38.annotation.gff3.gz\", \"gencode_v38_annotation3_bgz\")\n            pb.sql(\"SELECT attributes, count(*) AS cnt FROM gencode_v38_annotation3_bgz GROUP BY attributes\").limit(5).collect()\n            ```\n            ```shell\n\n            shape: (5, 2)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 Parent            \u2506 cnt   \u2502\n            \u2502 ---               \u2506 ---   \u2502\n            \u2502 str               \u2506 i64   \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 null              \u2506 60649 \u2502\n            \u2502 ENSG00000223972.5 \u2506 2     \u2502\n            \u2502 ENST00000456328.2 \u2506 3     \u2502\n            \u2502 ENST00000450305.2 \u2506 6     \u2502\n            \u2502 ENSG00000227232.5 \u2506 1     \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            ```\n        !!! tip\n            `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the GFF file. As a rule of thumb for large scale operations (reading a whole GFF), it is recommended to the default values.\n        \"\"\"\n\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        gff_read_options = GffReadOptions(\n            attr_fields=None,\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n            parallel=parallel,\n        )\n        read_options = ReadOptions(gff_read_options=gff_read_options)\n        py_register_table(ctx, path, name, InputFormat.Gff, read_options)\n\n    @staticmethod\n    def register_fastq(\n        path: str,\n        name: Union[str, None] = None,\n        chunk_size: int = 64,\n        concurrent_fetches: int = 8,\n        allow_anonymous: bool = True,\n        max_retries: int = 5,\n        timeout: int = 300,\n        enable_request_payer: bool = False,\n        compression_type: str = \"auto\",\n        parallel: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Register a FASTQ file as a Datafusion table.\n\n        Parameters:\n            path: The path to the FASTQ file.\n            name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n            chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            compression_type: The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compression is supported ('bgz' and 'gz').\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n            parallel: Whether to use the parallel reader for BGZF compressed files. Default is False. If a file ends with \".gz\" but is actually BGZF, it will attempt the parallel path and fall back to standard if not BGZF.\n\n        !!! Example\n            ```python\n              import polars_bio as pb\n              pb.register_fastq(\"gs://genomics-public-data/platinum-genomes/fastq/ERR194146.fastq.gz\", \"test_fastq\")\n              pb.sql(\"SELECT name, description FROM test_fastq WHERE name LIKE 'ERR194146%'\").limit(5).collect()\n            ```\n\n            ```shell\n\n              shape: (5, 2)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 name                \u2506 description                     \u2502\n            \u2502 ---                 \u2506 ---                             \u2502\n            \u2502 str                 \u2506 str                             \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 ERR194146.812444541 \u2506 HSQ1008:141:D0CC8ACXX:2:1204:1\u2026 \u2502\n            \u2502 ERR194146.812444542 \u2506 HSQ1008:141:D0CC8ACXX:4:1206:1\u2026 \u2502\n            \u2502 ERR194146.812444543 \u2506 HSQ1008:141:D0CC8ACXX:3:2104:5\u2026 \u2502\n            \u2502 ERR194146.812444544 \u2506 HSQ1008:141:D0CC8ACXX:3:2204:1\u2026 \u2502\n            \u2502 ERR194146.812444545 \u2506 HSQ1008:141:D0CC8ACXX:3:1304:3\u2026 \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n            ```\n\n\n        !!! tip\n            `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the FASTQ file. As a rule of thumb for large scale operations (reading a whole FASTQ), it is recommended to the default values.\n        \"\"\"\n\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        fastq_read_options = FastqReadOptions(\n            object_storage_options=object_storage_options, parallel=parallel\n        )\n        read_options = ReadOptions(fastq_read_options=fastq_read_options)\n        py_register_table(ctx, path, name, InputFormat.Fastq, read_options)\n\n    @staticmethod\n    def register_bed(\n        path: str,\n        name: Union[str, None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 64,\n        concurrent_fetches: int = 8,\n        allow_anonymous: bool = True,\n        max_retries: int = 5,\n        timeout: int = 300,\n        enable_request_payer: bool = False,\n        compression_type: str = \"auto\",\n    ) -&gt; None:\n        \"\"\"\n        Register a BED file as a Datafusion table.\n\n        Parameters:\n            path: The path to the BED file.\n            name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n            thread_num: The number of threads to use for reading the BED file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            compression_type: The compression type of the BED file. If not specified, it will be detected automatically..\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n\n        !!! Note\n            Only **BED4** format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name.\n            Also unlike other text formats, **GZIP** compression is not supported.\n\n        !!! Example\n            ```shell\n\n             cd /tmp\n             wget https://webs.iiitd.edu.in/raghava/humcfs/fragile_site_bed.zip -O fragile_site_bed.zip\n             unzip fragile_site_bed.zip -x \"__MACOSX/*\" \"*/.DS_Store\"\n            ```\n\n            ```python\n            import polars_bio as pb\n            pb.register_bed(\"/tmp/fragile_site_bed/chr5_fragile_site.bed\", \"test_bed\")\n            b.sql(\"select * FROM test_bed WHERE name LIKE 'FRA5%'\").collect()\n            ```\n\n            ```shell\n\n                shape: (8, 4)\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502 chrom \u2506 start     \u2506 end       \u2506 name  \u2502\n                \u2502 ---   \u2506 ---       \u2506 ---       \u2506 ---   \u2502\n                \u2502 str   \u2506 u32       \u2506 u32       \u2506 str   \u2502\n                \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n                \u2502 chr5  \u2506 28900001  \u2506 42500000  \u2506 FRA5A \u2502\n                \u2502 chr5  \u2506 92300001  \u2506 98200000  \u2506 FRA5B \u2502\n                \u2502 chr5  \u2506 130600001 \u2506 136200000 \u2506 FRA5C \u2502\n                \u2502 chr5  \u2506 92300001  \u2506 93916228  \u2506 FRA5D \u2502\n                \u2502 chr5  \u2506 18400001  \u2506 28900000  \u2506 FRA5E \u2502\n                \u2502 chr5  \u2506 98200001  \u2506 109600000 \u2506 FRA5F \u2502\n                \u2502 chr5  \u2506 168500001 \u2506 180915260 \u2506 FRA5G \u2502\n                \u2502 chr5  \u2506 50500001  \u2506 63000000  \u2506 FRA5H \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n\n        !!! tip\n            `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the BED file. As a rule of thumb for large scale operations (reading a whole BED), it is recommended to the default values.\n        \"\"\"\n\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=compression_type,\n        )\n\n        bed_read_options = BedReadOptions(\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(bed_read_options=bed_read_options)\n        py_register_table(ctx, path, name, InputFormat.Bed, read_options)\n\n    @staticmethod\n    def register_view(name: str, query: str) -&gt; None:\n        \"\"\"\n        Register a query as a Datafusion view. This view can be used in genomic ranges operations,\n        such as overlap, nearest, and count_overlaps. It is useful for filtering, transforming, and aggregating data\n        prior to the range operation. When combined with the range operation, it can be used to perform complex in a streaming fashion end-to-end.\n\n        Parameters:\n            name: The name of the table.\n            query: The SQL query.\n\n        !!! Example\n              ```python\n              import polars_bio as pb\n              pb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\", \"gnomad_sv\")\n              pb.register_view(\"v_gnomad_sv\", \"SELECT replace(chrom,'chr', '') AS chrom, start, end FROM gnomad_sv\")\n              pb.sql(\"SELECT * FROM v_gnomad_sv\").limit(5).collect()\n              ```\n              ```shell\n                shape: (5, 3)\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502 chrom \u2506 start   \u2506 end     \u2502\n                \u2502 ---   \u2506 ---     \u2506 ---     \u2502\n                \u2502 str   \u2506 u32     \u2506 u32     \u2502\n                \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n                \u2502 21    \u2506 5031905 \u2506 5031905 \u2502\n                \u2502 21    \u2506 5031905 \u2506 5031905 \u2502\n                \u2502 21    \u2506 5031909 \u2506 5031909 \u2502\n                \u2502 21    \u2506 5031911 \u2506 5031911 \u2502\n                \u2502 21    \u2506 5031911 \u2506 5031911 \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              ```\n        \"\"\"\n        py_register_view(ctx, name, query)\n\n    @staticmethod\n    def register_bam(\n        path: str,\n        name: Union[str, None] = None,\n        thread_num: int = 1,\n        chunk_size: int = 64,\n        concurrent_fetches: int = 8,\n        allow_anonymous: bool = True,\n        max_retries: int = 5,\n        timeout: int = 300,\n        enable_request_payer: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Register a BAM file as a Datafusion table.\n\n        Parameters:\n            path: The path to the BAM file.\n            name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n            thread_num: The number of threads to use for reading the BAM file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n            chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n        !!! note\n            BAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n        !!! Example\n\n            ```python\n            import polars_bio as pb\n            pb.register_bam(\"gs://genomics-public-data/1000-genomes/bam/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam\", \"HG00096_bam\", concurrent_fetches=1, chunk_size=8)\n            pb.sql(\"SELECT chrom, flags FROM HG00096_bam\").limit(5).collect()\n            ```\n            ```shell\n\n                shape: (5, 2)\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502 chrom \u2506 flags \u2502\n                \u2502 ---   \u2506 ---   \u2502\n                \u2502 str   \u2506 u32   \u2502\n                \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n                \u2502 chr1  \u2506 163   \u2502\n                \u2502 chr1  \u2506 163   \u2502\n                \u2502 chr1  \u2506 99    \u2502\n                \u2502 chr1  \u2506 99    \u2502\n                \u2502 chr1  \u2506 99    \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n        !!! tip\n            `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the BAM file. As a rule of thumb for large scale operations (reading a whole BAM), it is recommended keep the default values.\n            For more interactive inspecting a schema, it is recommended to decrease `chunk_size` to **8-16** and `concurrent_fetches` to **1-2**.\n        \"\"\"\n\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=\"auto\",\n        )\n\n        bam_read_options = BamReadOptions(\n            thread_num=thread_num,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(bam_read_options=bam_read_options)\n        py_register_table(ctx, path, name, InputFormat.Bam, read_options)\n\n    @staticmethod\n    def register_cram(\n        path: str,\n        name: Union[str, None] = None,\n        chunk_size: int = 64,\n        concurrent_fetches: int = 8,\n        allow_anonymous: bool = True,\n        max_retries: int = 5,\n        timeout: int = 300,\n        enable_request_payer: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Register a CRAM file as a Datafusion table.\n\n        !!! warning \"Embedded Reference Required\"\n            Currently, only CRAM files with **embedded reference sequences** are supported.\n            CRAM files requiring external reference FASTA files cannot be registered.\n            Most modern CRAM files include embedded references by default.\n\n            To create a CRAM file with embedded reference using samtools:\n            ```bash\n            samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n            ```\n\n        Parameters:\n            path: The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).\n            name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n            chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n            concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n            allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n            enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n            max_retries:  The maximum number of retries for reading the file from object storage.\n            timeout: The timeout in seconds for reading the file from object storage.\n        !!! note\n            CRAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n        !!! tip\n            `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the CRAM file. As a rule of thumb for large scale operations (reading a whole CRAM), it is recommended to keep the default values.\n            For more interactive inspecting a schema, it is recommended to decrease `chunk_size` to **8-16** and `concurrent_fetches` to **1-2**.\n        \"\"\"\n\n        object_storage_options = PyObjectStorageOptions(\n            allow_anonymous=allow_anonymous,\n            enable_request_payer=enable_request_payer,\n            chunk_size=chunk_size,\n            concurrent_fetches=concurrent_fetches,\n            max_retries=max_retries,\n            timeout=timeout,\n            compression_type=\"auto\",\n        )\n\n        cram_read_options = CramReadOptions(\n            reference_path=None,\n            object_storage_options=object_storage_options,\n        )\n        read_options = ReadOptions(cram_read_options=cram_read_options)\n        py_register_table(ctx, path, name, InputFormat.Cram, read_options)\n\n    @staticmethod\n    def sql(query: str) -&gt; pl.LazyFrame:\n        \"\"\"\n        Execute a SQL query on the registered tables.\n\n        Parameters:\n            query: The SQL query.\n\n        !!! Example\n              ```python\n              import polars_bio as pb\n              pb.register_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad_v4_1_sv\")\n              pb.sql(\"SELECT * FROM gnomad_v4_1_sv LIMIT 5\").collect()\n              ```\n        \"\"\"\n        df = py_read_sql(ctx, query)\n        return _lazy_scan(df)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_bam","title":"<code>register_bam(path, name=None, thread_num=1, chunk_size=64, concurrent_fetches=8, allow_anonymous=True, max_retries=5, timeout=300, enable_request_payer=False)</code>  <code>staticmethod</code>","text":"<p>Register a BAM file as a Datafusion table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the BAM file.</p> required <code>name</code> <code>Union[str, None]</code> <p>The name of the table. If None, the name of the table will be generated automatically based on the path.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the BAM file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 8-16.</p> <code>64</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 1-2.</p> <code>8</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <p>Note</p> <p>BAM reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>, <code>mate_start</code>, <code>mate_end</code> columns.</p> <p>Example</p> <p></p><pre><code>import polars_bio as pb\npb.register_bam(\"gs://genomics-public-data/1000-genomes/bam/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam\", \"HG00096_bam\", concurrent_fetches=1, chunk_size=8)\npb.sql(\"SELECT chrom, flags FROM HG00096_bam\").limit(5).collect()\n</code></pre> <pre><code>    shape: (5, 2)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 chrom \u2506 flags \u2502\n    \u2502 ---   \u2506 ---   \u2502\n    \u2502 str   \u2506 u32   \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 chr1  \u2506 163   \u2502\n    \u2502 chr1  \u2506 163   \u2502\n    \u2502 chr1  \u2506 99    \u2502\n    \u2502 chr1  \u2506 99    \u2502\n    \u2502 chr1  \u2506 99    \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre><p></p> <p>Tip</p> <p><code>chunk_size</code> and <code>concurrent_fetches</code> can be adjusted according to the network bandwidth and the size of the BAM file. As a rule of thumb for large scale operations (reading a whole BAM), it is recommended keep the default values. For more interactive inspecting a schema, it is recommended to decrease <code>chunk_size</code> to 8-16 and <code>concurrent_fetches</code> to 1-2.</p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_bam(\n    path: str,\n    name: Union[str, None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 64,\n    concurrent_fetches: int = 8,\n    allow_anonymous: bool = True,\n    max_retries: int = 5,\n    timeout: int = 300,\n    enable_request_payer: bool = False,\n) -&gt; None:\n    \"\"\"\n    Register a BAM file as a Datafusion table.\n\n    Parameters:\n        path: The path to the BAM file.\n        name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n        thread_num: The number of threads to use for reading the BAM file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n    !!! note\n        BAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n    !!! Example\n\n        ```python\n        import polars_bio as pb\n        pb.register_bam(\"gs://genomics-public-data/1000-genomes/bam/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam\", \"HG00096_bam\", concurrent_fetches=1, chunk_size=8)\n        pb.sql(\"SELECT chrom, flags FROM HG00096_bam\").limit(5).collect()\n        ```\n        ```shell\n\n            shape: (5, 2)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 chrom \u2506 flags \u2502\n            \u2502 ---   \u2506 ---   \u2502\n            \u2502 str   \u2506 u32   \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 chr1  \u2506 163   \u2502\n            \u2502 chr1  \u2506 163   \u2502\n            \u2502 chr1  \u2506 99    \u2502\n            \u2502 chr1  \u2506 99    \u2502\n            \u2502 chr1  \u2506 99    \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n    !!! tip\n        `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the BAM file. As a rule of thumb for large scale operations (reading a whole BAM), it is recommended keep the default values.\n        For more interactive inspecting a schema, it is recommended to decrease `chunk_size` to **8-16** and `concurrent_fetches` to **1-2**.\n    \"\"\"\n\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=\"auto\",\n    )\n\n    bam_read_options = BamReadOptions(\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(bam_read_options=bam_read_options)\n    py_register_table(ctx, path, name, InputFormat.Bam, read_options)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_bed","title":"<code>register_bed(path, name=None, thread_num=1, chunk_size=64, concurrent_fetches=8, allow_anonymous=True, max_retries=5, timeout=300, enable_request_payer=False, compression_type='auto')</code>  <code>staticmethod</code>","text":"<p>Register a BED file as a Datafusion table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the BED file.</p> required <code>name</code> <code>Union[str, None]</code> <p>The name of the table. If None, the name of the table will be generated automatically based on the path.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the BED file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 8-16.</p> <code>64</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 1-2.</p> <code>8</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>compression_type</code> <code>str</code> <p>The compression type of the BED file. If not specified, it will be detected automatically..</p> <code>'auto'</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <p>Note</p> <p>Only BED4 format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name. Also unlike other text formats, GZIP compression is not supported.</p> <p>Example</p> <pre><code> cd /tmp\n wget https://webs.iiitd.edu.in/raghava/humcfs/fragile_site_bed.zip -O fragile_site_bed.zip\n unzip fragile_site_bed.zip -x \"__MACOSX/*\" \"*/.DS_Store\"\n</code></pre> <pre><code>import polars_bio as pb\npb.register_bed(\"/tmp/fragile_site_bed/chr5_fragile_site.bed\", \"test_bed\")\nb.sql(\"select * FROM test_bed WHERE name LIKE 'FRA5%'\").collect()\n</code></pre> <pre><code>    shape: (8, 4)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 chrom \u2506 start     \u2506 end       \u2506 name  \u2502\n    \u2502 ---   \u2506 ---       \u2506 ---       \u2506 ---   \u2502\n    \u2502 str   \u2506 u32       \u2506 u32       \u2506 str   \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 chr5  \u2506 28900001  \u2506 42500000  \u2506 FRA5A \u2502\n    \u2502 chr5  \u2506 92300001  \u2506 98200000  \u2506 FRA5B \u2502\n    \u2502 chr5  \u2506 130600001 \u2506 136200000 \u2506 FRA5C \u2502\n    \u2502 chr5  \u2506 92300001  \u2506 93916228  \u2506 FRA5D \u2502\n    \u2502 chr5  \u2506 18400001  \u2506 28900000  \u2506 FRA5E \u2502\n    \u2502 chr5  \u2506 98200001  \u2506 109600000 \u2506 FRA5F \u2502\n    \u2502 chr5  \u2506 168500001 \u2506 180915260 \u2506 FRA5G \u2502\n    \u2502 chr5  \u2506 50500001  \u2506 63000000  \u2506 FRA5H \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Tip</p> <p><code>chunk_size</code> and <code>concurrent_fetches</code> can be adjusted according to the network bandwidth and the size of the BED file. As a rule of thumb for large scale operations (reading a whole BED), it is recommended to the default values.</p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_bed(\n    path: str,\n    name: Union[str, None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 64,\n    concurrent_fetches: int = 8,\n    allow_anonymous: bool = True,\n    max_retries: int = 5,\n    timeout: int = 300,\n    enable_request_payer: bool = False,\n    compression_type: str = \"auto\",\n) -&gt; None:\n    \"\"\"\n    Register a BED file as a Datafusion table.\n\n    Parameters:\n        path: The path to the BED file.\n        name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n        thread_num: The number of threads to use for reading the BED file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        compression_type: The compression type of the BED file. If not specified, it will be detected automatically..\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n\n    !!! Note\n        Only **BED4** format is supported. It extends the basic BED format (BED3) by adding a name field, resulting in four columns: chromosome, start position, end position, and name.\n        Also unlike other text formats, **GZIP** compression is not supported.\n\n    !!! Example\n        ```shell\n\n         cd /tmp\n         wget https://webs.iiitd.edu.in/raghava/humcfs/fragile_site_bed.zip -O fragile_site_bed.zip\n         unzip fragile_site_bed.zip -x \"__MACOSX/*\" \"*/.DS_Store\"\n        ```\n\n        ```python\n        import polars_bio as pb\n        pb.register_bed(\"/tmp/fragile_site_bed/chr5_fragile_site.bed\", \"test_bed\")\n        b.sql(\"select * FROM test_bed WHERE name LIKE 'FRA5%'\").collect()\n        ```\n\n        ```shell\n\n            shape: (8, 4)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 chrom \u2506 start     \u2506 end       \u2506 name  \u2502\n            \u2502 ---   \u2506 ---       \u2506 ---       \u2506 ---   \u2502\n            \u2502 str   \u2506 u32       \u2506 u32       \u2506 str   \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 chr5  \u2506 28900001  \u2506 42500000  \u2506 FRA5A \u2502\n            \u2502 chr5  \u2506 92300001  \u2506 98200000  \u2506 FRA5B \u2502\n            \u2502 chr5  \u2506 130600001 \u2506 136200000 \u2506 FRA5C \u2502\n            \u2502 chr5  \u2506 92300001  \u2506 93916228  \u2506 FRA5D \u2502\n            \u2502 chr5  \u2506 18400001  \u2506 28900000  \u2506 FRA5E \u2502\n            \u2502 chr5  \u2506 98200001  \u2506 109600000 \u2506 FRA5F \u2502\n            \u2502 chr5  \u2506 168500001 \u2506 180915260 \u2506 FRA5G \u2502\n            \u2502 chr5  \u2506 50500001  \u2506 63000000  \u2506 FRA5H \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n\n    !!! tip\n        `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the BED file. As a rule of thumb for large scale operations (reading a whole BED), it is recommended to the default values.\n    \"\"\"\n\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    bed_read_options = BedReadOptions(\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(bed_read_options=bed_read_options)\n    py_register_table(ctx, path, name, InputFormat.Bed, read_options)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_cram","title":"<code>register_cram(path, name=None, chunk_size=64, concurrent_fetches=8, allow_anonymous=True, max_retries=5, timeout=300, enable_request_payer=False)</code>  <code>staticmethod</code>","text":"<p>Register a CRAM file as a Datafusion table.</p> <p>Embedded Reference Required</p> <p>Currently, only CRAM files with embedded reference sequences are supported. CRAM files requiring external reference FASTA files cannot be registered. Most modern CRAM files include embedded references by default.</p> <p>To create a CRAM file with embedded reference using samtools: </p><pre><code>samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n</code></pre><p></p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).</p> required <code>name</code> <code>Union[str, None]</code> <p>The name of the table. If None, the name of the table will be generated automatically based on the path.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 8-16.</p> <code>64</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 1-2.</p> <code>8</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <p>Note</p> <p>CRAM reader uses 1-based coordinate system for the <code>start</code>, <code>end</code>, <code>mate_start</code>, <code>mate_end</code> columns.</p> <p>Tip</p> <p><code>chunk_size</code> and <code>concurrent_fetches</code> can be adjusted according to the network bandwidth and the size of the CRAM file. As a rule of thumb for large scale operations (reading a whole CRAM), it is recommended to keep the default values. For more interactive inspecting a schema, it is recommended to decrease <code>chunk_size</code> to 8-16 and <code>concurrent_fetches</code> to 1-2.</p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_cram(\n    path: str,\n    name: Union[str, None] = None,\n    chunk_size: int = 64,\n    concurrent_fetches: int = 8,\n    allow_anonymous: bool = True,\n    max_retries: int = 5,\n    timeout: int = 300,\n    enable_request_payer: bool = False,\n) -&gt; None:\n    \"\"\"\n    Register a CRAM file as a Datafusion table.\n\n    !!! warning \"Embedded Reference Required\"\n        Currently, only CRAM files with **embedded reference sequences** are supported.\n        CRAM files requiring external reference FASTA files cannot be registered.\n        Most modern CRAM files include embedded references by default.\n\n        To create a CRAM file with embedded reference using samtools:\n        ```bash\n        samtools view -C -o output.cram --output-fmt-option embed_ref=1 input.bam\n        ```\n\n    Parameters:\n        path: The path to the CRAM file (local or cloud storage: S3, GCS, Azure Blob).\n        name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n        chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n    !!! note\n        CRAM reader uses **1-based** coordinate system for the `start`, `end`, `mate_start`, `mate_end` columns.\n\n    !!! tip\n        `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the CRAM file. As a rule of thumb for large scale operations (reading a whole CRAM), it is recommended to keep the default values.\n        For more interactive inspecting a schema, it is recommended to decrease `chunk_size` to **8-16** and `concurrent_fetches` to **1-2**.\n    \"\"\"\n\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=\"auto\",\n    )\n\n    cram_read_options = CramReadOptions(\n        reference_path=None,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(cram_read_options=cram_read_options)\n    py_register_table(ctx, path, name, InputFormat.Cram, read_options)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_fastq","title":"<code>register_fastq(path, name=None, chunk_size=64, concurrent_fetches=8, allow_anonymous=True, max_retries=5, timeout=300, enable_request_payer=False, compression_type='auto', parallel=False)</code>  <code>staticmethod</code>","text":"<p>Register a FASTQ file as a Datafusion table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the FASTQ file.</p> required <code>name</code> <code>Union[str, None]</code> <p>The name of the table. If None, the name of the table will be generated automatically based on the path.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 8-16.</p> <code>64</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 1-2.</p> <code>8</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>compression_type</code> <code>str</code> <p>The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compression is supported ('bgz' and 'gz').</p> <code>'auto'</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>parallel</code> <code>bool</code> <p>Whether to use the parallel reader for BGZF compressed files. Default is False. If a file ends with \".gz\" but is actually BGZF, it will attempt the parallel path and fall back to standard if not BGZF.</p> <code>False</code> <p>Example</p> <pre><code>  import polars_bio as pb\n  pb.register_fastq(\"gs://genomics-public-data/platinum-genomes/fastq/ERR194146.fastq.gz\", \"test_fastq\")\n  pb.sql(\"SELECT name, description FROM test_fastq WHERE name LIKE 'ERR194146%'\").limit(5).collect()\n</code></pre> <pre><code>  shape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name                \u2506 description                     \u2502\n\u2502 ---                 \u2506 ---                             \u2502\n\u2502 str                 \u2506 str                             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 ERR194146.812444541 \u2506 HSQ1008:141:D0CC8ACXX:2:1204:1\u2026 \u2502\n\u2502 ERR194146.812444542 \u2506 HSQ1008:141:D0CC8ACXX:4:1206:1\u2026 \u2502\n\u2502 ERR194146.812444543 \u2506 HSQ1008:141:D0CC8ACXX:3:2104:5\u2026 \u2502\n\u2502 ERR194146.812444544 \u2506 HSQ1008:141:D0CC8ACXX:3:2204:1\u2026 \u2502\n\u2502 ERR194146.812444545 \u2506 HSQ1008:141:D0CC8ACXX:3:1304:3\u2026 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Tip</p> <p><code>chunk_size</code> and <code>concurrent_fetches</code> can be adjusted according to the network bandwidth and the size of the FASTQ file. As a rule of thumb for large scale operations (reading a whole FASTQ), it is recommended to the default values.</p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_fastq(\n    path: str,\n    name: Union[str, None] = None,\n    chunk_size: int = 64,\n    concurrent_fetches: int = 8,\n    allow_anonymous: bool = True,\n    max_retries: int = 5,\n    timeout: int = 300,\n    enable_request_payer: bool = False,\n    compression_type: str = \"auto\",\n    parallel: bool = False,\n) -&gt; None:\n    \"\"\"\n    Register a FASTQ file as a Datafusion table.\n\n    Parameters:\n        path: The path to the FASTQ file.\n        name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n        chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        compression_type: The compression type of the FASTQ file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compression is supported ('bgz' and 'gz').\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        parallel: Whether to use the parallel reader for BGZF compressed files. Default is False. If a file ends with \".gz\" but is actually BGZF, it will attempt the parallel path and fall back to standard if not BGZF.\n\n    !!! Example\n        ```python\n          import polars_bio as pb\n          pb.register_fastq(\"gs://genomics-public-data/platinum-genomes/fastq/ERR194146.fastq.gz\", \"test_fastq\")\n          pb.sql(\"SELECT name, description FROM test_fastq WHERE name LIKE 'ERR194146%'\").limit(5).collect()\n        ```\n\n        ```shell\n\n          shape: (5, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 name                \u2506 description                     \u2502\n        \u2502 ---                 \u2506 ---                             \u2502\n        \u2502 str                 \u2506 str                             \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 ERR194146.812444541 \u2506 HSQ1008:141:D0CC8ACXX:2:1204:1\u2026 \u2502\n        \u2502 ERR194146.812444542 \u2506 HSQ1008:141:D0CC8ACXX:4:1206:1\u2026 \u2502\n        \u2502 ERR194146.812444543 \u2506 HSQ1008:141:D0CC8ACXX:3:2104:5\u2026 \u2502\n        \u2502 ERR194146.812444544 \u2506 HSQ1008:141:D0CC8ACXX:3:2204:1\u2026 \u2502\n        \u2502 ERR194146.812444545 \u2506 HSQ1008:141:D0CC8ACXX:3:1304:3\u2026 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        ```\n\n\n    !!! tip\n        `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the FASTQ file. As a rule of thumb for large scale operations (reading a whole FASTQ), it is recommended to the default values.\n    \"\"\"\n\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    fastq_read_options = FastqReadOptions(\n        object_storage_options=object_storage_options, parallel=parallel\n    )\n    read_options = ReadOptions(fastq_read_options=fastq_read_options)\n    py_register_table(ctx, path, name, InputFormat.Fastq, read_options)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_gff","title":"<code>register_gff(path, name=None, thread_num=1, chunk_size=64, concurrent_fetches=8, allow_anonymous=True, max_retries=5, timeout=300, enable_request_payer=False, compression_type='auto', parallel=False)</code>  <code>staticmethod</code>","text":"<p>Register a GFF file as a Datafusion table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the GFF file.</p> required <code>name</code> <code>Union[str, None]</code> <p>The name of the table. If None, the name of the table will be generated automatically based on the path.</p> <code>None</code> <code>thread_num</code> <code>int</code> <p>The number of threads to use for reading the GFF file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>1</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 8-16.</p> <code>64</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 1-2.</p> <code>8</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>compression_type</code> <code>str</code> <p>The compression type of the GFF file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compression is supported ('bgz' and 'gz').</p> <code>'auto'</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <code>parallel</code> <code>bool</code> <p>Whether to use the parallel reader for BGZF-compressed local files. Default is False.</p> <code>False</code> <p>Note</p> <p>GFF reader uses 1-based coordinate system for the <code>start</code> and <code>end</code> columns.</p> <p>Example</p> <p></p><pre><code>wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/gencode.v38.annotation.gff3.gz -O /tmp/gencode.v38.annotation.gff3.gz\n</code></pre> <pre><code>import polars_bio as pb\npb.register_gff(\"/tmp/gencode.v38.annotation.gff3.gz\", \"gencode_v38_annotation3_bgz\")\npb.sql(\"SELECT attributes, count(*) AS cnt FROM gencode_v38_annotation3_bgz GROUP BY attributes\").limit(5).collect()\n</code></pre> <pre><code>shape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Parent            \u2506 cnt   \u2502\n\u2502 ---               \u2506 ---   \u2502\n\u2502 str               \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 null              \u2506 60649 \u2502\n\u2502 ENSG00000223972.5 \u2506 2     \u2502\n\u2502 ENST00000456328.2 \u2506 3     \u2502\n\u2502 ENST00000450305.2 \u2506 6     \u2502\n\u2502 ENSG00000227232.5 \u2506 1     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre><p></p> <p>Tip</p> <p><code>chunk_size</code> and <code>concurrent_fetches</code> can be adjusted according to the network bandwidth and the size of the GFF file. As a rule of thumb for large scale operations (reading a whole GFF), it is recommended to the default values.</p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_gff(\n    path: str,\n    name: Union[str, None] = None,\n    thread_num: int = 1,\n    chunk_size: int = 64,\n    concurrent_fetches: int = 8,\n    allow_anonymous: bool = True,\n    max_retries: int = 5,\n    timeout: int = 300,\n    enable_request_payer: bool = False,\n    compression_type: str = \"auto\",\n    parallel: bool = False,\n) -&gt; None:\n    \"\"\"\n    Register a GFF file as a Datafusion table.\n\n    Parameters:\n        path: The path to the GFF file.\n        name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n        thread_num: The number of threads to use for reading the GFF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        compression_type: The compression type of the GFF file. If not specified, it will be detected automatically based on the file extension. BGZF and GZIP compression is supported ('bgz' and 'gz').\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n        parallel: Whether to use the parallel reader for BGZF-compressed local files. Default is False.\n    !!! note\n        GFF reader uses **1-based** coordinate system for the `start` and `end` columns.\n\n    !!! Example\n        ```shell\n        wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_38/gencode.v38.annotation.gff3.gz -O /tmp/gencode.v38.annotation.gff3.gz\n        ```\n        ```python\n        import polars_bio as pb\n        pb.register_gff(\"/tmp/gencode.v38.annotation.gff3.gz\", \"gencode_v38_annotation3_bgz\")\n        pb.sql(\"SELECT attributes, count(*) AS cnt FROM gencode_v38_annotation3_bgz GROUP BY attributes\").limit(5).collect()\n        ```\n        ```shell\n\n        shape: (5, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 Parent            \u2506 cnt   \u2502\n        \u2502 ---               \u2506 ---   \u2502\n        \u2502 str               \u2506 i64   \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 null              \u2506 60649 \u2502\n        \u2502 ENSG00000223972.5 \u2506 2     \u2502\n        \u2502 ENST00000456328.2 \u2506 3     \u2502\n        \u2502 ENST00000450305.2 \u2506 6     \u2502\n        \u2502 ENSG00000227232.5 \u2506 1     \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        ```\n    !!! tip\n        `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the GFF file. As a rule of thumb for large scale operations (reading a whole GFF), it is recommended to the default values.\n    \"\"\"\n\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    gff_read_options = GffReadOptions(\n        attr_fields=None,\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n        parallel=parallel,\n    )\n    read_options = ReadOptions(gff_read_options=gff_read_options)\n    py_register_table(ctx, path, name, InputFormat.Gff, read_options)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_vcf","title":"<code>register_vcf(path, name=None, info_fields=None, thread_num=None, chunk_size=64, concurrent_fetches=8, allow_anonymous=True, max_retries=5, timeout=300, enable_request_payer=False, compression_type='auto')</code>  <code>staticmethod</code>","text":"<p>Register a VCF file as a Datafusion table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the VCF file.</p> required <code>name</code> <code>Union[str, None]</code> <p>The name of the table. If None, the name of the table will be generated automatically based on the path.</p> <code>None</code> <code>info_fields</code> <code>Union[list[str], None]</code> <p>List of INFO field names to register. If None, all INFO fields will be detected automatically from the VCF header. Use this to limit registration to specific fields for better performance.</p> <code>None</code> <code>thread_num</code> <code>Union[int, None]</code> <p>The number of threads to use for reading the VCF file. Used only for parallel decompression of BGZF blocks. Works only for local files.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 8-16.</p> <code>64</code> <code>concurrent_fetches</code> <code>int</code> <p>[GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to 1-2.</p> <code>8</code> <code>allow_anonymous</code> <code>bool</code> <p>[GCS, AWS S3] Whether to allow anonymous access to object storage.</p> <code>True</code> <code>enable_request_payer</code> <code>bool</code> <p>[AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.</p> <code>False</code> <code>compression_type</code> <code>str</code> <p>The compression type of the VCF file. If not specified, it will be detected automatically..</p> <code>'auto'</code> <code>max_retries</code> <code>int</code> <p>The maximum number of retries for reading the file from object storage.</p> <code>5</code> <code>timeout</code> <code>int</code> <p>The timeout in seconds for reading the file from object storage.</p> <code>300</code> <p>Note</p> <p>VCF reader uses 1-based coordinate system for the <code>start</code> and <code>end</code> columns.</p> <p>Example</p> <p></p><pre><code>import polars_bio as pb\npb.register_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\")\n</code></pre> <pre><code>INFO:polars_bio:Table: gnomad_v4_1_sv_sites_gz registered for path: /tmp/gnomad.v4.1.sv.sites.vcf.gz\n</code></pre><p></p> <p>Tip</p> <p><code>chunk_size</code> and <code>concurrent_fetches</code> can be adjusted according to the network bandwidth and the size of the VCF file. As a rule of thumb for large scale operations (reading a whole VCF), it is recommended to the default values.</p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_vcf(\n    path: str,\n    name: Union[str, None] = None,\n    info_fields: Union[list[str], None] = None,\n    thread_num: Union[int, None] = None,\n    chunk_size: int = 64,\n    concurrent_fetches: int = 8,\n    allow_anonymous: bool = True,\n    max_retries: int = 5,\n    timeout: int = 300,\n    enable_request_payer: bool = False,\n    compression_type: str = \"auto\",\n) -&gt; None:\n    \"\"\"\n    Register a VCF file as a Datafusion table.\n\n    Parameters:\n        path: The path to the VCF file.\n        name: The name of the table. If *None*, the name of the table will be generated automatically based on the path.\n        info_fields: List of INFO field names to register. If *None*, all INFO fields will be detected automatically from the VCF header. Use this to limit registration to specific fields for better performance.\n        thread_num: The number of threads to use for reading the VCF file. Used **only** for parallel decompression of BGZF blocks. Works only for **local** files.\n        chunk_size: The size in MB of a chunk when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **8-16**.\n        concurrent_fetches: [GCS] The number of concurrent fetches when reading from an object store. Default settings are optimized for large scale operations. For small scale (interactive) operations, it is recommended to decrease this value to **1-2**.\n        allow_anonymous: [GCS, AWS S3] Whether to allow anonymous access to object storage.\n        enable_request_payer: [AWS S3] Whether to enable request payer for object storage. This is useful for reading files from AWS S3 buckets that require request payer.\n        compression_type: The compression type of the VCF file. If not specified, it will be detected automatically..\n        max_retries:  The maximum number of retries for reading the file from object storage.\n        timeout: The timeout in seconds for reading the file from object storage.\n    !!! note\n        VCF reader uses **1-based** coordinate system for the `start` and `end` columns.\n\n    !!! Example\n          ```python\n          import polars_bio as pb\n          pb.register_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\")\n          ```\n         ```shell\n         INFO:polars_bio:Table: gnomad_v4_1_sv_sites_gz registered for path: /tmp/gnomad.v4.1.sv.sites.vcf.gz\n         ```\n    !!! tip\n        `chunk_size` and `concurrent_fetches` can be adjusted according to the network bandwidth and the size of the VCF file. As a rule of thumb for large scale operations (reading a whole VCF), it is recommended to the default values.\n    \"\"\"\n\n    object_storage_options = PyObjectStorageOptions(\n        allow_anonymous=allow_anonymous,\n        enable_request_payer=enable_request_payer,\n        chunk_size=chunk_size,\n        concurrent_fetches=concurrent_fetches,\n        max_retries=max_retries,\n        timeout=timeout,\n        compression_type=compression_type,\n    )\n\n    # Use provided info_fields or autodetect from VCF header\n    if info_fields is not None:\n        all_info_fields = info_fields\n    else:\n        # Get all info fields from VCF header for automatic field detection\n        all_info_fields = None\n        try:\n            from .io import IOOperations\n\n            vcf_schema_df = IOOperations.describe_vcf(\n                path,\n                allow_anonymous=allow_anonymous,\n                enable_request_payer=enable_request_payer,\n                compression_type=compression_type,\n            )\n            all_info_fields = vcf_schema_df.select(\"name\").to_series().to_list()\n        except Exception:\n            # Fallback to empty list if unable to get info fields\n            all_info_fields = []\n\n    vcf_read_options = VcfReadOptions(\n        info_fields=all_info_fields,\n        thread_num=thread_num,\n        object_storage_options=object_storage_options,\n    )\n    read_options = ReadOptions(vcf_read_options=vcf_read_options)\n    py_register_table(ctx, path, name, InputFormat.Vcf, read_options)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.register_view","title":"<code>register_view(name, query)</code>  <code>staticmethod</code>","text":"<p>Register a query as a Datafusion view. This view can be used in genomic ranges operations, such as overlap, nearest, and count_overlaps. It is useful for filtering, transforming, and aggregating data prior to the range operation. When combined with the range operation, it can be used to perform complex in a streaming fashion end-to-end.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the table.</p> required <code>query</code> <code>str</code> <p>The SQL query.</p> required <p>Example</p> <p></p><pre><code>import polars_bio as pb\npb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\", \"gnomad_sv\")\npb.register_view(\"v_gnomad_sv\", \"SELECT replace(chrom,'chr', '') AS chrom, start, end FROM gnomad_sv\")\npb.sql(\"SELECT * FROM v_gnomad_sv\").limit(5).collect()\n</code></pre> <pre><code>  shape: (5, 3)\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 chrom \u2506 start   \u2506 end     \u2502\n  \u2502 ---   \u2506 ---     \u2506 ---     \u2502\n  \u2502 str   \u2506 u32     \u2506 u32     \u2502\n  \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n  \u2502 21    \u2506 5031905 \u2506 5031905 \u2502\n  \u2502 21    \u2506 5031905 \u2506 5031905 \u2502\n  \u2502 21    \u2506 5031909 \u2506 5031909 \u2502\n  \u2502 21    \u2506 5031911 \u2506 5031911 \u2502\n  \u2502 21    \u2506 5031911 \u2506 5031911 \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre><p></p> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef register_view(name: str, query: str) -&gt; None:\n    \"\"\"\n    Register a query as a Datafusion view. This view can be used in genomic ranges operations,\n    such as overlap, nearest, and count_overlaps. It is useful for filtering, transforming, and aggregating data\n    prior to the range operation. When combined with the range operation, it can be used to perform complex in a streaming fashion end-to-end.\n\n    Parameters:\n        name: The name of the table.\n        query: The SQL query.\n\n    !!! Example\n          ```python\n          import polars_bio as pb\n          pb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\", \"gnomad_sv\")\n          pb.register_view(\"v_gnomad_sv\", \"SELECT replace(chrom,'chr', '') AS chrom, start, end FROM gnomad_sv\")\n          pb.sql(\"SELECT * FROM v_gnomad_sv\").limit(5).collect()\n          ```\n          ```shell\n            shape: (5, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 chrom \u2506 start   \u2506 end     \u2502\n            \u2502 ---   \u2506 ---     \u2506 ---     \u2502\n            \u2502 str   \u2506 u32     \u2506 u32     \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 21    \u2506 5031905 \u2506 5031905 \u2502\n            \u2502 21    \u2506 5031905 \u2506 5031905 \u2502\n            \u2502 21    \u2506 5031909 \u2506 5031909 \u2502\n            \u2502 21    \u2506 5031911 \u2506 5031911 \u2502\n            \u2502 21    \u2506 5031911 \u2506 5031911 \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          ```\n    \"\"\"\n    py_register_view(ctx, name, query)\n</code></pre>"},{"location":"api/#polars_bio.data_processing.sql","title":"<code>sql(query)</code>  <code>staticmethod</code>","text":"<p>Execute a SQL query on the registered tables.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The SQL query.</p> required <p>Example</p> <pre><code>import polars_bio as pb\npb.register_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad_v4_1_sv\")\npb.sql(\"SELECT * FROM gnomad_v4_1_sv LIMIT 5\").collect()\n</code></pre> Source code in <code>polars_bio/sql.py</code> <pre><code>@staticmethod\ndef sql(query: str) -&gt; pl.LazyFrame:\n    \"\"\"\n    Execute a SQL query on the registered tables.\n\n    Parameters:\n        query: The SQL query.\n\n    !!! Example\n          ```python\n          import polars_bio as pb\n          pb.register_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad_v4_1_sv\")\n          pb.sql(\"SELECT * FROM gnomad_v4_1_sv LIMIT 5\").collect()\n          ```\n    \"\"\"\n    df = py_read_sql(ctx, query)\n    return _lazy_scan(df)\n</code></pre>"},{"location":"api/#polars_bio.range_operations","title":"<code>range_operations</code>","text":"Source code in <code>polars_bio/range_op.py</code> <pre><code>class IntervalOperations:\n\n    @staticmethod\n    def overlap(\n        df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        use_zero_based: bool = False,\n        suffixes: tuple[str, str] = (\"_1\", \"_2\"),\n        on_cols: Union[list[str], None] = None,\n        cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        algorithm: str = \"Coitrees\",\n        low_memory: bool = False,\n        output_type: str = \"polars.LazyFrame\",\n        read_options1: Union[ReadOptions, None] = None,\n        read_options2: Union[ReadOptions, None] = None,\n        projection_pushdown: bool = False,\n    ) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n        \"\"\"\n        Find pairs of overlapping genomic intervals.\n        Bioframe inspired API.\n\n        Parameters:\n            df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n            df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n            use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n            cols1: The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            cols2:  The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            suffixes: Suffixes for the columns of the two overlapped sets.\n            on_cols: List of additional column names to join on. default is None.\n            algorithm: The algorithm to use for the overlap operation. Available options: Coitrees, IntervalTree, ArrayIntervalTree, Lapper, SuperIntervals\n            low_memory: If True, use low memory method for output generation. This may be slower but uses less memory.\n            output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n            read_options1: Additional options for reading the input files.\n            read_options2: Additional options for reading the input files.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        Returns:\n            **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n        Note:\n            1. The default output format, i.e.  [LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), is recommended for large datasets as it supports output streaming and lazy evaluation.\n            This enables efficient processing of large datasets without loading the entire output dataset into memory.\n            2. Streaming is only supported for polars.LazyFrame output.\n\n        Example:\n            ```python\n            import polars_bio as pb\n            import pandas as pd\n\n            df1 = pd.DataFrame([\n                ['chr1', 1, 5],\n                ['chr1', 3, 8],\n                ['chr1', 8, 10],\n                ['chr1', 12, 14]],\n            columns=['chrom', 'start', 'end']\n            )\n\n            df2 = pd.DataFrame(\n            [['chr1', 4, 8],\n             ['chr1', 10, 11]],\n            columns=['chrom', 'start', 'end' ]\n            )\n            overlapping_intervals = pb.overlap(df1, df2, output_type=\"pandas.DataFrame\")\n\n            overlapping_intervals\n                chrom_1         start_1     end_1 chrom_2       start_2  end_2\n            0     chr1            1          5     chr1            4          8\n            1     chr1            3          8     chr1            4          8\n\n            ```\n\n        Todo:\n             Support for on_cols.\n        \"\"\"\n\n        _validate_overlap_input(\n            cols1, cols2, on_cols, suffixes, output_type, use_zero_based\n        )\n\n        cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n        cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n        range_options = RangeOptions(\n            range_op=RangeOp.Overlap,\n            filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n            suffixes=suffixes,\n            columns_1=cols1,\n            columns_2=cols2,\n            overlap_alg=algorithm,\n            overlap_low_memory=low_memory,\n        )\n\n        return range_operation(\n            df1,\n            df2,\n            range_options,\n            output_type,\n            ctx,\n            read_options1,\n            read_options2,\n            projection_pushdown,\n        )\n\n    @staticmethod\n    def nearest(\n        df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        use_zero_based: bool = False,\n        suffixes: tuple[str, str] = (\"_1\", \"_2\"),\n        on_cols: Union[list[str], None] = None,\n        cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        output_type: str = \"polars.LazyFrame\",\n        read_options: Union[ReadOptions, None] = None,\n        projection_pushdown: bool = False,\n    ) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n        \"\"\"\n        Find pairs of closest genomic intervals.\n        Bioframe inspired API.\n\n        Parameters:\n            df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n            df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n            use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n            cols1: The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            cols2:  The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            suffixes: Suffixes for the columns of the two overlapped sets.\n            on_cols: List of additional column names to join on. default is None.\n            output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n            read_options: Additional options for reading the input files.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n\n        Returns:\n            **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n        Note:\n            The default output format, i.e. [LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), is recommended for large datasets as it supports output streaming and lazy evaluation.\n            This enables efficient processing of large datasets without loading the entire output dataset into memory.\n\n        Example:\n\n        Todo:\n            Support for on_cols.\n        \"\"\"\n\n        _validate_overlap_input(\n            cols1, cols2, on_cols, suffixes, output_type, use_zero_based\n        )\n\n        cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n        cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n        range_options = RangeOptions(\n            range_op=RangeOp.Nearest,\n            filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n            suffixes=suffixes,\n            columns_1=cols1,\n            columns_2=cols2,\n        )\n        return range_operation(\n            df1,\n            df2,\n            range_options,\n            output_type,\n            ctx,\n            read_options,\n            projection_pushdown=projection_pushdown,\n        )\n\n    @staticmethod\n    def coverage(\n        df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        use_zero_based: bool = False,\n        suffixes: tuple[str, str] = (\"_1\", \"_2\"),\n        on_cols: Union[list[str], None] = None,\n        cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        output_type: str = \"polars.LazyFrame\",\n        read_options: Union[ReadOptions, None] = None,\n        projection_pushdown: bool = False,\n    ) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n        \"\"\"\n        Calculate intervals coverage.\n        Bioframe inspired API.\n\n        Parameters:\n            df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n            df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n            use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n            cols1: The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            cols2:  The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            suffixes: Suffixes for the columns of the two overlapped sets.\n            on_cols: List of additional column names to join on. default is None.\n            output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n            read_options: Additional options for reading the input files.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n\n        Returns:\n            **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n        Note:\n            The default output format, i.e. [LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), is recommended for large datasets as it supports output streaming and lazy evaluation.\n            This enables efficient processing of large datasets without loading the entire output dataset into memory.\n\n        Example:\n\n        Todo:\n            Support for on_cols.\n        \"\"\"\n\n        _validate_overlap_input(\n            cols1,\n            cols2,\n            on_cols,\n            suffixes,\n            output_type,\n            use_zero_based,\n        )\n\n        cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n        cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n        range_options = RangeOptions(\n            range_op=RangeOp.Coverage,\n            filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n            suffixes=suffixes,\n            columns_1=cols1,\n            columns_2=cols2,\n        )\n        return range_operation(\n            df2,\n            df1,\n            range_options,\n            output_type,\n            ctx,\n            read_options,\n            projection_pushdown=projection_pushdown,\n        )\n\n    @staticmethod\n    def count_overlaps(\n        df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        use_zero_based: bool = False,\n        suffixes: tuple[str, str] = (\"\", \"_\"),\n        cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        on_cols: Union[list[str], None] = None,\n        output_type: str = \"polars.LazyFrame\",\n        naive_query: bool = True,\n        projection_pushdown: bool = False,\n    ) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n        \"\"\"\n        Count pairs of overlapping genomic intervals.\n        Bioframe inspired API.\n\n        Parameters:\n            df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n            df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n            use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n            suffixes: Suffixes for the columns of the two overlapped sets.\n            cols1: The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            cols2:  The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            on_cols: List of additional column names to join on. default is None.\n            output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n            naive_query: If True, use naive query for counting overlaps based on overlaps.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n        Returns:\n            **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n        Example:\n            ```python\n            import polars_bio as pb\n            import pandas as pd\n\n            df1 = pd.DataFrame([\n                ['chr1', 1, 5],\n                ['chr1', 3, 8],\n                ['chr1', 8, 10],\n                ['chr1', 12, 14]],\n            columns=['chrom', 'start', 'end']\n            )\n\n            df2 = pd.DataFrame(\n            [['chr1', 4, 8],\n             ['chr1', 10, 11]],\n            columns=['chrom', 'start', 'end' ]\n            )\n            counts = pb.count_overlaps(df1, df2, output_type=\"pandas.DataFrame\")\n\n            counts\n\n            chrom  start  end  count\n            0  chr1      1    5      1\n            1  chr1      3    8      1\n            2  chr1      8   10      0\n            3  chr1     12   14      0\n            ```\n\n        Todo:\n             Support return_input.\n        \"\"\"\n        _validate_overlap_input(\n            cols1, cols2, on_cols, suffixes, output_type, use_zero_based\n        )\n        my_ctx = get_py_ctx()\n        on_cols = [] if on_cols is None else on_cols\n        cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n        cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n        if naive_query:\n            range_options = RangeOptions(\n                range_op=RangeOp.CountOverlapsNaive,\n                filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n                suffixes=suffixes,\n                columns_1=cols1,\n                columns_2=cols2,\n            )\n            return range_operation(df2, df1, range_options, output_type, ctx)\n        df1 = read_df_to_datafusion(my_ctx, df1)\n        df2 = read_df_to_datafusion(my_ctx, df2)\n\n        curr_cols = set(df1.schema().names) | set(df2.schema().names)\n        s1start_s2end = prevent_column_collision(\"s1starts2end\", curr_cols)\n        s1end_s2start = prevent_column_collision(\"s1ends2start\", curr_cols)\n        contig = prevent_column_collision(\"contig\", curr_cols)\n        count = prevent_column_collision(\"count\", curr_cols)\n        starts = prevent_column_collision(\"starts\", curr_cols)\n        ends = prevent_column_collision(\"ends\", curr_cols)\n        is_s1 = prevent_column_collision(\"is_s1\", curr_cols)\n        suff, _ = suffixes\n        df1, df2 = df2, df1\n        df1 = df1.select(\n            *(\n                [\n                    literal(1).alias(is_s1),\n                    col(cols1[1]).alias(s1start_s2end),\n                    col(cols1[2]).alias(s1end_s2start),\n                    col(cols1[0]).alias(contig),\n                ]\n                + on_cols\n            )\n        )\n        df2 = df2.select(\n            *(\n                [\n                    literal(0).alias(is_s1),\n                    col(cols2[2]).alias(s1end_s2start),\n                    col(cols2[1]).alias(s1start_s2end),\n                    col(cols2[0]).alias(contig),\n                ]\n                + on_cols\n            )\n        )\n\n        df = df1.union(df2)\n\n        partitioning = [col(contig)] + [col(c) for c in on_cols]\n        df = df.select(\n            *(\n                [\n                    s1start_s2end,\n                    s1end_s2start,\n                    contig,\n                    is_s1,\n                    datafusion.functions.sum(col(is_s1))\n                    .over(\n                        datafusion.expr.Window(\n                            partition_by=partitioning,\n                            order_by=[\n                                col(s1start_s2end).sort(),\n                                col(is_s1).sort(ascending=use_zero_based),\n                            ],\n                        )\n                    )\n                    .alias(starts),\n                    datafusion.functions.sum(col(is_s1))\n                    .over(\n                        datafusion.expr.Window(\n                            partition_by=partitioning,\n                            order_by=[\n                                col(s1end_s2start).sort(),\n                                col(is_s1).sort(ascending=(not use_zero_based)),\n                            ],\n                        )\n                    )\n                    .alias(ends),\n                ]\n                + on_cols\n            )\n        )\n        df = df.filter(col(is_s1) == 0)\n        df = df.select(\n            *(\n                [\n                    col(contig).alias(cols1[0] + suff),\n                    col(s1end_s2start).alias(cols1[1] + suff),\n                    col(s1start_s2end).alias(cols1[2] + suff),\n                ]\n                + on_cols\n                + [(col(starts) - col(ends)).alias(count)]\n            )\n        )\n\n        return convert_result(df, output_type)\n\n    @staticmethod\n    def merge(\n        df: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n        use_zero_based: bool = False,\n        min_dist: float = 0,\n        cols: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n        on_cols: Union[list[str], None] = None,\n        output_type: str = \"polars.LazyFrame\",\n        projection_pushdown: bool = False,\n    ) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n        \"\"\"\n        Merge overlapping intervals. It is assumed that start &lt; end.\n\n\n        Parameters:\n            df: Can be a path to a file, a polars DataFrame, or a pandas DataFrame. CSV with a header, BED  and Parquet are supported.\n            use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n            cols: The names of columns containing the chromosome, start and end of the\n                genomic intervals, provided separately for each set.\n            on_cols: List of additional column names for clustering. default is None.\n            output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n            projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n        Returns:\n            **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n        Example:\n\n        Todo:\n            Support for on_cols.\n        \"\"\"\n        suffixes = (\"_1\", \"_2\")\n        _validate_overlap_input(\n            cols, cols, on_cols, suffixes, output_type, use_zero_based\n        )\n\n        my_ctx = get_py_ctx()\n        cols = DEFAULT_INTERVAL_COLUMNS if cols is None else cols\n        contig = cols[0]\n        start = cols[1]\n        end = cols[2]\n\n        on_cols = [] if on_cols is None else on_cols\n        on_cols = [contig] + on_cols\n\n        df = read_df_to_datafusion(my_ctx, df)\n        df_schema = df.schema()\n        start_type = df_schema.field(start).type\n        end_type = df_schema.field(end).type\n\n        curr_cols = set(df_schema.names)\n        start_end = prevent_column_collision(\"start_end\", curr_cols)\n        is_start_end = prevent_column_collision(\"is_start_or_end\", curr_cols)\n        current_intervals = prevent_column_collision(\"current_intervals\", curr_cols)\n        n_intervals = prevent_column_collision(\"n_intervals\", curr_cols)\n\n        end_positions = df.select(\n            *(\n                [\n                    (col(end) + min_dist).alias(start_end),\n                    literal(-1).alias(is_start_end),\n                ]\n                + on_cols\n            )\n        )\n        start_positions = df.select(\n            *([col(start).alias(start_end), literal(1).alias(is_start_end)] + on_cols)\n        )\n        all_positions = start_positions.union(end_positions)\n        start_end_type = all_positions.schema().field(start_end).type\n        all_positions = all_positions.select(\n            *([col(start_end).cast(start_end_type), col(is_start_end)] + on_cols)\n        )\n\n        sorting = [\n            col(start_end).sort(),\n            col(is_start_end).sort(ascending=use_zero_based),\n        ]\n        all_positions = all_positions.sort(*sorting)\n\n        on_cols_expr = [col(c) for c in on_cols]\n\n        win = datafusion.expr.Window(\n            partition_by=on_cols_expr,\n            order_by=sorting,\n        )\n        all_positions = all_positions.select(\n            *(\n                [\n                    start_end,\n                    is_start_end,\n                    datafusion.functions.sum(col(is_start_end))\n                    .over(win)\n                    .alias(current_intervals),\n                ]\n                + on_cols\n                + [\n                    datafusion.functions.row_number(\n                        partition_by=on_cols_expr, order_by=sorting\n                    ).alias(n_intervals)\n                ]\n            )\n        )\n        all_positions = all_positions.filter(\n            ((col(current_intervals) == 0) &amp; (col(is_start_end) == -1))\n            | ((col(current_intervals) == 1) &amp; (col(is_start_end) == 1))\n        )\n        all_positions = all_positions.select(\n            *(\n                [start_end, is_start_end]\n                + on_cols\n                + [\n                    (\n                        (\n                            col(n_intervals)\n                            - datafusion.functions.lag(\n                                col(n_intervals), partition_by=on_cols_expr\n                            )\n                            + 1\n                        )\n                        / 2\n                    )\n                    .cast(pa.int64())\n                    .alias(n_intervals)\n                ]\n            )\n        )\n        result = all_positions.select(\n            *(\n                [\n                    (col(start_end) - min_dist).alias(end),\n                    is_start_end,\n                    datafusion.functions.lag(\n                        col(start_end), partition_by=on_cols_expr\n                    ).alias(start),\n                ]\n                + on_cols\n                + [n_intervals]\n            )\n        )\n        result = result.filter(col(is_start_end) == -1)\n        result = result.select(\n            *(\n                [contig, col(start).cast(start_type), col(end).cast(end_type)]\n                + on_cols[1:]\n                + [n_intervals]\n            )\n        )\n\n        return convert_result(result, output_type)\n</code></pre>"},{"location":"api/#polars_bio.range_operations.count_overlaps","title":"<code>count_overlaps(df1, df2, use_zero_based=False, suffixes=('', '_'), cols1=['chrom', 'start', 'end'], cols2=['chrom', 'start', 'end'], on_cols=None, output_type='polars.LazyFrame', naive_query=True, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Count pairs of overlapping genomic intervals. Bioframe inspired API.</p> <p>Parameters:</p> Name Type Description Default <code>df1</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see register_vcf). CSV with a header, BED and Parquet are supported.</p> required <code>df2</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.</p> required <code>use_zero_based</code> <code>bool</code> <p>By default 1-based coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.</p> <code>False</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Suffixes for the columns of the two overlapped sets.</p> <code>('', '_')</code> <code>cols1</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>cols2</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>on_cols</code> <code>Union[list[str], None]</code> <p>List of additional column names to join on. default is None.</p> <code>None</code> <code>output_type</code> <code>str</code> <p>Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.</p> <code>'polars.LazyFrame'</code> <code>naive_query</code> <code>bool</code> <p>If True, use naive query for counting overlaps based on overlaps.</p> <code>True</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Returns:     polars.LazyFrame or polars.DataFrame or pandas.DataFrame of the overlapping intervals.</p> Example <pre><code>import polars_bio as pb\nimport pandas as pd\n\ndf1 = pd.DataFrame([\n    ['chr1', 1, 5],\n    ['chr1', 3, 8],\n    ['chr1', 8, 10],\n    ['chr1', 12, 14]],\ncolumns=['chrom', 'start', 'end']\n)\n\ndf2 = pd.DataFrame(\n[['chr1', 4, 8],\n ['chr1', 10, 11]],\ncolumns=['chrom', 'start', 'end' ]\n)\ncounts = pb.count_overlaps(df1, df2, output_type=\"pandas.DataFrame\")\n\ncounts\n\nchrom  start  end  count\n0  chr1      1    5      1\n1  chr1      3    8      1\n2  chr1      8   10      0\n3  chr1     12   14      0\n</code></pre> Todo <p>Support return_input.</p> Source code in <code>polars_bio/range_op.py</code> <pre><code>@staticmethod\ndef count_overlaps(\n    df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    use_zero_based: bool = False,\n    suffixes: tuple[str, str] = (\"\", \"_\"),\n    cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    on_cols: Union[list[str], None] = None,\n    output_type: str = \"polars.LazyFrame\",\n    naive_query: bool = True,\n    projection_pushdown: bool = False,\n) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n    \"\"\"\n    Count pairs of overlapping genomic intervals.\n    Bioframe inspired API.\n\n    Parameters:\n        df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n        df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n        use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n        suffixes: Suffixes for the columns of the two overlapped sets.\n        cols1: The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        cols2:  The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        on_cols: List of additional column names to join on. default is None.\n        output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n        naive_query: If True, use naive query for counting overlaps based on overlaps.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n    Returns:\n        **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n    Example:\n        ```python\n        import polars_bio as pb\n        import pandas as pd\n\n        df1 = pd.DataFrame([\n            ['chr1', 1, 5],\n            ['chr1', 3, 8],\n            ['chr1', 8, 10],\n            ['chr1', 12, 14]],\n        columns=['chrom', 'start', 'end']\n        )\n\n        df2 = pd.DataFrame(\n        [['chr1', 4, 8],\n         ['chr1', 10, 11]],\n        columns=['chrom', 'start', 'end' ]\n        )\n        counts = pb.count_overlaps(df1, df2, output_type=\"pandas.DataFrame\")\n\n        counts\n\n        chrom  start  end  count\n        0  chr1      1    5      1\n        1  chr1      3    8      1\n        2  chr1      8   10      0\n        3  chr1     12   14      0\n        ```\n\n    Todo:\n         Support return_input.\n    \"\"\"\n    _validate_overlap_input(\n        cols1, cols2, on_cols, suffixes, output_type, use_zero_based\n    )\n    my_ctx = get_py_ctx()\n    on_cols = [] if on_cols is None else on_cols\n    cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n    cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n    if naive_query:\n        range_options = RangeOptions(\n            range_op=RangeOp.CountOverlapsNaive,\n            filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n            suffixes=suffixes,\n            columns_1=cols1,\n            columns_2=cols2,\n        )\n        return range_operation(df2, df1, range_options, output_type, ctx)\n    df1 = read_df_to_datafusion(my_ctx, df1)\n    df2 = read_df_to_datafusion(my_ctx, df2)\n\n    curr_cols = set(df1.schema().names) | set(df2.schema().names)\n    s1start_s2end = prevent_column_collision(\"s1starts2end\", curr_cols)\n    s1end_s2start = prevent_column_collision(\"s1ends2start\", curr_cols)\n    contig = prevent_column_collision(\"contig\", curr_cols)\n    count = prevent_column_collision(\"count\", curr_cols)\n    starts = prevent_column_collision(\"starts\", curr_cols)\n    ends = prevent_column_collision(\"ends\", curr_cols)\n    is_s1 = prevent_column_collision(\"is_s1\", curr_cols)\n    suff, _ = suffixes\n    df1, df2 = df2, df1\n    df1 = df1.select(\n        *(\n            [\n                literal(1).alias(is_s1),\n                col(cols1[1]).alias(s1start_s2end),\n                col(cols1[2]).alias(s1end_s2start),\n                col(cols1[0]).alias(contig),\n            ]\n            + on_cols\n        )\n    )\n    df2 = df2.select(\n        *(\n            [\n                literal(0).alias(is_s1),\n                col(cols2[2]).alias(s1end_s2start),\n                col(cols2[1]).alias(s1start_s2end),\n                col(cols2[0]).alias(contig),\n            ]\n            + on_cols\n        )\n    )\n\n    df = df1.union(df2)\n\n    partitioning = [col(contig)] + [col(c) for c in on_cols]\n    df = df.select(\n        *(\n            [\n                s1start_s2end,\n                s1end_s2start,\n                contig,\n                is_s1,\n                datafusion.functions.sum(col(is_s1))\n                .over(\n                    datafusion.expr.Window(\n                        partition_by=partitioning,\n                        order_by=[\n                            col(s1start_s2end).sort(),\n                            col(is_s1).sort(ascending=use_zero_based),\n                        ],\n                    )\n                )\n                .alias(starts),\n                datafusion.functions.sum(col(is_s1))\n                .over(\n                    datafusion.expr.Window(\n                        partition_by=partitioning,\n                        order_by=[\n                            col(s1end_s2start).sort(),\n                            col(is_s1).sort(ascending=(not use_zero_based)),\n                        ],\n                    )\n                )\n                .alias(ends),\n            ]\n            + on_cols\n        )\n    )\n    df = df.filter(col(is_s1) == 0)\n    df = df.select(\n        *(\n            [\n                col(contig).alias(cols1[0] + suff),\n                col(s1end_s2start).alias(cols1[1] + suff),\n                col(s1start_s2end).alias(cols1[2] + suff),\n            ]\n            + on_cols\n            + [(col(starts) - col(ends)).alias(count)]\n        )\n    )\n\n    return convert_result(df, output_type)\n</code></pre>"},{"location":"api/#polars_bio.range_operations.coverage","title":"<code>coverage(df1, df2, use_zero_based=False, suffixes=('_1', '_2'), on_cols=None, cols1=['chrom', 'start', 'end'], cols2=['chrom', 'start', 'end'], output_type='polars.LazyFrame', read_options=None, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Calculate intervals coverage. Bioframe inspired API.</p> <p>Parameters:</p> Name Type Description Default <code>df1</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see register_vcf). CSV with a header, BED and Parquet are supported.</p> required <code>df2</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.</p> required <code>use_zero_based</code> <code>bool</code> <p>By default 1-based coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.</p> <code>False</code> <code>cols1</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>cols2</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Suffixes for the columns of the two overlapped sets.</p> <code>('_1', '_2')</code> <code>on_cols</code> <code>Union[list[str], None]</code> <p>List of additional column names to join on. default is None.</p> <code>None</code> <code>output_type</code> <code>str</code> <p>Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.</p> <code>'polars.LazyFrame'</code> <code>read_options</code> <code>Union[ReadOptions, None]</code> <p>Additional options for reading the input files.</p> <code>None</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[LazyFrame, DataFrame, 'pd.DataFrame', DataFrame]</code> <p>polars.LazyFrame or polars.DataFrame or pandas.DataFrame of the overlapping intervals.</p> Note <p>The default output format, i.e. LazyFrame, is recommended for large datasets as it supports output streaming and lazy evaluation. This enables efficient processing of large datasets without loading the entire output dataset into memory.</p> <p>Example:</p> Todo <p>Support for on_cols.</p> Source code in <code>polars_bio/range_op.py</code> <pre><code>@staticmethod\ndef coverage(\n    df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    use_zero_based: bool = False,\n    suffixes: tuple[str, str] = (\"_1\", \"_2\"),\n    on_cols: Union[list[str], None] = None,\n    cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    output_type: str = \"polars.LazyFrame\",\n    read_options: Union[ReadOptions, None] = None,\n    projection_pushdown: bool = False,\n) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n    \"\"\"\n    Calculate intervals coverage.\n    Bioframe inspired API.\n\n    Parameters:\n        df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n        df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n        use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n        cols1: The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        cols2:  The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        suffixes: Suffixes for the columns of the two overlapped sets.\n        on_cols: List of additional column names to join on. default is None.\n        output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n        read_options: Additional options for reading the input files.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n\n    Returns:\n        **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n    Note:\n        The default output format, i.e. [LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), is recommended for large datasets as it supports output streaming and lazy evaluation.\n        This enables efficient processing of large datasets without loading the entire output dataset into memory.\n\n    Example:\n\n    Todo:\n        Support for on_cols.\n    \"\"\"\n\n    _validate_overlap_input(\n        cols1,\n        cols2,\n        on_cols,\n        suffixes,\n        output_type,\n        use_zero_based,\n    )\n\n    cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n    cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n    range_options = RangeOptions(\n        range_op=RangeOp.Coverage,\n        filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n        suffixes=suffixes,\n        columns_1=cols1,\n        columns_2=cols2,\n    )\n    return range_operation(\n        df2,\n        df1,\n        range_options,\n        output_type,\n        ctx,\n        read_options,\n        projection_pushdown=projection_pushdown,\n    )\n</code></pre>"},{"location":"api/#polars_bio.range_operations.merge","title":"<code>merge(df, use_zero_based=False, min_dist=0, cols=['chrom', 'start', 'end'], on_cols=None, output_type='polars.LazyFrame', projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Merge overlapping intervals. It is assumed that start &lt; end.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame. CSV with a header, BED  and Parquet are supported.</p> required <code>use_zero_based</code> <code>bool</code> <p>By default 1-based coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.</p> <code>False</code> <code>cols</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>on_cols</code> <code>Union[list[str], None]</code> <p>List of additional column names for clustering. default is None.</p> <code>None</code> <code>output_type</code> <code>str</code> <p>Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.</p> <code>'polars.LazyFrame'</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[LazyFrame, DataFrame, 'pd.DataFrame', DataFrame]</code> <p>polars.LazyFrame or polars.DataFrame or pandas.DataFrame of the overlapping intervals.</p> <p>Example:</p> Todo <p>Support for on_cols.</p> Source code in <code>polars_bio/range_op.py</code> <pre><code>@staticmethod\ndef merge(\n    df: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    use_zero_based: bool = False,\n    min_dist: float = 0,\n    cols: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    on_cols: Union[list[str], None] = None,\n    output_type: str = \"polars.LazyFrame\",\n    projection_pushdown: bool = False,\n) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n    \"\"\"\n    Merge overlapping intervals. It is assumed that start &lt; end.\n\n\n    Parameters:\n        df: Can be a path to a file, a polars DataFrame, or a pandas DataFrame. CSV with a header, BED  and Parquet are supported.\n        use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n        cols: The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        on_cols: List of additional column names for clustering. default is None.\n        output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    Returns:\n        **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n    Example:\n\n    Todo:\n        Support for on_cols.\n    \"\"\"\n    suffixes = (\"_1\", \"_2\")\n    _validate_overlap_input(\n        cols, cols, on_cols, suffixes, output_type, use_zero_based\n    )\n\n    my_ctx = get_py_ctx()\n    cols = DEFAULT_INTERVAL_COLUMNS if cols is None else cols\n    contig = cols[0]\n    start = cols[1]\n    end = cols[2]\n\n    on_cols = [] if on_cols is None else on_cols\n    on_cols = [contig] + on_cols\n\n    df = read_df_to_datafusion(my_ctx, df)\n    df_schema = df.schema()\n    start_type = df_schema.field(start).type\n    end_type = df_schema.field(end).type\n\n    curr_cols = set(df_schema.names)\n    start_end = prevent_column_collision(\"start_end\", curr_cols)\n    is_start_end = prevent_column_collision(\"is_start_or_end\", curr_cols)\n    current_intervals = prevent_column_collision(\"current_intervals\", curr_cols)\n    n_intervals = prevent_column_collision(\"n_intervals\", curr_cols)\n\n    end_positions = df.select(\n        *(\n            [\n                (col(end) + min_dist).alias(start_end),\n                literal(-1).alias(is_start_end),\n            ]\n            + on_cols\n        )\n    )\n    start_positions = df.select(\n        *([col(start).alias(start_end), literal(1).alias(is_start_end)] + on_cols)\n    )\n    all_positions = start_positions.union(end_positions)\n    start_end_type = all_positions.schema().field(start_end).type\n    all_positions = all_positions.select(\n        *([col(start_end).cast(start_end_type), col(is_start_end)] + on_cols)\n    )\n\n    sorting = [\n        col(start_end).sort(),\n        col(is_start_end).sort(ascending=use_zero_based),\n    ]\n    all_positions = all_positions.sort(*sorting)\n\n    on_cols_expr = [col(c) for c in on_cols]\n\n    win = datafusion.expr.Window(\n        partition_by=on_cols_expr,\n        order_by=sorting,\n    )\n    all_positions = all_positions.select(\n        *(\n            [\n                start_end,\n                is_start_end,\n                datafusion.functions.sum(col(is_start_end))\n                .over(win)\n                .alias(current_intervals),\n            ]\n            + on_cols\n            + [\n                datafusion.functions.row_number(\n                    partition_by=on_cols_expr, order_by=sorting\n                ).alias(n_intervals)\n            ]\n        )\n    )\n    all_positions = all_positions.filter(\n        ((col(current_intervals) == 0) &amp; (col(is_start_end) == -1))\n        | ((col(current_intervals) == 1) &amp; (col(is_start_end) == 1))\n    )\n    all_positions = all_positions.select(\n        *(\n            [start_end, is_start_end]\n            + on_cols\n            + [\n                (\n                    (\n                        col(n_intervals)\n                        - datafusion.functions.lag(\n                            col(n_intervals), partition_by=on_cols_expr\n                        )\n                        + 1\n                    )\n                    / 2\n                )\n                .cast(pa.int64())\n                .alias(n_intervals)\n            ]\n        )\n    )\n    result = all_positions.select(\n        *(\n            [\n                (col(start_end) - min_dist).alias(end),\n                is_start_end,\n                datafusion.functions.lag(\n                    col(start_end), partition_by=on_cols_expr\n                ).alias(start),\n            ]\n            + on_cols\n            + [n_intervals]\n        )\n    )\n    result = result.filter(col(is_start_end) == -1)\n    result = result.select(\n        *(\n            [contig, col(start).cast(start_type), col(end).cast(end_type)]\n            + on_cols[1:]\n            + [n_intervals]\n        )\n    )\n\n    return convert_result(result, output_type)\n</code></pre>"},{"location":"api/#polars_bio.range_operations.nearest","title":"<code>nearest(df1, df2, use_zero_based=False, suffixes=('_1', '_2'), on_cols=None, cols1=['chrom', 'start', 'end'], cols2=['chrom', 'start', 'end'], output_type='polars.LazyFrame', read_options=None, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Find pairs of closest genomic intervals. Bioframe inspired API.</p> <p>Parameters:</p> Name Type Description Default <code>df1</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see register_vcf). CSV with a header, BED and Parquet are supported.</p> required <code>df2</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.</p> required <code>use_zero_based</code> <code>bool</code> <p>By default 1-based coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.</p> <code>False</code> <code>cols1</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>cols2</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Suffixes for the columns of the two overlapped sets.</p> <code>('_1', '_2')</code> <code>on_cols</code> <code>Union[list[str], None]</code> <p>List of additional column names to join on. default is None.</p> <code>None</code> <code>output_type</code> <code>str</code> <p>Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.</p> <code>'polars.LazyFrame'</code> <code>read_options</code> <code>Union[ReadOptions, None]</code> <p>Additional options for reading the input files.</p> <code>None</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[LazyFrame, DataFrame, 'pd.DataFrame', DataFrame]</code> <p>polars.LazyFrame or polars.DataFrame or pandas.DataFrame of the overlapping intervals.</p> Note <p>The default output format, i.e. LazyFrame, is recommended for large datasets as it supports output streaming and lazy evaluation. This enables efficient processing of large datasets without loading the entire output dataset into memory.</p> <p>Example:</p> Todo <p>Support for on_cols.</p> Source code in <code>polars_bio/range_op.py</code> <pre><code>@staticmethod\ndef nearest(\n    df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    use_zero_based: bool = False,\n    suffixes: tuple[str, str] = (\"_1\", \"_2\"),\n    on_cols: Union[list[str], None] = None,\n    cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    output_type: str = \"polars.LazyFrame\",\n    read_options: Union[ReadOptions, None] = None,\n    projection_pushdown: bool = False,\n) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n    \"\"\"\n    Find pairs of closest genomic intervals.\n    Bioframe inspired API.\n\n    Parameters:\n        df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n        df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n        use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n        cols1: The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        cols2:  The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        suffixes: Suffixes for the columns of the two overlapped sets.\n        on_cols: List of additional column names to join on. default is None.\n        output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n        read_options: Additional options for reading the input files.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n\n    Returns:\n        **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n    Note:\n        The default output format, i.e. [LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), is recommended for large datasets as it supports output streaming and lazy evaluation.\n        This enables efficient processing of large datasets without loading the entire output dataset into memory.\n\n    Example:\n\n    Todo:\n        Support for on_cols.\n    \"\"\"\n\n    _validate_overlap_input(\n        cols1, cols2, on_cols, suffixes, output_type, use_zero_based\n    )\n\n    cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n    cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n    range_options = RangeOptions(\n        range_op=RangeOp.Nearest,\n        filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n        suffixes=suffixes,\n        columns_1=cols1,\n        columns_2=cols2,\n    )\n    return range_operation(\n        df1,\n        df2,\n        range_options,\n        output_type,\n        ctx,\n        read_options,\n        projection_pushdown=projection_pushdown,\n    )\n</code></pre>"},{"location":"api/#polars_bio.range_operations.overlap","title":"<code>overlap(df1, df2, use_zero_based=False, suffixes=('_1', '_2'), on_cols=None, cols1=['chrom', 'start', 'end'], cols2=['chrom', 'start', 'end'], algorithm='Coitrees', low_memory=False, output_type='polars.LazyFrame', read_options1=None, read_options2=None, projection_pushdown=False)</code>  <code>staticmethod</code>","text":"<p>Find pairs of overlapping genomic intervals. Bioframe inspired API.</p> <p>Parameters:</p> Name Type Description Default <code>df1</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see register_vcf). CSV with a header, BED and Parquet are supported.</p> required <code>df2</code> <code>Union[str, DataFrame, LazyFrame, 'pd.DataFrame']</code> <p>Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.</p> required <code>use_zero_based</code> <code>bool</code> <p>By default 1-based coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.</p> <code>False</code> <code>cols1</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>cols2</code> <code>Union[list[str], None]</code> <p>The names of columns containing the chromosome, start and end of the genomic intervals, provided separately for each set.</p> <code>['chrom', 'start', 'end']</code> <code>suffixes</code> <code>tuple[str, str]</code> <p>Suffixes for the columns of the two overlapped sets.</p> <code>('_1', '_2')</code> <code>on_cols</code> <code>Union[list[str], None]</code> <p>List of additional column names to join on. default is None.</p> <code>None</code> <code>algorithm</code> <code>str</code> <p>The algorithm to use for the overlap operation. Available options: Coitrees, IntervalTree, ArrayIntervalTree, Lapper, SuperIntervals</p> <code>'Coitrees'</code> <code>low_memory</code> <code>bool</code> <p>If True, use low memory method for output generation. This may be slower but uses less memory.</p> <code>False</code> <code>output_type</code> <code>str</code> <p>Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.</p> <code>'polars.LazyFrame'</code> <code>read_options1</code> <code>Union[ReadOptions, None]</code> <p>Additional options for reading the input files.</p> <code>None</code> <code>read_options2</code> <code>Union[ReadOptions, None]</code> <p>Additional options for reading the input files.</p> <code>None</code> <code>projection_pushdown</code> <code>bool</code> <p>Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[LazyFrame, DataFrame, 'pd.DataFrame', DataFrame]</code> <p>polars.LazyFrame or polars.DataFrame or pandas.DataFrame of the overlapping intervals.</p> Note <ol> <li>The default output format, i.e.  LazyFrame, is recommended for large datasets as it supports output streaming and lazy evaluation. This enables efficient processing of large datasets without loading the entire output dataset into memory.</li> <li>Streaming is only supported for polars.LazyFrame output.</li> </ol> Example <pre><code>import polars_bio as pb\nimport pandas as pd\n\ndf1 = pd.DataFrame([\n    ['chr1', 1, 5],\n    ['chr1', 3, 8],\n    ['chr1', 8, 10],\n    ['chr1', 12, 14]],\ncolumns=['chrom', 'start', 'end']\n)\n\ndf2 = pd.DataFrame(\n[['chr1', 4, 8],\n ['chr1', 10, 11]],\ncolumns=['chrom', 'start', 'end' ]\n)\noverlapping_intervals = pb.overlap(df1, df2, output_type=\"pandas.DataFrame\")\n\noverlapping_intervals\n    chrom_1         start_1     end_1 chrom_2       start_2  end_2\n0     chr1            1          5     chr1            4          8\n1     chr1            3          8     chr1            4          8\n</code></pre> Todo <p>Support for on_cols.</p> Source code in <code>polars_bio/range_op.py</code> <pre><code>@staticmethod\ndef overlap(\n    df1: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    df2: Union[str, pl.DataFrame, pl.LazyFrame, \"pd.DataFrame\"],\n    use_zero_based: bool = False,\n    suffixes: tuple[str, str] = (\"_1\", \"_2\"),\n    on_cols: Union[list[str], None] = None,\n    cols1: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    cols2: Union[list[str], None] = [\"chrom\", \"start\", \"end\"],\n    algorithm: str = \"Coitrees\",\n    low_memory: bool = False,\n    output_type: str = \"polars.LazyFrame\",\n    read_options1: Union[ReadOptions, None] = None,\n    read_options2: Union[ReadOptions, None] = None,\n    projection_pushdown: bool = False,\n) -&gt; Union[pl.LazyFrame, pl.DataFrame, \"pd.DataFrame\", datafusion.DataFrame]:\n    \"\"\"\n    Find pairs of overlapping genomic intervals.\n    Bioframe inspired API.\n\n    Parameters:\n        df1: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table (see [register_vcf](api.md#polars_bio.register_vcf)). CSV with a header, BED and Parquet are supported.\n        df2: Can be a path to a file, a polars DataFrame, or a pandas DataFrame or a registered table. CSV with a header, BED  and Parquet are supported.\n        use_zero_based: By default **1-based** coordinates system is used, as all input file readers use 1-based coordinates. If enabled, 0-based is used instead and end user is responsible for ensuring that both datasets follow this coordinates system.\n        cols1: The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        cols2:  The names of columns containing the chromosome, start and end of the\n            genomic intervals, provided separately for each set.\n        suffixes: Suffixes for the columns of the two overlapped sets.\n        on_cols: List of additional column names to join on. default is None.\n        algorithm: The algorithm to use for the overlap operation. Available options: Coitrees, IntervalTree, ArrayIntervalTree, Lapper, SuperIntervals\n        low_memory: If True, use low memory method for output generation. This may be slower but uses less memory.\n        output_type: Type of the output. default is \"polars.LazyFrame\", \"polars.DataFrame\", or \"pandas.DataFrame\" or \"datafusion.DataFrame\" are also supported.\n        read_options1: Additional options for reading the input files.\n        read_options2: Additional options for reading the input files.\n        projection_pushdown: Enable column projection pushdown to optimize query performance by only reading the necessary columns at the DataFusion level.\n\n    Returns:\n        **polars.LazyFrame** or polars.DataFrame or pandas.DataFrame of the overlapping intervals.\n\n    Note:\n        1. The default output format, i.e.  [LazyFrame](https://docs.pola.rs/api/python/stable/reference/lazyframe/index.html), is recommended for large datasets as it supports output streaming and lazy evaluation.\n        This enables efficient processing of large datasets without loading the entire output dataset into memory.\n        2. Streaming is only supported for polars.LazyFrame output.\n\n    Example:\n        ```python\n        import polars_bio as pb\n        import pandas as pd\n\n        df1 = pd.DataFrame([\n            ['chr1', 1, 5],\n            ['chr1', 3, 8],\n            ['chr1', 8, 10],\n            ['chr1', 12, 14]],\n        columns=['chrom', 'start', 'end']\n        )\n\n        df2 = pd.DataFrame(\n        [['chr1', 4, 8],\n         ['chr1', 10, 11]],\n        columns=['chrom', 'start', 'end' ]\n        )\n        overlapping_intervals = pb.overlap(df1, df2, output_type=\"pandas.DataFrame\")\n\n        overlapping_intervals\n            chrom_1         start_1     end_1 chrom_2       start_2  end_2\n        0     chr1            1          5     chr1            4          8\n        1     chr1            3          8     chr1            4          8\n\n        ```\n\n    Todo:\n         Support for on_cols.\n    \"\"\"\n\n    _validate_overlap_input(\n        cols1, cols2, on_cols, suffixes, output_type, use_zero_based\n    )\n\n    cols1 = DEFAULT_INTERVAL_COLUMNS if cols1 is None else cols1\n    cols2 = DEFAULT_INTERVAL_COLUMNS if cols2 is None else cols2\n    range_options = RangeOptions(\n        range_op=RangeOp.Overlap,\n        filter_op=FilterOp.Weak if not use_zero_based else FilterOp.Strict,\n        suffixes=suffixes,\n        columns_1=cols1,\n        columns_2=cols2,\n        overlap_alg=algorithm,\n        overlap_low_memory=low_memory,\n    )\n\n    return range_operation(\n        df1,\n        df2,\n        range_options,\n        output_type,\n        ctx,\n        read_options1,\n        read_options2,\n        projection_pushdown,\n    )\n</code></pre>"},{"location":"api/#polars_bio.set_loglevel","title":"<code>set_loglevel(level)</code>","text":"<p>Set the log level for the logger and root logger.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>The log level to set. Can be \"debug\", \"info\", \"warn\", or \"warning\".</p> required <p>Note</p> <p>Please note that the log level should be set as a first step after importing the library. Once set it can be only decreased, not increased. In order to increase the log level, you need to restart the Python session. </p><pre><code>import polars_bio as pb\npb.set_loglevel(\"info\")\n</code></pre><p></p> Source code in <code>polars_bio/logging.py</code> <pre><code>def set_loglevel(level: str):\n    \"\"\"\n    Set the log level for the logger and root logger.\n\n    Parameters:\n        level: The log level to set. Can be \"debug\", \"info\", \"warn\", or \"warning\".\n\n    !!! note\n        Please note that the log level should be set as a **first** step after importing the library.\n        Once set it can be only **decreased**, not increased. In order to increase the log level, you need to restart the Python session.\n        ```python\n        import polars_bio as pb\n        pb.set_loglevel(\"info\")\n        ```\n    \"\"\"\n    level = level.lower()\n    if level == \"debug\":\n        logger.setLevel(logging.DEBUG)\n        root_logger.setLevel(logging.DEBUG)\n        logging.basicConfig(level=logging.DEBUG)\n    elif level == \"info\":\n        logger.setLevel(logging.INFO)\n        root_logger.setLevel(logging.INFO)\n        logging.basicConfig(level=logging.INFO)\n    elif level == \"warn\" or level == \"warning\":\n        logger.setLevel(logging.WARN)\n        root_logger.setLevel(logging.WARN)\n        logging.basicConfig(level=logging.WARN)\n    else:\n        raise ValueError(f\"{level} is not a valid log level\")\n</code></pre>"},{"location":"contact/","title":"\ud83d\udce1 Contact","text":""},{"location":"contact/#contact-us","title":"Contact Us","text":"<p>You can drop us an email and join Discord to introduce yourself and ask questions.</p>"},{"location":"faq/","title":"\u2753 FAQ","text":"<ol> <li> <p>What versions of Polars are supported?</p> <p>Short answer: Polars == 1.29.0 is supported.</p> <p>Long answer: We recommend handling most of the heavy lifting on the DataFusion side (e.g., using SQL and views) and relying on Polars\u2019 streaming capabilities primarily for projection, filtering and sinking results. Right now, Polars 1.29.0 is the last version that supports pyo3 0.24.x that is required by DataFusion. With the most recet version of polars-bio (0.13.0) we migrated to the Polars new streaming engine.</p> </li> <li> <p>What to do if I get  <code>Illegal instruction (core dumped)</code> when using polars-bio? This error is likely due to the fact that the ABI of the polars-bio wheel package does not match the ABI of the Python interpreter. To fix this, you can build the wheel package from source. See Quickstart for more information. </p><pre><code>#/var/log/syslog\n\npolars-bio-intel kernel: [ 1611.175045] traps: python[8844] trap invalid opcode ip:709d3ec253cc sp:7ffcc28754e8 error:0 in polars_bio.abi3.so[709d36533000+9aab000]\n</code></pre><p></p> </li> <li> <p>How to build the documentation?    To build the documentation, you need to install the <code>polars-bio</code> package and then run the following command in the root directory of the repository: </p><pre><code>MKDOCS_EXPORTER_PDF=false JUPYTER_PLATFORM_DIRS=1 mkdocs serve  -w polars_bio\n</code></pre> Some pages of the documentation take a while to build\u2014to speed up the process, you can disable dynamic content rendering: <pre><code>MKDOCS_EXPORTER_PDF=false ENABLE_MD_EXEC=false ENABLE_MKDOCSTRINGS=false ENABLE_JUPYTER=false JUPYTER_PLATFORM_DIRS=1 mkdocs serve\n</code></pre><p></p> </li> <li> <p>How to build the source code and install in the current virtual environment? </p><pre><code>RUSTFLAGS=\"-Ctarget-cpu=native\" maturin develop --release  -m Cargo.toml\n</code></pre><p></p> </li> <li> <p>How to run the integration tests?    To run the integration tests, you need to have the <code>azure-cli</code>, <code>docker</code>, and <code>pytest</code> installed. Then, you can run the following commands: </p><pre><code>cd it\nsource bin/start.sh\nJUPYTER_PLATFORM_DIRS=1 pytest it_object_storage_io.py -o log_cli=true --log-cli-level=INFO\nsource bin/stop.sh\n</code></pre> Check the <code>README</code> in <code>it</code> directory for more information.<p></p> </li> </ol>"},{"location":"features/","title":"\ud83d\udd28Features","text":""},{"location":"features/#genomic-ranges-operations","title":"Genomic ranges operations","text":"Features Bioframe polars-bio PyRanges Pybedtools PyGenomics GenomicRanges overlap nearest count_overlaps cluster merge complement coverage expand sort read_table <p>Limitations</p> <p>For now polars-bio uses <code>int32</code> positions encoding for interval operations (issue) meaning that it does not support operation on chromosomes longer than 2Gb. <code>int64</code> support is planned for future releases (issue).</p>"},{"location":"features/#coordinate-systems-support","title":"Coordinate systems support","text":"<p>polars-bio supports both 0-based and 1-based coordinate systems for genomic ranges operations. By default, it uses 1-based coordinates system, for both reading bioinformatic input files (with methods <code>read_*</code> or <code>register_*</code> based on noodles that is 1-based, please refer to issue and issue and issue for more details)  and all interval operations. If your data is in 0-based coordinates, you can set the <code>use_zero_based</code> parameter to <code>True</code> in the interval functions, e.g. overlap or nearest. This parameter can be especially useful when migrating your pipeline that used 0-based tools, such as for instance Bioframe. In such case, a warning message will be printed to the console, indicating that the coordinates are 0-based and end user is responsible for ensuring that the coordinates are 0-based.</p>"},{"location":"features/#api-comparison-between-libraries","title":"API comparison between libraries","text":"<p>There is no standard API for genomic ranges operations in Python. This table compares the API of the libraries. The table is not exhaustive and only shows the most common operations used in benchmarking.</p> operation Bioframe polars-bio PyRanges0 PyRanges1 Pybedtools GenomicRanges overlap overlap overlap join<sup>1</sup> join_ranges intersect<sup>2</sup> find_overlaps<sup>3</sup> nearest closest nearest nearest nearest closest<sup>4</sup> nearest<sup>5</sup> read_table read_table read_table read_bed read_bed BedTool read_bed <p>Note</p> <ol> <li>There is an overlap method in PyRanges, but its output is only limited to indices of intervals from the other Dataframe that overlap. In Bioframe's benchmark also join method instead of overlap was used.</li> <li>wa and wb options used to obtain a comparable output.</li> <li>Output contains only a list with the same length as query, containing hits to overlapping indices. Data transformation is required to obtain the same output as in other libraries.   Since the performance was far worse than in more efficient libraries anyway, additional data transformation was not included in the benchmark.</li> <li>s=first was used to obtain a comparable output.</li> <li>select=\"arbitrary\" was used to obtain a comparable output.</li> </ol>"},{"location":"features/#file-formats-support","title":"File formats support","text":"<p>For bioinformatic format there are always three methods available: <code>read_*</code> (eager), <code>scan_*</code> (lazy) and <code>register_*</code> that can be used to either read file into Polars DataFrame/LazyFrame or register it as a DataFusion table for further processing using SQL or builtin interval methods. In either case, local and or cloud storage files can be used as an input. Please refer to cloud storage section for more details.</p> Format Single-threaded Parallel Limit pushdown Predicate pushdown Projection pushdown BED \u274c \u274c \u274c VCF BAM \u274c \u274c \u274c CRAM \u274c \u274c \u274c FASTQ \u274c \u274c FASTA \u274c \u274c \u274c GFF3"},{"location":"features/#sql-powered-data-processing","title":"SQL-powered data processing","text":"<p>polars-bio provides a SQL-like API for bioinformatic data querying or manipulation. Check SQL reference for more details.</p> <pre><code>import polars_bio as pb\npb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad_sv\", thread_num=1, info_fields=[\"SVTYPE\", \"SVLEN\"])\npb.sql(\"SELECT * FROM gnomad_sv WHERE SVTYPE = 'DEL' AND SVLEN &gt; 1000\").limit(3).collect()\n</code></pre> <pre><code>shape: (3, 10)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 chrom \u2506 start \u2506 end   \u2506 id                             \u2506 \u2026 \u2506 qual  \u2506 filter     \u2506 svtype \u2506 svlen \u2502\n\u2502 ---   \u2506 ---   \u2506 ---   \u2506 ---                            \u2506   \u2506 ---   \u2506 ---        \u2506 ---    \u2506 ---   \u2502\n\u2502 str   \u2506 u32   \u2506 u32   \u2506 str                            \u2506   \u2506 f64   \u2506 str        \u2506 str    \u2506 i32   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 chr1  \u2506 22000 \u2506 30000 \u2506 gnomAD-SV_v3_DEL_chr1_fa103016 \u2506 \u2026 \u2506 999.0 \u2506 HIGH_NCR   \u2506 DEL    \u2506 8000  \u2502\n\u2502 chr1  \u2506 40000 \u2506 47000 \u2506 gnomAD-SV_v3_DEL_chr1_b26f63f7 \u2506 \u2026 \u2506 145.0 \u2506 PASS       \u2506 DEL    \u2506 7000  \u2502\n\u2502 chr1  \u2506 79086 \u2506 88118 \u2506 gnomAD-SV_v3_DEL_chr1_733c4ef0 \u2506 \u2026 \u2506 344.0 \u2506 UNRESOLVED \u2506 DEL    \u2506 9032  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can use view mechanism to create a virtual table from a DataFrame that contain preprocessing steps and reuse it in multiple steps. To avoid materializing the intermediate results in memory, you can run your processing in  streaming mode.</p>"},{"location":"features/#parallel-engine","title":"Parallel engine \ud83c\udfce\ufe0f","text":"<p>It is straightforward to parallelize operations in polars-bio. The library is built on top of Apache DataFusion  you can set the degree of parallelism using the <code>datafusion.execution.target_partitions</code> option, e.g.: </p><pre><code>import polars_bio as pb\npb.set_option(\"datafusion.execution.target_partitions\", \"8\")\n</code></pre><p></p> <p>Tip</p> <ol> <li>The default value is 1 (parallel execution disabled).</li> <li>The <code>datafusion.execution.target_partitions</code> option is a global setting and affects all operations in the current session.</li> <li>Check available strategies for optimal performance.</li> <li>See  the other configuration settings in the Apache DataFusion documentation.</li> </ol>"},{"location":"features/#cloud-storage","title":"Cloud storage \u2601\ufe0f","text":"<p>polars-bio supports direct streamed reading from cloud storages (e.g. S3, GCS) enabling processing large-scale genomics data without materializing in memory. It is built upon the OpenDAL project, a unified data access layer for cloud storage, which allows to read  bioinformatic file formats from various cloud storage providers. For Apache DataFusion native file formats, such as Parquet or CSV please refer to DataFusion user guide.</p>"},{"location":"features/#example","title":"Example","text":"<pre><code>import polars_bio as pb\n## Register VCF files from Google Cloud Storage that will be streamed - no need to download them to the local disk, size ~0.8TB\npb.register_vcf(\"gs://gcp-public-data--gnomad/release/2.1.1/liftover_grch38/vcf/genomes/gnomad.genomes.r2.1.1.sites.liftover_grch38.vcf.bgz\", \"gnomad_big\", allow_anonymous=True)\npb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad_sv\", allow_anonymous=True)\npb.overlap(\"gnomad_sv\", \"gnomad_big\", streaming=True).sink_parquet(\"/tmp/overlap.parquet\")\n</code></pre> It is  especially useful when combined with SQL support for preprocessing and streaming processing capabilities. <p>Tip</p> <p>If you access cloud storage with authentication provided, please make sure the <code>allow_anonymous</code> parameter is set to <code>False</code> in the read/describe/register_table functions.</p>"},{"location":"features/#supported-features","title":"Supported features","text":"Feature AWS S3 Google Cloud Storage Azure Blob Storage Anonymous access Authenticated access Requester Pays Concurrent requests<sup>1</sup> Streaming reads <p>Note</p> <p><sup>1</sup>For more information on concurrent requests and block size tuning please refer to issue.</p>"},{"location":"features/#aws-s3-configuration","title":"AWS S3 configuration","text":"<p>Supported environment variables:</p> Variable Description AWS_ACCESS_KEY_ID AWS access key ID for authenticated access to S3. AWS_SECRET_ACCESS_KEY AWS secret access key for authenticated access to S3. AWS_ENDPOINT_URL Custom S3 endpoint URL for accessing S3-compatible storage. AWS_REGION  or AWS_DEFAULT_REGION AWS region for accessing S3."},{"location":"features/#google-cloud-storage-configuration","title":"Google Cloud Storage configuration","text":"<p>Supported environment variables:</p> Variable Description GOOGLE_APPLICATION_CREDENTIALS Path to the Google Cloud service account key file for authenticated access to GCS."},{"location":"features/#azure-blob-storage-configuration","title":"Azure Blob Storage configuration","text":"<p>Supported environment variables:</p> Variable Description AZURE_STORAGE_ACCOUNT Azure Storage account name for authenticated access to Azure Blob Storage. AZURE_STORAGE_KEY Azure Storage account key for authenticated access to Azure Blob Storage. AZURE_ENDPOINT_URL Azure Blob Storage endpoint URL for accessing Azure Blob Storage."},{"location":"features/#streaming","title":"Streaming \ud83d\ude82","text":"<p>polars-bio supports out-of-core processing with Apache DataFusion async streams and Polars LazyFrame streaming option. It can bring  significant speedup as well reduction in memory usage allowing to process large datasets that do not fit in memory. See our benchmark results. There are 2 ways of using streaming mode:</p> <ol> <li> <p>By setting the <code>output_type</code> to <code>datafusion.DataFrame</code> and using the Python DataFrame API, including methods such as count, write_parquet or write_csv or write_json. In this option you completely bypass the polars streaming engine.</p> <p><code>python import polars_bio as pb import polars as pl pb.overlap(\"/tmp/gnomad.v4.1.sv.sites.parquet\", \"/tmp/gnomad.exomes.v4.1.sites.chr1.parquet\", output_type=\"datafusion.DataFrame\").write_parquet(\"/tmp/overlap.parquet\") pl.scan_parquet(\"/tmp/overlap.parquet\").collect().count()</code> </p><pre><code> shape: (1, 6)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 chrom_1    \u2506 start_1    \u2506 end_1      \u2506 chrom_2    \u2506 start_2    \u2506 end_2      \u2502\n \u2502 ---        \u2506 ---        \u2506 ---        \u2506 ---        \u2506 ---        \u2506 ---        \u2502\n \u2502 u32        \u2506 u32        \u2506 u32        \u2506 u32        \u2506 u32        \u2506 u32        \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 2629727337 \u2506 2629727337 \u2506 2629727337 \u2506 2629727337 \u2506 2629727337 \u2506 2629727337 \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre><p></p> <p>Tip</p> <p>If you only need to write the results as fast as possible into one of the above file formats or quickly get the row count, then it is in the most cases the best option.</p> </li> <li> <p>Using polars new streaming engine:</p> <pre><code>import os\nimport polars_bio as pb\nos.environ['BENCH_DATA_ROOT'] = \"/Users/mwiewior/research/data/databio\"\nos.environ['POLARS_VERBOSE'] = \"1\"\n\ncols=[\"contig\", \"pos_start\", \"pos_end\"]\nBENCH_DATA_ROOT = os.getenv('BENCH_DATA_ROOT', '/data/bench_data/databio')\ndf_1 = f\"{BENCH_DATA_ROOT}/exons/*.parquet\"\ndf_2 =  f\"{BENCH_DATA_ROOT}/exons/*.parquet\"\npb.overlap(df_1, df_2, cols1=cols, cols2=cols).collect(engine=\"streaming\").limit()\n</code></pre> <pre><code>1652814rows [00:00, 20208793.67rows/s]\n[MultiScanState]: Readers disconnected\npolars-stream: done running graph phase\npolars-stream: updating graph state\nshape: (5, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 contig_1 \u2506 pos_start_1 \u2506 pos_end_1 \u2506 contig_2 \u2506 pos_start_2 \u2506 pos_end_2 \u2502\n\u2502 ---      \u2506 ---         \u2506 ---       \u2506 ---      \u2506 ---         \u2506 ---       \u2502\n\u2502 str      \u2506 i32         \u2506 i32       \u2506 str      \u2506 i32         \u2506 i32       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 chr1     \u2506 11873       \u2506 12227     \u2506 chr1     \u2506 11873       \u2506 12227     \u2502\n\u2502 chr1     \u2506 12612       \u2506 12721     \u2506 chr1     \u2506 12612       \u2506 12721     \u2502\n\u2502 chr1     \u2506 13220       \u2506 14409     \u2506 chr1     \u2506 13220       \u2506 14409     \u2502\n\u2502 chr1     \u2506 13220       \u2506 14409     \u2506 chr1     \u2506 14361       \u2506 14829     \u2502\n\u2502 chr1     \u2506 14361       \u2506 14829     \u2506 chr1     \u2506 13220       \u2506 14409     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </li> </ol> <p>Parallellism can be controlled using the <code>datafusion.execution.target_partitions</code>option as described in the parallel engine section (compare the row/s metric in the following examples).</p> <p></p><pre><code> pb.set_option(\"datafusion.execution.target_partitions\", \"1\")\n pb.overlap(df_1, df_2, cols1=cols, cols2=cols).collect(engine=\"streaming\").count()\n</code></pre> <pre><code> 1652814rows [00:00, 19664163.99rows/s]\n shape: (1, 6)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 contig_1 \u2506 pos_start_1 \u2506 pos_end_1 \u2506 contig_2 \u2506 pos_start_2 \u2506 pos_end_2 \u2502\n \u2502 ---      \u2506 ---         \u2506 ---       \u2506 ---      \u2506 ---         \u2506 ---       \u2502\n \u2502 u32      \u2506 u32         \u2506 u32       \u2506 u32      \u2506 u32         \u2506 u32       \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 1652814  \u2506 1652814     \u2506 1652814   \u2506 1652814  \u2506 1652814     \u2506 1652814   \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code> pb.set_option(\"datafusion.execution.target_partitions\", \"2\")\n pb.overlap(df_1, df_2, cols1=cols, cols2=cols).collect(engine=\"streaming\").count()\n</code></pre><p></p> <pre><code> 1652814rows [00:00, 27841987.75rows/s]\n shape: (1, 6)\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 contig_1 \u2506 pos_start_1 \u2506 pos_end_1 \u2506 contig_2 \u2506 pos_start_2 \u2506 pos_end_2 \u2502\n \u2502 ---      \u2506 ---         \u2506 ---       \u2506 ---      \u2506 ---         \u2506 ---       \u2502\n \u2502 u32      \u2506 u32         \u2506 u32       \u2506 u32      \u2506 u32         \u2506 u32       \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 1652814  \u2506 1652814     \u2506 1652814   \u2506 1652814  \u2506 1652814     \u2506 1652814   \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"features/#compression","title":"Compression","text":"<p>polars-bio supports GZIP ( default file extension <code>*.gz</code>) and Block GZIP (BGZIP, default file extension <code>*.bgz</code>) when reading files from local and cloud storages. For BGZIP it is possible to parallelize decoding of compressed blocks to substantially speedup reading VCF, FASTQ or GFF files by increasing <code>thread_num</code> parameter. Please take a look at the following GitHub discussion.</p>"},{"location":"features/#dataframes-support","title":"DataFrames support","text":"I/O Bioframe polars-bio PyRanges Pybedtools PyGenomics GenomicRanges Pandas DataFrame Polars DataFrame Polars LazyFrame Native readers"},{"location":"performance/","title":"\ud83d\ude80 Performance","text":""},{"location":"performance/#results-summary","title":"Results summary \ud83d\udcc8","text":""},{"location":"performance/#current-performance","title":"Current Performance \ud83d\udd25","text":"<p>Latest Benchmark Comparison: View Interactive Performance Report</p> <p>The benchmark comparison shows performance across three key operations (overlap, nearest, count_overlaps) comparing polars-bio against alternative tools (pyranges1, genomicranges, bioframe). Updated automatically on each release.</p>"},{"location":"performance/#single-thread-performance","title":"Single-thread performance \ud83c\udfc3\u200d","text":""},{"location":"performance/#parallel-performance","title":"Parallel performance \ud83c\udfc3\u200d\ud83c\udfc3\u200d","text":""},{"location":"performance/#benchmarks","title":"Benchmarks \ud83e\uddea","text":""},{"location":"performance/#detailed-results-shortcuts","title":"Detailed results shortcuts \ud83d\udc68\u200d\ud83d\udd2c","text":"<ul> <li>Binary operations</li> <li>Parallel execution and scalability</li> <li>Memory characteristics</li> <li>DataFrame formats performance</li> </ul>"},{"location":"performance/#test-datasets","title":"Test datasets \ud83d\uddc3\ufe0f","text":"<p>AIList dataset was used for benchmarking.</p> Dataset# Name Size(x1000) Non-flatness 0 chainRn4 2,351 6 1 fBrain 199 1 2 exons 439 2 3 chainOrnAna1 1,957 6 4 chainVicPac2 7,684 8 5 chainXenTro3Link 50,981 7 6 chainMonDom5Link 128,187 7 7 ex-anno 1,194 2 8 ex-rna 9,945 7 <p>Note</p> <p>Test dataset in Parquet format can be downloaded from:</p> <ul> <li>for single-thread tests</li> <li>for parallel tests (8 partitions per dataset)</li> </ul>"},{"location":"performance/#test-libraries","title":"Test libraries \ud83d\udcda","text":"<ul> <li>Bioframe-0.7.2</li> <li>PyRanges0-0.0.132</li> <li>PyRanges1-e634a11</li> <li>pybedtools-0.10.0</li> <li>PyGenomics-0.1.1</li> <li>GenomicRanges-0.5.0</li> </ul> <p>Note</p> <p>Some tests were not conducted for all libraries in case of poor performance of specific tools, e.g. <code>pybedtools</code>, <code>PyGenomics</code> and <code>GenomicRanges</code> for the largest outputs.</p>"},{"location":"performance/#output-compatibility","title":"Output compatibility \ud83d\udda5\ufe0f","text":"<p>See API comparison for more details on parameters used in the benchmark.</p>"},{"location":"performance/#binary-operations","title":"Binary operations","text":""},{"location":"performance/#overlap-operation","title":"Overlap operation","text":"<p>Test cases were categorized based on the size \ud83d\udc55 of the input datasets and the expected output size into the following groups:</p> <ul> <li>S-size: output &lt; 1,000,000</li> <li>M-size: 1,000,000 &lt; output &lt; 100,000,000</li> <li>L-size: 100,000,000 &lt; output &lt; 1,000,000,000</li> <li>XL-size: output &gt; 1,000,000,000</li> </ul> <p>Tip</p> <ol> <li>Naming convention for the test cases is as follows <code>test-case-size (dataset-1-id, dataset-2-id)</code>, e.g.: <code>S-size (1-2)</code>, where <code>1</code> and <code>2</code> are the indices of the datasets used in the test case.</li> <li>In the case of all but polars-bio native reader the reported timings exclude the time to read the data from disk and do the required preprocessing (e.g. Python object creation) and column mappings.</li> </ol>"},{"location":"performance/#apple-silicon-macos","title":"Apple Silicon (macOS) \ud83c\udf4e","text":"<p>Here is the configuration of the Apple Silicon machine used for benchmarking:</p> <ul> <li>cpu architecture: <code>arm64</code></li> <li>cpu name: <code>Apple M3 Max</code></li> <li>cpu cores: <code>16</code></li> <li>memory: <code>64 GB</code></li> <li>kernel: <code>Darwin Kernel Version 24.2.0: Fri Dec  6 19:02:12 PST 2024; root:xnu-11215.61.5~2/RELEASE_ARM64_T6031</code></li> <li>system: <code>Darwin</code></li> <li>os-release: <code>macOS-15.2-arm64-arm-64bit</code></li> <li>python: <code>3.12.4</code></li> <li>polars-bio: <code>0.3.0</code></li> </ul>"},{"location":"performance/#s-size","title":"S-size","text":""},{"location":"performance/#s-size-1-2","title":"S-size (1-2)","text":"<p>Output size: 54,246</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.100738 0.101541 0.101119 0.25x polars_bio 0.032156 0.035501 0.033394 0.77x pyranges0 0.024100 0.028271 0.025589 1.00x pyranges1 0.053770 0.054647 0.054121 0.47x pybedtools0 0.281969 0.283385 0.282857 0.09x pygenomics 1.424975 1.436369 1.430531 0.02x genomicranges 0.972717 0.979013 0.975761 0.03x"},{"location":"performance/#s-size-2-7","title":"S-size (2-7)","text":"<p>Output size: 273,500</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.298039 0.309271 0.302905 0.30x polars_bio 0.089324 0.092200 0.090332 1.00x pyranges0 0.096478 0.103456 0.101023 0.89x pyranges1 0.195621 0.198025 0.197146 0.46x pybedtools0 1.004577 1.013097 1.007701 0.09x pygenomics 4.264575 4.275965 4.269055 0.02x genomicranges 2.919675 2.926785 2.923549 0.03x"},{"location":"performance/#s-size-1-0","title":"S-size (1-0)","text":"<p>Output size: 320,955</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.521093 0.549674 0.534084 0.28x polars_bio 0.135411 0.168570 0.147222 1.00x pyranges0 0.271539 0.282081 0.276298 0.53x pyranges1 0.418972 0.426373 0.422060 0.35x pybedtools0 1.258828 1.269215 1.264674 0.12x pygenomics 7.877381 7.908531 7.894108 0.02x genomicranges 4.222082 4.266592 4.244865 0.03x"},{"location":"performance/#m-size","title":"M-size","text":""},{"location":"performance/#m-size-7-0","title":"M-size (7-0)","text":"<p>Output size: 2,761,621</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.935141 0.990710 0.970345 0.22x polars_bio 0.213880 0.220151 0.216288 1.00x pyranges0 0.408637 0.434262 0.422380 0.51x pyranges1 0.632015 0.642214 0.635670 0.34x pybedtools0 6.415976 6.467304 6.444268 0.03x pygenomics 9.588232 9.705035 9.653368 0.02x genomicranges 9.017886 9.058916 9.033964 0.02x"},{"location":"performance/#m-size-7-3","title":"M-size (7-3)","text":"<p>Output size: 4,408,383</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.954765 0.969307 0.959704 0.21x polars_bio 0.198607 0.208906 0.203033 1.00x pyranges0 0.425277 0.430527 0.428594 0.47x pyranges1 0.696934 0.710050 0.702206 0.29x pybedtools0 9.403818 9.491574 9.453402 0.02x pygenomics 8.638968 8.662197 8.647764 0.02x genomicranges 10.514233 10.556004 10.540377 0.02x"},{"location":"performance/#l-size","title":"L-size","text":""},{"location":"performance/#l-size-0-8","title":"L-size (0-8)","text":"<p>Output size: 164,196,784</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 15.630508 16.719793 16.080009 0.19x polars_bio 2.882900 3.135100 2.997755 1.00x pyranges0 9.276095 10.158109 9.761880 0.31x pyranges1 13.076820 13.510234 13.329948 0.22x pybedtools0 322.922915 335.123071 329.659142 0.01x pygenomics 128.849536 132.109689 130.089096 0.02x genomicranges 234.237435 239.315157 236.504565 0.01x"},{"location":"performance/#l-size-4-8","title":"L-size (4-8)","text":"<p>Output size: 227,832,153</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 22.911206 23.118100 23.030572 0.16x polars_bio 3.541325 3.937760 3.684317 1.00x pyranges0 13.035069 13.510203 13.225005 0.28x pyranges1 20.924921 21.657297 21.398281 0.17x pybedtools0 505.897157 521.239276 511.310686 0.01x pygenomics 159.883847 160.942329 160.306970 0.02x genomicranges 322.217280 322.490391 322.371662 0.01x"},{"location":"performance/#l-size-7-8","title":"L-size (7-8)","text":"<p>Output size: 307,184,634</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 29.128664 29.993182 29.518215 0.12x polars_bio 3.260438 3.897260 3.489278 1.00x pyranges0 16.615283 16.983202 16.753369 0.21x pyranges1 30.504657 30.912445 30.752887 0.11x pybedtools0 555.480532 559.947421 556.986772 0.01x pygenomics 156.724420 157.321514 156.935424 0.02x genomicranges 416.095573 417.284236 416.700000 0.01x"},{"location":"performance/#xl-size","title":"XL-size","text":""},{"location":"performance/#xl-size-3-0","title":"XL-size (3-0)","text":"<p>Output size: 1,086,692,495</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 124.244987 126.569689 125.435831 0.12x polars_bio 12.650240 15.858913 14.776997 1.00x pyranges0 85.652054 94.383934 88.712706 0.17x pyranges1 92.802026 94.400313 93.447716 0.16x"},{"location":"performance/#amd-genoa-linux","title":"AMD Genoa (Linux) \ud83d\udc27","text":"<p>c3d-highmem-8 machine was used for benchmarking.</p> <ul> <li>cpu architecture: <code>x86_64</code></li> <li>cpu name: <code>AMD EPYC 9B14</code></li> <li>cpu cores: <code>4</code></li> <li>memory: <code>63 GB</code></li> <li>kernel: <code>#22~22.04.1-Ubuntu SMP Mon Dec  9 20:42:57 UTC 2024</code></li> <li>system: <code>Linux</code></li> <li>os-release: <code>Linux-6.8.0-1020-gcp-x86_64-with-glibc2.35</code></li> <li>python: <code>3.12.8</code></li> <li>polars-bio: <code>0.3.0</code></li> </ul>"},{"location":"performance/#s-size_1","title":"S-size","text":""},{"location":"performance/#s-size-1-2_1","title":"S-size (1-2)","text":"<p>Output size: 54,246</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.094509 0.095311 0.094797 0.61x polars_bio 0.058527 0.066444 0.061503 0.95x pyranges0 0.057583 0.059461 0.058245 1.00x pyranges1 0.098868 0.107992 0.101964 0.57x pybedtools0 0.382701 0.384930 0.383619 0.15x pygenomics 2.335400 2.340616 2.338876 0.02x genomicranges 1.648289 1.663941 1.657652 0.04x"},{"location":"performance/#s-size-2-7_1","title":"S-size (2-7)","text":"<p>Output size: 273,500</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.273727 0.275239 0.274383 0.60x polars_bio 0.161882 0.164253 0.163334 1.00x pyranges0 0.169721 0.171931 0.170678 0.96x pyranges1 0.304432 0.323747 0.311284 0.52x pybedtools0 1.477541 1.478301 1.477841 0.11x pygenomics 6.929725 6.932875 6.931662 0.02x genomicranges 5.096514 5.105638 5.100280 0.03x"},{"location":"performance/#s-size-1-0_1","title":"S-size (1-0)","text":"<p>Output size: 320,955</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.457869 0.460473 0.459397 0.55x polars_bio 0.251083 0.252582 0.251673 1.00x pyranges0 0.365083 0.376212 0.369148 0.68x pyranges1 0.593858 0.605304 0.600537 0.42x pybedtools0 1.834958 1.858740 1.844379 0.14x pygenomics 12.730241 12.771149 12.756920 0.02x genomicranges 7.090998 7.121029 7.107298 0.04x"},{"location":"performance/#m-size_1","title":"M-size","text":""},{"location":"performance/#m-size-7-0_1","title":"M-size (7-0)","text":"<p>Output size: 2,761,621</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.873343 0.875288 0.874457 0.50x polars_bio 0.420260 0.450565 0.433827 1.00x pyranges0 0.559251 0.564516 0.561273 0.77x pyranges1 1.876350 1.888463 1.880867 0.23x pybedtools0 10.379844 10.430488 10.404292 0.04x pygenomics 15.553783 15.567857 15.562953 0.03x genomicranges 15.517461 15.548186 15.535206 0.03x"},{"location":"performance/#m-size-7-3_1","title":"M-size (7-3)","text":"<p>Output size: 4,408,383</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 1.022998 1.028002 1.024980 0.40x polars_bio 0.397203 0.426743 0.412704 1.00x pyranges0 0.590809 0.602570 0.594928 0.69x pyranges1 2.027123 2.074861 2.045372 0.20x pybedtools0 15.957823 16.006681 15.988963 0.03x pygenomics 13.983596 13.994300 13.990662 0.03x genomicranges 18.602139 18.625446 18.615777 0.02x"},{"location":"performance/#l-size_1","title":"L-size","text":""},{"location":"performance/#l-size-0-8_1","title":"L-size (0-8)","text":"<p>Output size: 164,196,784</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 21.459718 21.516023 21.480410 0.29x polars_bio 5.713430 6.952107 6.129996 1.00x pyranges0 15.898455 16.227408 16.011707 0.38x pyranges1 21.721230 22.272518 21.917855 0.28x pybedtools0 575.612739 578.021023 577.165597 0.01x pygenomics 244.510614 245.508453 245.063967 0.03x genomicranges 440.650408 440.737924 440.706206 0.01x"},{"location":"performance/#l-size-4-8_1","title":"L-size (4-8)","text":"<p>Output size: 227,832,153</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 29.460466 29.864740 29.633731 0.34x polars_bio 9.731893 10.180046 9.968996 1.00x pyranges0 21.637592 22.724399 22.011753 0.45x pyranges1 37.035666 37.531010 37.218867 0.27x"},{"location":"performance/#l-size-7-8_1","title":"L-size (7-8)","text":"<p>Output size: 307,184,634</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 38.547761 38.593432 38.573512 0.18x polars_bio 6.356472 8.204682 6.980182 1.00x pyranges0 28.664496 28.878972 28.751498 0.24x pyranges1 80.373241 80.871479 80.546908 0.09x"},{"location":"performance/#intel-emerald-rapids-linux","title":"Intel Emerald Rapids (Linux) \ud83d\udc27","text":"<p>c4-highmem-8 machine was used for benchmarking.</p> <ul> <li>cpu architecture: <code>x86_64</code></li> <li>cpu name: <code>INTEL(R) XEON(R) PLATINUM 8581C CPU @ 2.30GHz</code></li> <li>cpu cores: <code>22</code></li> <li>memory: <code>86 GB</code></li> <li>kernel: <code>#27~22.04.1-Ubuntu SMP Tue Jul 16 23:03:39 UTC 2024</code></li> <li>system: <code>Linux</code></li> <li>os-release: <code>Linux-6.5.0-1025-gcp-x86_64-with-glibc2.35</code></li> <li>python: <code>3.12.8</code></li> <li>polars-bio: <code>0.3.0</code></li> </ul>"},{"location":"performance/#s-size_2","title":"S-size","text":""},{"location":"performance/#s-size-1-2_2","title":"S-size (1-2)","text":"<p>Output size: 54,246</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.080274 0.083350 0.082125 0.67x polars_bio 0.051923 0.060853 0.055115 1.00x pyranges0 0.057737 0.063692 0.060233 0.92x pyranges1 0.092273 0.104232 0.096598 0.57x pybedtools0 0.342928 0.350446 0.345739 0.16x pygenomics 1.933479 1.980263 1.958915 0.03x genomicranges 1.317808 1.365975 1.345268 0.04x"},{"location":"performance/#s-size-2-7_2","title":"S-size (2-7)","text":"<p>Output size: 273,500</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.242910 0.250233 0.246872 0.59x polars_bio 0.142933 0.151324 0.146654 1.00x pyranges0 0.181919 0.184524 0.183063 0.80x pyranges1 0.303359 0.305036 0.304166 0.48x pybedtools0 1.303765 1.318575 1.310322 0.11x pygenomics 5.744573 5.917737 5.816145 0.03x genomicranges 4.202981 4.298941 4.243175 0.03x"},{"location":"performance/#s-size-1-0_2","title":"S-size (1-0)","text":"<p>Output: 320,955</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.421461 0.449266 0.434152 0.53x polars_bio 0.228252 0.233000 0.230004 1.00x pyranges0 0.383663 0.401601 0.391000 0.59x pyranges1 0.563753 0.575554 0.570290 0.40x pybedtools0 1.617740 1.643310 1.631340 0.14x pygenomics 10.491757 10.753130 10.636810 0.02x genomicranges 5.806456 5.880285 5.851234 0.04x"},{"location":"performance/#m-size_2","title":"M-size","text":""},{"location":"performance/#m-size-7-0_2","title":"M-size (7-0)","text":"<p>Output: 2,761,621</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 0.900843 0.928098 0.917930 0.43x polars_bio 0.380828 0.408791 0.390157 1.00x pyranges0 0.580401 0.607483 0.595004 0.66x pyranges1 1.697365 1.705109 1.699965 0.23x pybedtools0 9.120270 9.384526 9.211789 0.04x pygenomics 13.123205 13.179993 13.160740 0.03x genomicranges 13.230635 13.690668 13.472020 0.03x"},{"location":"performance/#m-size-7-3_2","title":"M-size (7-3)","text":"<p>Output: 4,408,383</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 1.137155 1.142985 1.140749 0.35x polars_bio 0.382198 0.411443 0.396179 1.00x pyranges0 0.650236 0.675971 0.659619 0.60x pyranges1 1.818395 1.841851 1.826528 0.22x pybedtools0 14.588216 14.666769 14.621019 0.03x pygenomics 11.975859 12.196851 12.121281 0.03x genomicranges 15.640415 15.839974 15.736289 0.03x"},{"location":"performance/#l-size_2","title":"L-size","text":""},{"location":"performance/#l-size-0-8_2","title":"L-size (0-8)","text":"<p>Output: 164,196,784</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 28.818453 28.956365 28.884398 0.21x polars_bio 5.904987 6.562457 6.145784 1.00x pyranges0 22.664353 22.997717 22.806512 0.27x pyranges1 24.446387 24.804753 24.613135 0.25x"},{"location":"performance/#l-size-4-8_2","title":"L-size (4-8)","text":"<p>Output: 227,832,153</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 39.868340 40.109302 39.951601 0.25x polars_bio 9.736690 10.277895 10.021107 1.00x pyranges0 31.146222 31.290984 31.208499 0.32x pyranges1 39.407547 40.279563 39.843926 0.25x"},{"location":"performance/#l-size-7-8_2","title":"L-size (7-8)","text":"<p>Output: 307,184,634</p> Library Min (s) Max (s) Mean (s) Speedup bioframe 51.923368 52.840132 52.354141 0.14x polars_bio 6.604371 7.975253 7.151908 1.00x pyranges0 41.702499 42.557826 42.027393 0.17x pyranges1 63.524302 63.774618 63.679367 0.11x"},{"location":"performance/#sorted-input","title":"Sorted input","text":"<p>Todo</p> <ul> <li>Add sorted input benchmarks</li> </ul>"},{"location":"performance/#nearest-closest-operation","title":"Nearest (closest) operation","text":""},{"location":"performance/#apple-silicon-macos_1","title":"Apple Silicon (macOS) \ud83c\udf4e","text":""},{"location":"performance/#s-size_3","title":"S-size","text":""},{"location":"performance/#s-size-1-2_3","title":"S-size (1-2)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 0.282320 0.288275 0.285267 0.31x polars_bio 0.085046 0.091221 0.087545 1.00x pyranges0 0.131831 0.134894 0.132961 0.66x pyranges1 0.174185 0.176994 0.175650 0.50x pybedtools0 0.639068 0.648982 0.644444 0.14x"},{"location":"performance/#s-size-2-7_3","title":"S-size (2-7)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 0.819279 0.829933 0.826124 0.27x polars_bio 0.219446 0.222345 0.220642 1.00x pyranges0 0.336059 0.346129 0.339557 0.65x pyranges1 0.415821 0.425321 0.420848 0.52x pybedtools0 1.477262 1.490676 1.483696 0.15x"},{"location":"performance/#s-size-1-0_3","title":"S-size (1-0)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 1.130541 1.140416 1.134000 0.18x polars_bio 0.196717 0.208593 0.204053 1.00x pyranges0 0.705755 0.734622 0.720525 0.28x pyranges1 0.764694 0.848379 0.803320 0.25x pybedtools0 1.054003 1.106122 1.075032 0.19x"},{"location":"performance/#m-size_3","title":"M-size","text":""},{"location":"performance/#m-size-7-0_3","title":"M-size (7-0)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 2.477785 2.568602 2.509461 0.17x polars_bio 0.428317 0.444993 0.435540 1.00x pyranges0 0.776533 0.816372 0.795476 0.55x pyranges1 0.944443 0.956939 0.952353 0.46x pybedtools0 3.891626 3.920097 3.907743 0.11x"},{"location":"performance/#m-size-7-3_3","title":"M-size (7-3)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 2.753566 2.862580 2.797397 0.17x polars_bio 0.456776 0.473078 0.465653 1.00x pyranges0 0.763046 0.791106 0.773746 0.60x pyranges1 0.915549 0.943690 0.931994 0.50x pybedtools0 3.781775 3.803629 3.794066 0.12x"},{"location":"performance/#l-size_3","title":"L-size","text":""},{"location":"performance/#l-size-0-8_3","title":"L-size (0-8)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 48.211329 50.000878 49.136208 0.03x polars_bio 1.493048 1.620652 1.552847 1.00x pyranges0 3.082013 3.146659 3.116663 0.50x pyranges1 3.662140 3.706852 3.684952 0.42x pybedtools0 10.561658 10.661184 10.603403 0.15x"},{"location":"performance/#l-size-4-8_3","title":"L-size (4-8)","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.778845 1.806916 1.793131 1.00x pyranges0 4.083200 4.223863 4.162773 0.43x pyranges1 5.263221 5.281766 5.274634 0.34x pybedtools0 25.670818 25.789135 25.725079 0.07x"},{"location":"performance/#l-size-7-8_3","title":"L-size (7-8)","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.002583 1.018811 1.009884 1.00x pyranges0 2.700747 2.722101 2.712181 0.37x pyranges1 2.988758 3.026965 3.008430 0.34x pybedtools0 9.403173 9.474385 9.441718 0.11x"},{"location":"performance/#l-size-3-0","title":"L-size (3-0)","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.917404 0.924649 0.921255 0.73x pyranges0 0.648998 0.701870 0.669507 1.00x pyranges1 0.945559 0.962450 0.956495 0.70x pybedtools0 18.643435 18.860937 18.717684 0.04x"},{"location":"performance/#intel-emerald-rapids-linux_1","title":"Intel Emerald Rapids (Linux) \ud83d\udc27","text":""},{"location":"performance/#s-size_4","title":"S-size","text":""},{"location":"performance/#s-size-1-2_4","title":"S-size (1-2)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 0.166667 0.170252 0.167967 0.64x polars_bio 0.059757 0.200437 0.106731 1.00x pyranges0 0.179466 0.193530 0.187714 0.57x pyranges1 0.242658 0.249828 0.245899 0.43x pybedtools0 0.917019 0.931643 0.926433 0.12x"},{"location":"performance/#s-size-2-7_4","title":"S-size (2-7)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 0.422708 0.429339 0.426257 0.48x polars_bio 0.198758 0.213887 0.205798 1.00x pyranges0 0.416234 0.421807 0.418619 0.49x pyranges1 0.531085 0.541683 0.536459 0.38x pybedtools0 2.085108 2.086168 2.085780 0.10x"},{"location":"performance/#s-size-1-0_4","title":"S-size (1-0)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 0.563159 0.578794 0.572864 0.33x polars_bio 0.175278 0.206305 0.189767 1.00x pyranges0 0.683342 0.692020 0.687795 0.28x pyranges1 0.747615 0.754387 0.750464 0.25x pybedtools0 1.177251 1.192054 1.185509 0.16x"},{"location":"performance/#m-size_4","title":"M-size","text":""},{"location":"performance/#m-size-7-0_4","title":"M-size (7-0)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 1.200956 1.222905 1.210387 0.32x polars_bio 0.380992 0.388604 0.383601 1.00x pyranges0 0.811919 0.826886 0.821876 0.47x pyranges1 1.001142 1.039321 1.025727 0.37x pybedtools0 5.498016 5.507600 5.503549 0.07x"},{"location":"performance/#m-size-7-3_4","title":"M-size (7-3)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 1.254999 1.262944 1.259257 0.29x polars_bio 0.359952 0.380151 0.367453 1.00x pyranges0 0.772943 0.777694 0.775242 0.47x pyranges1 0.969036 0.976941 0.972361 0.38x pybedtools0 5.394985 5.454826 5.431693 0.07x"},{"location":"performance/#l-size_4","title":"L-size","text":""},{"location":"performance/#l-size-0-8_4","title":"L-size (0-8)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 21.325827 22.295620 21.664544 0.10x polars_bio 2.031079 2.123994 2.062699 1.00x pyranges0 4.146689 4.172250 4.161514 0.50x pyranges1 4.658245 5.014545 4.811681 0.43x pybedtools0 16.245615 16.445935 16.373377 0.13x"},{"location":"performance/#l-size-4-8_4","title":"L-size (4-8)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 29.156254 30.051563 29.682944 0.10x polars_bio 3.013091 3.045008 3.032196 1.00x pyranges0 5.610373 5.752500 5.693492 0.53x pyranges1 7.469939 7.503416 7.486032 0.41x pybedtools0 39.047774 39.824156 39.436474 0.08x"},{"location":"performance/#l-size-7-8_4","title":"L-size (7-8)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 39.984802 40.155487 40.065113 0.05x polars_bio 1.868242 1.878759 1.873989 1.00x pyranges0 4.016616 4.034881 4.028447 0.47x pyranges1 4.251595 4.516436 4.341912 0.43x pybedtools0 15.481021 15.533977 15.501447 0.12x"},{"location":"performance/#l-size-3-0_1","title":"L-size (3-0)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 85.826377 86.023302 85.933492 0.01x polars_bio 1.093852 1.129010 1.113706 0.79x pyranges0 0.871503 0.903123 0.883908 1.00x pyranges1 1.151087 1.200064 1.168257 0.76x pybedtools0 28.309991 28.624311 28.421618 0.03x"},{"location":"performance/#xl-size_1","title":"XL-size","text":""},{"location":"performance/#xl-size-0-4","title":"XL-size (0-4)","text":"Library Min (s) Max (s) Mean (s) Speedup bioframe 365.207028 365.455848 365.327366 0.01x polars_bio 3.553054 3.568899 3.559842 0.81x pyranges0 2.867332 2.888607 2.879132 1.00x pyranges1 3.145913 3.294060 3.227092 0.89x pybedtools0 126.338178 127.104972 126.646993 0.02x"},{"location":"performance/#xl-size-0-5","title":"XL-size (0-5)","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 15.814259 15.907476 15.845883 1.00x pyranges0 20.752479 20.837782 20.797340 0.76x pyranges1 20.315355 20.490498 20.376382 0.78x"},{"location":"performance/#parallel-execution-and-scalability","title":"Parallel execution and scalability","text":"<p>Apple Silicon and c4-standard-32 machine were used for benchmarking.</p> <ul> <li>cpu architecture: <code>x86_64</code></li> <li>cpu name: <code>INTEL(R) XEON(R) PLATINUM 8581C CPU @ 2.30GHz</code></li> <li>cpu cores: <code>16</code></li> <li>memory: <code>118 GB</code></li> <li>kernel: <code>#27~22.04.1-Ubuntu SMP Tue Jul 16 23:03:39 UTC 2024</code></li> <li>system: <code>Linux</code></li> <li>os-release: <code>Linux-6.5.0-1025-gcp-x86_64-with-glibc2.35</code></li> <li>python: <code>3.12.8</code></li> <li>polars-bio: <code>0.3.0</code></li> </ul> <p>Two strategies were used for parallel execution (<code>n</code> - degree of parallelism):</p> <ul> <li> <p><code>polars_bio-n</code>: Default, dynamic partitioning schema (median of 2 partitions/dataset) with repartitioning in DataFusion on Parquet scan and join operations: </p><pre><code>import polars_bio as pb\npb.set_option(\"datafusion.optimizer.repartition_joins\", \"true\")\npb.set_option(\"datafusion.optimizer.repartition_file_scans\", \"true\")\npb.set_option(\"datafusion.execution.coalesce_batches\", \"false\")\n</code></pre> the <code>single-thread</code> dataset was used (see Test datasets)<p></p> </li> <li> <p><code>polars_bio-n-p</code>: Custom partitioning schema (constant number of 8 partitions/dataset) without any repartitioning in DataFusion: </p><pre><code>import polars_bio as pb\npb.set_option(\"datafusion.optimizer.repartition_joins\", \"false\")\npb.set_option(\"datafusion.optimizer.repartition_file_scans\", \"false\")\npb.set_option(\"datafusion.execution.coalesce_batches\", \"false\")\n</code></pre> the <code>parallel</code> dataset was used (see Test datasets)<p></p> </li> </ul>"},{"location":"performance/#overlap-operation_1","title":"Overlap operation","text":""},{"location":"performance/#apple-silicon-macos_2","title":"Apple Silicon (macOS) \ud83c\udf4e","text":""},{"location":"performance/#0-8","title":"0-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 9.146743 10.067171 9.512946 0.31x pyranges1-1 17.084293 17.394639 17.207398 0.17x polars_bio-1 2.784917 3.184688 2.963876 1.00x polars_bio-2 1.447746 2.194926 1.716935 1.73x polars_bio-4 1.023359 1.031373 1.027862 2.88x polars_bio-8 0.745024 0.766747 0.757039 3.92x -------------- ----------- ----------- ----------- ----------- polars_bio-1-p 3.106839 3.335528 3.221183 1.00x polars_bio-2-p 1.610237 1.643171 1.626704 1.98x polars_bio-4-p 0.947643 0.948290 0.947967 3.40x polars_bio-8-p 0.579332 0.585496 0.582414 5.53x"},{"location":"performance/#7-8","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 16.015978 16.471722 16.183480 0.24x pyranges1-1 30.504657 30.912445 30.752887 0.13x polars_bio-1 3.582070 4.331780 3.930337 1.00x polars_bio-2 1.798026 1.866828 1.829596 2.15x polars_bio-4 1.126025 1.135795 1.132349 3.47x polars_bio-8 0.703821 0.707697 0.705424 5.57x -------------- ----------- ----------- ----------- ----------- polars_bio-1-p 3.862783 4.572159 4.217471 1.00x polars_bio-2-p 2.003091 2.006744 2.004917 2.10x polars_bio-4-p 1.081358 1.097517 1.089438 3.87x polars_bio-8-p 0.652152 0.653111 0.652631 6.46x"},{"location":"performance/#2-5","title":"2-5","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 7.359118 8.248676 7.747425 0.42x pyranges1-1 12.017050 12.394313 12.172057 0.26x polars_bio-1 3.168840 3.279239 3.221157 1.00x polars_bio-2 1.807984 1.896123 1.840286 1.75x polars_bio-4 1.565173 1.855352 1.667814 1.93x polars_bio-8 1.328546 1.644594 1.525987 2.11x -------------- ---------- ---------- ---------- --------- polars_bio-1-p 4.691770 4.771827 4.731799 1.00x polars_bio-2-p 2.498744 2.529678 2.514211 1.88x polars_bio-4-p 1.350183 1.360860 1.355522 3.49x polars_bio-8-p 0.746751 0.746974 0.746863 6.34x"},{"location":"performance/#3-0","title":"3-0","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 78.437583 80.667906 79.691000 0.16x pyranges1-1 149.301588 150.696560 150.214238 0.08x polars_bio-1 8.699317 15.876707 12.749627 1.00x polars_bio-2 7.107510 11.556344 8.876861 1.44x polars_bio-4 6.368686 6.746370 6.558874 1.94x polars_bio-8 5.673492 6.341975 6.052686 2.11x -------------- ----------- ----------- ----------- --------- polars_bio-1-p 16.687511 19.602739 18.145125 1.00x polars_bio-2-p 9.592687 11.276648 10.434667 1.74x polars_bio-4-p 6.641342 6.712883 6.677113 2.72x polars_bio-8-p 5.365854 5.920471 5.643162 3.22x"},{"location":"performance/#intel-emerald-rapids-linux_2","title":"Intel Emerald Rapids (Linux) \ud83d\udc27","text":""},{"location":"performance/#0-8_1","title":"0-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 22.427066 23.052440 22.637076 0.29x pyranges1-1 35.304058 35.420546 35.342961 0.18x polars_bio-1 5.664570 7.867539 6.508315 1.00x polars_bio-2 3.485226 3.621209 3.564963 1.83x polars_bio-4 2.262268 2.320929 2.287944 2.84x polars_bio-8 1.287120 1.311752 1.297510 5.02x --------------- ----------- ----------- ----------- ----------- polars_bio-1-p 5.825176 7.007628 6.252962 1.00x polars_bio-2-p 2.976644 3.025504 2.995113 2.09x polars_bio-4-p 1.622611 1.690197 1.650458 3.79x polars_bio-8-p 1.009492 1.046739 1.025886 6.10x"},{"location":"performance/#7-8_1","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 41.676284 42.974216 42.485708 0.18x pyranges1-1 63.524302 63.774618 63.679367 0.12x polars_bio-1 6.510632 9.640636 7.619978 1.00x polars_bio-2 4.063316 4.558028 4.316856 1.77x polars_bio-4 3.006938 3.116209 3.053199 2.50x polars_bio-8 1.733345 1.782316 1.752699 4.35x --------------- ----------- ----------- ----------- ----------- polars_bio-1-p 6.666566 8.707044 7.364003 1.00x polars_bio-2-p 3.314721 3.438854 3.396223 2.17x polars_bio-4-p 1.755033 1.766559 1.760501 4.18x polars_bio-8-p 1.023208 1.055603 1.035804 7.11x"},{"location":"performance/#2-5_1","title":"2-5","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 15.954215 17.879185 16.597961 0.32x pyranges1-1 22.822777 23.005675 22.899582 0.23x polars_bio-1 5.096198 5.652478 5.296669 1.00x polars_bio-2 3.216712 3.390962 3.296900 1.61x polars_bio-4 2.941997 3.078842 3.004835 1.76x polars_bio-8 2.373662 2.483793 2.423432 2.19x --------------- ----------- ----------- ----------- ----------- polars_bio-1-p 6.835908 8.957041 7.564713 1.00x polars_bio-2-p 3.406529 3.430781 3.416292 2.21x polars_bio-4-p 1.815182 1.942866 1.872337 4.04x polars_bio-8-p 1.026042 1.065482 1.039835 7.27x"},{"location":"performance/#3-0_1","title":"3-0","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 158.193622 159.014103 158.563798 0.17x pyranges1-1 OOM OOM OOM OOM polars_bio-1 26.957168 27.577231 27.316310 1.00x polars_bio-2 19.440849 19.631778 19.567068 1.40x polars_bio-4 16.432316 16.657353 16.570284 1.65x polars_bio-8 12.845359 13.136680 12.951113 2.11x -------------- ------------ ------------ ------------ ----------- polars_bio-1-p 34.869014 35.937479 35.249302 1.00x polars_bio-2-p 20.142638 20.460018 20.338156 1.73x polars_bio-4-p 11.641085 11.721084 11.672311 3.02x polars_bio-8-p 7.169329 7.339832 7.258024 4.86x"},{"location":"performance/#nearest-operation","title":"Nearest operation","text":""},{"location":"performance/#apple-silicon-macos_3","title":"Apple Silicon (macOS) \ud83c\udf4e","text":""},{"location":"performance/#7-8_2","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 2.617098 2.632619 2.626817 0.39x pyranges1-1 2.928071 2.952393 2.942198 0.35x polars_bio-1 0.999672 1.038078 1.016733 1.00x polars_bio-2 0.624798 0.630383 0.627723 1.62x polars_bio-4 0.412480 0.422400 0.417233 2.44x polars_bio-8 0.286680 0.291932 0.290088 3.50x -------------- ---------- ---------- ---------- --------- polars_bio-1-p 1.450476 1.478374 1.466073 1.00x polars_bio-2-p 1.013673 1.029715 1.019719 1.44x polars_bio-4-p 0.812852 0.816052 0.814196 1.80x polars_bio-8-p 0.715727 0.726820 0.722109 2.03x"},{"location":"performance/#0-8_2","title":"0-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 2.727178 2.788261 2.748268 0.39x pyranges1-1 3.193758 3.290031 3.238138 0.33x polars_bio-1 1.050470 1.111362 1.071476 1.00x polars_bio-2 0.603192 0.614378 0.607069 1.76x polars_bio-4 0.477346 0.484047 0.480698 2.23x polars_bio-8 0.371300 0.377496 0.374637 2.86x -------------- ---------- ---------- ---------- --------- polars_bio-1-p 1.459614 1.499385 1.485763 1.00x polars_bio-2-p 1.031476 1.032248 1.031815 1.44x polars_bio-4-p 0.813042 0.818795 0.815014 1.82x polars_bio-8-p 0.727105 0.735477 0.730848 2.03x"},{"location":"performance/#0-3","title":"0-3","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 0.605024 0.655083 0.628258 1.45x pyranges1-1 0.892005 0.899846 0.895358 1.01x polars_bio-1 0.901617 0.919927 0.908753 1.00x polars_bio-2 0.565947 0.570143 0.568091 1.60x polars_bio-4 0.486143 0.487667 0.486668 1.87x polars_bio-8 0.404343 0.408482 0.406183 2.24x -------------- ---------- ---------- ---------- --------- polars_bio-1-p 1.934625 1.983807 1.962461 1.00x polars_bio-2-p 1.063823 1.069980 1.067726 1.84x polars_bio-4-p 0.618193 0.620918 0.619740 3.17x polars_bio-8-p 0.378345 0.381553 0.380137 5.16x"},{"location":"performance/#2-5_2","title":"2-5","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 11.466866 11.731607 11.589608 0.16x pyranges1-1 12.607366 12.686471 12.659969 0.15x polars_bio-1 1.785067 1.984576 1.859738 1.00x polars_bio-2 1.550936 1.616606 1.576498 1.18x polars_bio-4 1.293685 1.354271 1.327746 1.40x polars_bio-8 1.229453 1.255038 1.244184 1.49x -------------- ---------- ---------- ---------- --------- polars_bio-1-p 4.099759 4.148830 4.119466 1.00x polars_bio-2-p 3.899533 3.927669 3.910608 1.05x polars_bio-4-p 3.730015 3.764352 3.748710 1.10x polars_bio-8-p 3.740107 3.776072 3.758196 1.10x"},{"location":"performance/#intel-emerald-rapids-linux_3","title":"Intel Emerald Rapids (Linux) \ud83d\udc27","text":""},{"location":"performance/#7-8_3","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 4.206312 4.294343 4.241896 0.45x pyranges1-1 4.442628 4.488366 4.458621 0.43x polars_bio-1 1.891354 1.948671 1.912490 1.00x polars_bio-2 1.283955 1.302282 1.295635 1.48x polars_bio-4 1.078061 1.105893 1.094149 1.75x polars_bio-8 0.712460 0.752014 0.727148 2.63x --------------- ---------- ---------- ---------- --------- polars_bio-1-p 2.828171 2.931478 2.890248 1.00x polars_bio-2-p 1.916772 1.936575 1.927385 1.50x polars_bio-4-p 1.456353 1.481438 1.472393 1.96x polars_bio-8-p 1.295097 1.350529 1.315073 2.20x"},{"location":"performance/#0-8_3","title":"0-8","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 4.231424 4.330897 4.274404 0.48x pyranges1-1 4.763702 4.832694 4.797875 0.43x polars_bio-1 2.041052 2.054510 2.048951 1.00x polars_bio-2 1.427670 1.462461 1.445207 1.42x polars_bio-4 1.133872 1.182288 1.150375 1.78x polars_bio-8 0.743850 0.786324 0.769738 2.66x --------------- ---------- ---------- ---------- --------- polars_bio-1-p 2.757630 2.817896 2.794401 1.00x polars_bio-2-p 1.912476 1.934266 1.926969 1.45x polars_bio-4-p 1.483118 1.571922 1.534062 1.82x polars_bio-8-p 1.345707 1.363905 1.356738 2.06x"},{"location":"performance/#0-3_1","title":"0-3","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 0.929409 1.043995 0.989172 1.29x pyranges1-1 1.232229 1.277243 1.250441 1.02x polars_bio-1 1.121446 1.560456 1.272248 1.00x polars_bio-2 0.790184 0.798372 0.795170 1.60x polars_bio-4 0.645712 0.662949 0.652850 1.95x polars_bio-8 0.473802 0.505282 0.489050 2.60x --------------- ---------- ---------- ---------- --------- polars_bio-1-p 2.863790 3.048004 2.927503 1.00x polars_bio-2-p 1.545225 1.580199 1.560213 1.88x polars_bio-4-p 0.921394 0.944576 0.934756 3.13x polars_bio-8-p 0.625656 0.637595 0.632294 4.63x"},{"location":"performance/#2-5_3","title":"2-5","text":"Library Min (s) Max (s) Mean (s) Speedup pyranges0-1 21.188286 21.349862 21.267732 0.24x pyranges1-1 19.789758 20.092196 19.913107 0.26x polars_bio-1 5.085885 5.158123 5.120825 1.00x polars_bio-2 4.084694 4.328842 4.207706 1.22x polars_bio-4 3.570746 3.885584 3.752306 1.36x polars_bio-8 3.250405 3.413984 3.329296 1.54x --------------- ---------- ---------- ---------- --------- polars_bio-1-p 8.974429 9.101872 9.048213 1.00x polars_bio-2-p 8.297582 8.385287 8.339353 1.09x polars_bio-4-p 8.007553 8.099914 8.053293 1.12x polars_bio-8-p 7.851029 8.051397 7.939732 1.14x polars_bio-16-p 7.746810 7.985732 7.882904 1.15x"},{"location":"performance/#dataframes-comparison","title":"DataFrames comparison","text":"<p>Note</p> <p>In the following benchmarks we compared the perfoemance of Python DataFrames libraries in the following scenarios:</p> <ul> <li><code>polars_bio</code>: native Rust Parquet (default) reader and Polars LazyFrame (default) as an output.</li> <li><code>polars_bio_pandas_lf</code>: Pandas DataFrames as an input and Polars LazyFrame as an output.</li> <li><code>polars_bio_pandas_pd</code>: Pandas DataFrames as an input and Pandas DataFrame as an output.</li> <li><code>polars_bio_polars_eager</code>: Polars DataFrames as an input and Polars LazyFrame as an output.</li> <li><code>polars_bio_polars_lazy</code>: Polars LazyFrames as an input and Polars LazyFrame as an output.</li> </ul>"},{"location":"performance/#apple-silicon-macos_4","title":"Apple Silicon (macOS) \ud83c\udf4e","text":""},{"location":"performance/#s-size_5","title":"S-size","text":""},{"location":"performance/#1-2","title":"1-2","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.035567 0.036777 0.035995 0.91x polars_bio_pandas_lf 0.040237 0.041256 0.040694 0.80x polars_bio_pandas_pd 0.040554 0.040888 0.040761 0.80x polars_bio_polars_eager 0.032051 0.033022 0.032693 1.00x polars_bio_polars_lazy 0.034346 0.035225 0.034775 0.94x"},{"location":"performance/#2-7","title":"2-7","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.094768 0.096217 0.095266 1.00x polars_bio_pandas_lf 0.163054 0.164207 0.163713 0.58x polars_bio_pandas_pd 0.163245 0.166200 0.165022 0.58x polars_bio_polars_eager 0.142344 0.145895 0.144110 0.66x polars_bio_polars_lazy 0.149738 0.150299 0.149929 0.64x"},{"location":"performance/#1-0","title":"1-0","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.145564 0.151407 0.147679 1.00x polars_bio_pandas_lf 0.238292 0.240374 0.239504 0.62x polars_bio_pandas_pd 0.239330 0.252445 0.244414 0.60x polars_bio_polars_eager 0.208421 0.214513 0.210896 0.70x polars_bio_polars_lazy 0.219629 0.222126 0.220908 0.67x"},{"location":"performance/#m-size_5","title":"M-size","text":""},{"location":"performance/#7-0","title":"7-0","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.224327 0.227891 0.225606 1.00x polars_bio_pandas_lf 0.377938 0.378380 0.378205 0.60x polars_bio_pandas_pd 0.413825 0.415470 0.414630 0.54x polars_bio_polars_eager 0.332434 0.335960 0.334393 0.67x polars_bio_polars_lazy 0.347608 0.350382 0.349330 0.65x"},{"location":"performance/#7-3","title":"7-3","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.206701 0.217080 0.210280 1.00x polars_bio_pandas_lf 0.345310 0.355560 0.349561 0.60x polars_bio_pandas_pd 0.415459 0.417442 0.416609 0.50x polars_bio_polars_eager 0.311204 0.313540 0.312487 0.67x polars_bio_polars_lazy 0.321170 0.322826 0.321981 0.65x"},{"location":"performance/#l-size_5","title":"L-size","text":""},{"location":"performance/#0-8_4","title":"0-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 2.750666 2.895516 2.802942 1.00x polars_bio_pandas_lf 3.525844 3.646709 3.592018 0.78x polars_bio_pandas_pd 6.455399 6.539737 6.487919 0.43x polars_bio_polars_eager 3.236083 3.428796 3.331644 0.84x polars_bio_polars_lazy 3.220374 3.251365 3.232736 0.87x"},{"location":"performance/#4-8","title":"4-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.677363 3.877014 3.749576 1.00x polars_bio_pandas_lf 4.875777 5.007774 4.953983 0.76x polars_bio_pandas_pd 8.595318 8.809947 8.704564 0.43x polars_bio_polars_eager 4.473527 4.608746 4.561838 0.82x polars_bio_polars_lazy 4.728077 4.786690 4.758805 0.79x"},{"location":"performance/#7-8_4","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.439489 3.917193 3.633215 1.00x polars_bio_pandas_lf 3.930340 4.079147 3.985301 0.91x polars_bio_pandas_pd 9.646125 9.994008 9.798255 0.37x polars_bio_polars_eager 3.742098 3.995767 3.832054 0.95x polars_bio_polars_lazy 3.767904 4.058453 3.882342 0.94x Source Peak Memory (MB)) Factor polars_bio 14,671 1.0x polars_bio_pandas_pd 22,589 1.54x polars_bio_pandas_eager 23,681 1.61x"},{"location":"performance/#memory-characteristic-polars_bio","title":"Memory characteristic polars_bio","text":""},{"location":"performance/#memory-characteristic-polars_bio_pandas_pd","title":"Memory characteristic polars_bio_pandas_pd","text":""},{"location":"performance/#memory-characteristic-polars_bio_polars_eager","title":"Memory characteristic polars_bio_polars_eager","text":""},{"location":"performance/#intel-emerald-rapids-linux_4","title":"Intel Emerald Rapids (Linux) \ud83d\udc27","text":""},{"location":"performance/#s-size_6","title":"S-size","text":""},{"location":"performance/#1-2_1","title":"1-2","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.044786 0.051431 0.047491 0.75x polars_bio_pandas_lf 0.049655 0.053397 0.051123 0.70x polars_bio_pandas_pd 0.049221 0.049408 0.049292 0.73x polars_bio_polars_eager 0.035443 0.037997 0.036327 0.99x polars_bio_polars_lazy 0.035665 0.036124 0.035831 1.00x"},{"location":"performance/#2-7_1","title":"2-7","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.121025 0.125696 0.122869 0.88x polars_bio_pandas_lf 0.136112 0.146342 0.141704 0.76x polars_bio_pandas_pd 0.136125 0.137920 0.137167 0.79x polars_bio_polars_eager 0.106999 0.111473 0.108813 0.99x polars_bio_polars_lazy 0.107742 0.108038 0.107885 1.00x"},{"location":"performance/#1-0_1","title":"1-0","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.180773 0.185704 0.183153 0.91x polars_bio_pandas_lf 0.210633 0.217342 0.213262 0.78x polars_bio_pandas_pd 0.211245 0.211972 0.211680 0.79x polars_bio_polars_eager 0.166366 0.169000 0.167294 1.00x polars_bio_polars_lazy 0.166566 0.167847 0.167033 1.00x"},{"location":"performance/#m-size_6","title":"M-size","text":""},{"location":"performance/#7-0_1","title":"7-0","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.306130 0.314524 0.309803 1.00x polars_bio_pandas_lf 0.416123 0.432397 0.422839 0.73x polars_bio_pandas_pd 0.410937 0.414566 0.412503 0.75x polars_bio_polars_eager 0.353321 0.364626 0.358433 0.86x polars_bio_polars_lazy 0.355099 0.359842 0.357666 0.87x"},{"location":"performance/#7-3_1","title":"7-3","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.283038 0.292933 0.288120 1.00x polars_bio_pandas_lf 0.496220 0.510444 0.502504 0.57x polars_bio_pandas_pd 0.495243 0.498179 0.497064 0.58x polars_bio_polars_eager 0.446789 0.455552 0.450521 0.64x polars_bio_polars_lazy 0.450512 0.456530 0.453931 0.63x"},{"location":"performance/#l-size_6","title":"L-size","text":""},{"location":"performance/#0-8_5","title":"0-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 4.519114 4.539367 4.532138 1.00x polars_bio_pandas_lf 12.710922 12.805014 12.751166 0.36x polars_bio_pandas_pd 12.699757 12.820158 12.759016 0.36x polars_bio_polars_eager 12.455788 12.555952 12.501217 0.36x polars_bio_polars_lazy 12.536595 12.579006 12.561026 0.36x"},{"location":"performance/#4-8_1","title":"4-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 6.043839 6.129112 6.088359 1.00x polars_bio_pandas_lf 16.528438 16.674857 16.605654 0.37x polars_bio_pandas_pd 16.575829 16.643302 16.600709 0.37x polars_bio_polars_eager 16.177433 16.185123 16.180217 0.38x polars_bio_polars_lazy 16.214009 16.395757 16.281422 0.37x"},{"location":"performance/#7-8_5","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 4.600700 4.806215 4.689799 1.00x polars_bio_pandas_lf 19.858977 20.342740 20.104499 0.23x polars_bio_pandas_pd 20.263301 20.594552 20.402049 0.23x polars_bio_polars_eager 19.837098 20.012580 19.922743 0.24x polars_bio_polars_lazy 19.803839 19.818197 19.813257 0.24x"},{"location":"performance/#parallel-execution","title":"Parallel execution","text":""},{"location":"performance/#apple-silicon-macos_5","title":"Apple Silicon (macOS) \ud83c\udf4e","text":""},{"location":"performance/#7-8_6","title":"7-8","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio-1 2.809130 3.025777 2.892455 1.00x polars_bio_pandas_lf-1 6.113947 6.343946 6.200402 0.47x polars_bio_pandas_pd-1 7.101394 7.133803 7.121356 0.41x polars_bio_polars_eager-1 6.083699 6.269502 6.188576 0.47x polars_bio_polars_lazy-1 6.282692 6.359252 6.328352 0.46x polars_bio-2 1.382220 1.489515 1.435259 2.02x polars_bio_pandas_lf-2 4.088560 4.139376 4.107673 0.70x polars_bio_pandas_pd-2 5.591844 5.612861 5.603072 0.52x polars_bio_polars_eager-2 3.995305 4.058894 4.020753 0.72x polars_bio_polars_lazy-2 3.961027 4.047943 4.001683 0.72x polars_bio-4 1.017920 1.077169 1.041166 2.78x polars_bio_pandas_lf-4 3.084727 3.126532 3.102596 0.93x polars_bio_pandas_pd-4 4.925954 4.957415 4.943877 0.59x polars_bio_polars_eager-4 2.914283 2.971686 2.935221 0.99x polars_bio_polars_lazy-4 2.918793 2.944206 2.930453 0.99x polars_bio-8 0.688430 0.751968 0.711147 4.07x polars_bio_pandas_lf-8 2.558258 2.606939 2.588139 1.12x polars_bio_pandas_pd-8 4.448074 4.490866 4.474837 0.65x polars_bio_polars_eager-8 2.398288 2.513702 2.446019 1.18x polars_bio_polars_lazy-8 2.406907 2.418571 2.411573 1.20x"},{"location":"performance/#memory-characteristics","title":"Memory characteristics","text":"<p>How to run the benchmarks with memory-profiler: </p><pre><code>(polars-bio-py3.12) \u279c  polars-bio git:(master) \u2717 pip list | grep memory\nmemory-profiler            0.61.0\n\nmprof run --include-children benchmark/src/memory/mem_xxx.py\nmprof plot mprofile_xxx.dat\n</code></pre><p></p> <p>Tip</p> <ol> <li>Here we report end-to-end time, i.e. including reading and writing to a file and all the required operations in between, such as data transformation, Python object creation, etc.</li> </ol>"},{"location":"performance/#apple-silicon-macos_6","title":"Apple Silicon (macOS) \ud83c\udf4e","text":""},{"location":"performance/#read-parquet-files-and-count-overlaps-7-8","title":"Read Parquet files and count overlaps  7-8","text":"Library Peak Memory (MB) Factor polars-bio 14,650 1.0x bioframe 35,720 2.43x pyranges0 30,140 2.06x pyranges1 35,940 2.45x"},{"location":"performance/#polars-bio","title":"polars-bio","text":""},{"location":"performance/#bioframe","title":"bioframe","text":""},{"location":"performance/#pyranges0","title":"pyranges0","text":""},{"location":"performance/#pyranges1","title":"pyranges1","text":""},{"location":"performance/#calculate-overlaps-and-export-to-a-csv-file-7-8","title":"Calculate overlaps and export to a CSV file 7-8","text":"Library Time (s) Speedup Peak Memory (MB) Factor polars-bio 23.765 0.77x 14,660 26.07x polars-bio-stream 18.221<sup>1</sup> 1.0x 562.22 1.0x bioframe 370.010 0.05x 33,352 59.32x pyranges0 275.237 0.07x 30.052 53.45x pyranges1 351.041 0.05x 36,530 64.97x <p><sup>1</sup> Despite limiting the number of threads in DataFusion (<code>datafusion.execution.target_partitions=1</code>) and in Polars (<code>POLARS_MAX_THREADS=1</code>) cpu utilization was constant and approx.160%.</p>"},{"location":"performance/#polars-bio_1","title":"polars-bio","text":""},{"location":"performance/#polars-bio_stream","title":"polars-bio_stream","text":""},{"location":"performance/#bioframe_1","title":"bioframe","text":""},{"location":"performance/#pyranges0_1","title":"pyranges0","text":""},{"location":"performance/#pyranges1_1","title":"pyranges1","text":""},{"location":"performance/#how-to-run-the-benchmarks","title":"How to run the benchmarks","text":"<p>Check the repository for more details on how to run the benchmarks. ```</p> <p>Todo</p> <ul> <li>Add more details on how to run the benchmarks</li> </ul>"},{"location":"quickstart/","title":"\ud83c\udfc3\ud83c\udffc\u200d\u2642\ufe0f Quick start","text":"<p>polars-bio is available on PyPI and can be installed with pip: </p><pre><code>pip install polars-bio\n</code></pre> To enable support for Pandas DataFrames, install the <code>pandas</code> extra: <pre><code>pip install polars-bio[pandas]\n</code></pre> For visualization features, which depend on <code>bioframe</code> and <code>matplotlib</code>, install the <code>viz</code> extra: <pre><code>pip install polars-bio[viz]\n</code></pre> There are binary versions for Linux (x86_64), MacOS (x86_64 and arm64) and Windows (x86_64). In case of other platforms (or errors indicating incompatibilites between Python's ABI), it is fairly easy to build polars-bio from source with poetry and maturin: <pre><code>git clone https://github.com/biodatageeks/polars-bio.git\ncd polars-bio\npoetry env use 3.12\npoetry update\nRUSTFLAGS=\"-Ctarget-cpu=native\" maturin build --release -m Cargo.toml\n</code></pre> and you should see the following output: <pre><code>Compiling polars_bio v0.10.3 (/Users/mwiewior/research/git/polars-bio)\nFinished `release` profile [optimized] target(s) in 1m 25s\n\ud83d\udce6 Built wheel for abi3 Python \u2265 3.8 to /Users/mwiewior/research/git/polars-bio/target/wheels/polars_bio-0.10.3-cp38-abi3-macosx_11_0_arm64.whl\n</code></pre> and finally install the package with pip: <pre><code>pip install /Users/mwiewior/research/git/polars-bio/target/wheels/polars_bio-0.10.3-cp38-abi3-macosx_11_0_arm64.whl\n</code></pre><p></p> <p>Tip</p> <p>Required dependencies:</p> <ul> <li>Python&gt;=3.9&lt;3.14 (3.12 is recommended),</li> <li>poetry</li> <li>cmake,</li> <li>Rust compiler</li> <li>Cargo are required to build the package from source. rustup is the recommended way to install Rust.</li> </ul> <pre><code>import polars_bio as pb\npb.read_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\", compression_type=\"bgz\").limit(3).collect()\n</code></pre> <pre><code>shape: (3, 8)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 chrom \u2506 start \u2506 end    \u2506 id                             \u2506 ref \u2506 alt   \u2506 qual  \u2506 filter              \u2502\n\u2502 ---   \u2506 ---   \u2506 ---    \u2506 ---                            \u2506 --- \u2506 ---   \u2506 ---   \u2506 ---                 \u2502\n\u2502 str   \u2506 u32   \u2506 u32    \u2506 str                            \u2506 str \u2506 str   \u2506 f64   \u2506 str                 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 chr1  \u2506 10000 \u2506 295666 \u2506 gnomAD-SV_v3_DUP_chr1_01c2781c \u2506 N   \u2506 &lt;DUP&gt; \u2506 134.0 \u2506 HIGH_NCR            \u2502\n\u2502 chr1  \u2506 10434 \u2506 10434  \u2506 gnomAD-SV_v3_BND_chr1_1a45f73a \u2506 N   \u2506 &lt;BND&gt; \u2506 260.0 \u2506 HIGH_NCR;UNRESOLVED \u2502\n\u2502 chr1  \u2506 10440 \u2506 10440  \u2506 gnomAD-SV_v3_BND_chr1_3fa36917 \u2506 N   \u2506 &lt;BND&gt; \u2506 198.0 \u2506 HIGH_NCR;UNRESOLVED \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>If you see the above output, you have successfully installed polars-bio and can start using it. Please refer to the Tutorial and API documentation for more details on how to use the library.</p>"},{"location":"supplement/","title":"\ud83d\udd2c Auxiliary materials","text":""},{"location":"supplement/#supplemental-material","title":"Supplemental material","text":"<p>This document provides additional information about the algorithms, benchmarking setup, data, and results that were presented in the manuscript.</p>"},{"location":"supplement/#algorithm-description","title":"Algorithm description","text":"<p><code>polars-bio</code> implements a set of binary interval operations on genomic ranges, such as overlap, nearest, count-overlaps, and coverage. All these operations share the very similar algorithmic structure, which is presented in the diagram below.</p> <pre><code>flowchart TB\n    %% Define header node\n    H[\"Interval operation\"]\n\n    %% Define DataFrame nodes\n    I0[\"left DataFrame\"]\n    I1[\"right DataFrame\"]\n\n    style I0 stroke-dasharray: 5 5, stroke-width: 1\n\n    %% Draw edges with labels\n    H --&gt;|probe /streaming/ side| I0\n    H --&gt;|build /search structure/ side| I1\n\n    %% Record batches under left DataFrame within a dotted box\n    I0 --&gt; LeftGroup\n    subgraph LeftGroup[\"Record Batches\"]\n        direction TB\n        LB0[\"Batch 1\"]\n        LB1[\"Batch 2\"]\n        LB2[\"Batch 3\"]\n    end\n    style LeftGroup stroke-dasharray: 5 5, stroke-width: 1\n\n    %% Record batches under right DataFrame within a dotted box\n    I1 --&gt; RightGroup\n    subgraph RightGroup[\"Record Batches\"]\n        direction TB\n        RB0[\"Batch 1\"]\n        RB1[\"Batch 2\"]\n        RB2[\"Batch 3\"]\n    end\n</code></pre> <p>The basic concept is that each operation consists of two sides: the probe side and the build side. The probe side is the one that is streamed, while the build side is the one that is implemented as a search data structure (for generic overlap operation the search structure can be changed using algorithm parameter, for other operations is always Cache Oblivious Interval Trees as according to the benchmark COITrees outperforms other data structures). In the case of nearest operation there is an additional sorted list of intervals used for searching for closest intervals in the case of non-existing overlaps.</p> <p>Note</p> <p>Available search structure implementations for overlap operation:</p> <ul> <li>COITrees</li> <li>IITree</li> <li>AVL-tree</li> <li>rust-lapper</li> <li>superintervals - available since <code>polars-bio</code> version <code>0.12.0</code></li> </ul> <p>Once the build side data structure is ready, then records from the probe side are processed against the search structure organized as record batches. Each record batch can be processed independently. Search structure nodes contains identifiers of the rows from the build side that are then used to construct a new record that is returned as a result of the operation.</p>"},{"location":"supplement/#out-of-core-streaming-processing","title":"Out-of-core (streaming) processing","text":"<p>This algorithm allows you to process your results without requiring all your data to be in memory at the same time. In particular, the probe side can be streamed from a file stored locally or on a cloud object storage, while the build side needs to be fully materialized in memory. In real applications, the probe side is usually a large file with genomic intervals, while the build side is a smaller file with annotations or other genomic features. This allows you to process large genomic datasets without running out of memory.</p> <p>Note</p> <ol> <li>In this sense, the order of the sides is important, as the probe side is streamed and processed in batches, while the build side is fully materialized in memory.</li> <li>The smaller the build side and larger the number of overlaps are, the higher is the gain of memory efficiency. For instance, when we compare the real <code>8-7</code> (<code>10^7 vs. 1.2*10^6</code>) and synthetic (<code>10^7 vs. 10^7</code>) datasets, we can see that we benefit more from using streaming mode in the former benchmark.</li> </ol>"},{"location":"supplement/#parallelization","title":"Parallelization","text":"<p>In the current implementation, the probe side can be processed in parallel using multiple threads on partitioned (implicitly or explicilty partitioned inputs - see partitioning strategies). The build side is predominantly single-threaded (with the notable exception of BGZF compressed or partitioned Parquet/CSV input data files reading, which can be parallelized).</p>"},{"location":"supplement/#implementation","title":"Implementation","text":"<p><code>polars-bio</code> uses the following Apache DataFusion extension points:</p> <ul> <li>DefaultPhysicalPlanner and PhysicalOptimizerRule for detecting and rewriting generic interval join operations (i.e. overlap and nearest) with optimizied execution strategies. This is implemented as a part of our another project sequila-native that exposes optimized interval join operations for Apache DataFusion with both SQL and DataFrame APIs.</li> <li>TableProvider and User-Defined Table Function mechanism for implementing specialized operations, such as coverage and count-overlaps.</li> </ul>"},{"location":"supplement/#comparison-with-existing-tools","title":"Comparison with existing tools","text":"<p>The table below compares <code>polars-bio</code> with other popular Python libraries for genomic ranges operations.</p> Feature/Library polars-bio Bioframe PyRanges0 PyRanges1 pybedtools PyGenomics GenomicRanges out-of-core processing \u2705 \u274c \u274c \u274c \u274c \u274c \u274c parallel processing \u2705 \u274c \u2705<sup>1</sup> \u274c \u274c \u274c \u274c vectorized execution engine \u2705 \u274c \u274c \u274c \u274c \u274c \u274c cloud object storage support \u2705 \u2705/\u274c<sup>2</sup> \u274c \u274c \u274c \u274c \u2705 Pandas/Polars DataFrame support \u2705/\u2705 \u2705/\u274c \u2705/\u274c<sup>3</sup> \u2705/\u274c<sup>4</sup> \u274c/\u274c \u274c/\u274c \u2705/\u2705 <p>Note</p> <p><sup>1</sup> PyRanges0 supports parallel processing with Ray, but it does not bring any performance benefits over single-threaded execution and it is not recommended. Overlap and nearest operations benchmark (1,2,4,6,8 threads) on 8-7 on Apple M3 Max platfotm confirms this observation.</p> Library Min (s) Max (s) Mean (s) Speedup pyranges0 16.519153 17.889156 17.118936 1.00x pyranges0-2 32.539549 34.858773 33.762477 0.51x pyranges0-4 30.033927 30.367822 30.158362 0.57x pyranges0-6 27.711752 33.280867 30.089641 0.57x pyranges0-8 30.049501 33.257462 31.553328 0.54x Library Min (s) Max (s) Mean (s) Speedup pyranges0 1.580677 1.703093 1.630820 1.00x pyranges0-2 3.954720 4.032619 3.997087 0.41x pyranges0-4 3.716688 4.004058 3.847917 0.42x pyranges0-6 3.853526 3.942475 3.883337 0.42x pyranges0-8 3.861577 3.924950 3.902913 0.42x <p><sup>2</sup> Some input functions, such as <code>read_table</code> support cloud object storage</p> <p><sup>3</sup> Only export/import with data copying is supported</p> <p><sup>4</sup> RangeFrame class extends Pandas DataFrame</p>"},{"location":"supplement/#benchmark-setup","title":"Benchmark setup","text":""},{"location":"supplement/#code-and-benchmarking-scenarios","title":"Code and  benchmarking scenarios","text":"<p>Repository</p>"},{"location":"supplement/#memory-profiling","title":"Memory profiling","text":"<p>For memory profiling Python memory-profiler <code>version 0.61.0</code> was used. A helper run-memory-profiler.py script was developed and a sample invocation was used to run the tests as it is presented in the snippet below: </p><pre><code>PRFOF_FILE=\"polars_bio_1-2.dat\"\nmprof run --output $PRFOF_FILE python src/run-memory-profiler.py --bench-config conf/paper/benchmark-e2e-overlap.yaml --tool polars_bio --test-case 1-2\nmprof plot $PRFOF_FILE\n</code></pre><p></p> <p>Note</p> <p>On each memory profile plot, the maximum memory is marked at the intersection of the two dashed lines.</p>"},{"location":"supplement/#operating-systems-and-hardware-configurations","title":"Operating systems and hardware configurations","text":""},{"location":"supplement/#macos","title":"macOS","text":"<ul> <li>cpu architecture: <code>arm64</code></li> <li>cpu name: <code>Apple M3 Max</code></li> <li>cpu cores: <code>16</code></li> <li>memory: <code>64 GB</code></li> <li>kernel: <code>Darwin Kernel Version 24.2.0: Fri Dec  6 19:02:12 PST 2024; root:xnu-11215.61.5~2/RELEASE_ARM64_T6031</code></li> <li>system: <code>Darwin</code></li> <li>os-release: <code>macOS-15.2-arm64-arm-64bit</code></li> <li>python: <code>3.12.4</code></li> <li>polars-bio: <code>0.8.3</code></li> </ul>"},{"location":"supplement/#linux","title":"Linux","text":"<p>c3-standard-22 machine was used for benchmarking.</p> <ul> <li>cpu architecture: <code>x86_64</code></li> <li>cpu name: <code>Intel(R) Xeon(R) Platinum 8481C CPU @ 2.70GHz</code></li> <li>cpu cores: <code>22</code></li> <li>memory: <code>88 GB</code></li> <li>kernel: <code>Linux-6.8.0-1025-gcp-x86_64-with-glibc2.35</code></li> <li>system: <code>Linux</code></li> <li>os-release: <code>#27~22.04.1-Ubuntu SMP Mon Feb 24 16:42:24 UTC 2025</code></li> <li>python: <code>3.12.8</code></li> <li>polars-bio: <code>0.8.3</code></li> </ul>"},{"location":"supplement/#software","title":"Software","text":"<ul> <li>Bioframe-0.7.2</li> <li>PyRanges0-0.0.132</li> <li>PyRanges1-e634a11</li> <li>pybedtools-0.10.0</li> <li>PyGenomics-0.1.1</li> <li>GenomicRanges-0.5.0</li> </ul>"},{"location":"supplement/#data","title":"Data","text":""},{"location":"supplement/#real-dataset","title":"Real dataset","text":"<p>The AIList dataset after transcoding into the Parquet file format (with the Snappy compression) was used for benchmarking. This dataset was published with the AIList paper:</p> <p>Jianglin Feng , Aakrosh Ratan , Nathan C Sheffield, Augmented Interval List: a novel data structure for efficient genomic interval search, Bioinformatics 2019.</p> Dataset# Name Size(x1000) Description 0 chainRn4 2,351 Source 1 fBrain 199 Source 2 exons 439 Dataset used in the BEDTools tutorial. 3 chainOrnAna1 1,957 Source 4 chainVicPac2 7,684 Source 5 chainXenTro3Link 50,981 Source 6 chainMonDom5Link 128,187 Source 7 ex-anno 1,194 Dataset contains GenCode annotations with ~1.2 million lines, mixing all types of features. 8 ex-rna 9,945 Dataset contains ~10 million direct-RNA mappings. <p>Source: AIList Github</p> Rank Dataset 1 Dataset 2 # of overlaps 1 chainMonDom5Link chainXenTro3Link 416,157,506,000 2 chainMonDom5Link chainVicPac2 248,984,248,721 3 chainVicPac2 chainXenTro3Link 117,131,343,532 4 chainMonDom5Link chainOrnAna1 52,992,648,116 5 chainMonDom5Link chainRn4 27,741,145,443 6 chainXenTro3Link chainOrnAna1 26,405,758,645 7 chainRn4 chainXenTro3Link 18,432,254,632 8 chainVicPac2 chainOrnAna1 6,864,638,705 9 chainMonDom5Link ex-rna 4,349,989,219 10 chainRn4 chainVicPac2 3,892,115,928 11 ex-rna chainXenTro3Link 1,830,555,949 --- ---------------- ---------------- --------------- 12 chainRn4 chainOrnAna1 1,086,692,495 13 ex-rna ex-anno 307,184,634 14 ex-rna chainVicPac2 227,832,153 15 ex-rna chainRn4 164,196,784 16 chainMonDom5Link exons 116,300,901 17 ex-rna chainOrnAna1 109,300,082 18 chainXenTro3Link exons 52,395,369 19 ex-rna exons 36,411,474 20 chainMonDom5Link ex-anno 33,966,070 21 chainXenTro3Link ex-anno 13,693,852 22 chainVicPac2 exons 10,566,462 23 ex-rna fBrain 8,385,799 24 chainVicPac2 ex-anno 5,745,319 25 chainOrnAna1 ex-anno 4,408,383 26 chainOrnAna1 exons 3,255,513 27 chainRn4 ex-anno 2,761,621 28 chainRn4 exons 2,633,098 29 chainMonDom5Link fBrain 2,380,147 30 fBrain chainXenTro3Link 625,718 31 fBrain chainOrnAna1 398,738 32 fBrain chainVicPac2 357,564 33 chainRn4 fBrain 320,955 34 ex-anno exons 273,500 35 fBrain ex-anno 73,437 36 fBrain exons 54,246 <p>Source: Calculated with polars-bio (using 0-based coordinates) in streaming mode.</p> <p>All Parquet files from this dataset shared the same schema: </p><pre><code>  contig STRING\n  pos_start INT32\n  pos_end INT32\n</code></pre><p></p>"},{"location":"supplement/#synthetic-dataset","title":"Synthetic dataset","text":"<p>Randomly generated intervals (100-10,000,000) inspired by bioframe performance analysis. Generated with generate_dataset.py </p><pre><code>poetry run python src/generate_dataset.py\n</code></pre> All Parquet files from this dataset shared the same schema: <pre><code>  contig STRING\n  pos_start INT64\n  pos_end INT64\n</code></pre><p></p> <p>Note</p> <p>Test datasets in the Parquet format can be downloaded from:</p> <ul> <li>single thread benchmarks<ul> <li>databio.zip</li> <li>random_intervals_20250622_221714-1p.zip</li> </ul> </li> <li>parallel benchmarks (partitioned)<ul> <li>databio-8p.zip</li> <li>random_intervals_20250622_221714-8p.zip</li> </ul> </li> </ul>"},{"location":"supplement/#overlap-summary","title":"Overlap summary","text":"Test case polars_bio<sup>1</sup> - # of overlaps bioframe<sup>2</sup> - # of overlaps pyranges0 - # of overlaps pyranges1 - # of overlaps 1-2 54,246 54,246 54,246 54,246 8-7 307,184,634 307,184,634 307,184,634 307,184,634 100 781 781 781 781 1000 8,859 8,859 8,859 8,859 10000 90,236 90,236 90,236 90,236 100000 902,553 902,553 902,553 902,553 1000000 9,007,817 9,007,817 9,007,817 9,007,817 10000000 90,005,371 90,005,371 90,005,371 90,005,371 <p><sup>1</sup> bioframe and pyranges are zero-based, this is why we need to set <code>use_zero_based=True</code> (polars-bio &gt;= 0.10.3) in polars-bio to get the same results as in bioframe and pyranges.</p> <p><sup>2</sup> bioframe <code>how</code> parameter is set to <code>inner</code> (<code>left</code> by default)</p>"},{"location":"supplement/#summary-statistics","title":"Summary statistics","text":""},{"location":"supplement/#single-thread-results","title":"Single-thread results","text":"<p>Results for <code>overlap</code>, <code>nearest</code>, <code>count-overlaps</code>, and <code>coverage</code> operations with single-thread performance on <code>apple-m3-max</code> and <code>gcp-linux</code> platforms.</p> <p>Note</p> <p>Please note that in case of <code>pyranges0</code> we were unable to compute the results of coverage and count-overlaps operations for macOS and Linux in the synthetic benchmark, so the results are not presented here.</p> <p></p>"},{"location":"supplement/#exec-1--apple-m3-max","title":"apple-m3-max","text":""},{"location":"supplement/#exec-1--1-2","title":"1-2","text":""},{"location":"supplement/#exec-1--overlap","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.035619 0.043113 0.0383 2.70x bioframe 0.102257 0.104425 0.103354 1.00x pyranges0 0.025425 0.032821 0.028001 3.69x pyranges1 0.059608 0.064147 0.061763 1.67x pybedtools 0.343204 0.352804 0.348434 0.30x genomicranges 1.042893 1.044245 1.043488 0.10x"},{"location":"supplement/#exec-1--nearest","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.039943 0.045166 0.042109 4.45x bioframe 0.185452 0.189631 0.187388 1.00x pyranges0 0.092334 0.09634 0.093688 2.00x pyranges1 0.133631 0.134179 0.133981 1.40x pybedtools 0.756676 0.761866 0.75953 0.25x"},{"location":"supplement/#exec-1--count-overlaps","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.026706 0.029754 0.028142 4.69x bioframe 0.131124 0.133729 0.132052 1.00x pyranges0 0.039136 0.039774 0.039377 3.35x pyranges1 0.061976 0.063181 0.062658 2.11x pybedtools 0.665804 0.673844 0.668534 0.20x genomicranges 0.994963 1.006435 0.999389 0.13x"},{"location":"supplement/#exec-1--coverage","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.0262 0.028749 0.027418 6.30x bioframe 0.16949 0.176628 0.172842 1.00x pyranges0 0.07376 0.076708 0.075369 2.29x pyranges1 0.128027 0.133263 0.130247 1.33x pybedtools 0.701817 0.708726 0.705839 0.24x genomicranges 1.032651 1.049059 1.040799 0.17x"},{"location":"supplement/#exec-1--8-7","title":"8-7","text":""},{"location":"supplement/#exec-1--overlap_1","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.987391 4.648581 4.235518 7.17x bioframe 29.793837 30.991576 30.375518 1.00x pyranges0 15.632212 15.974075 15.857213 1.92x pyranges1 31.622804 33.699074 32.680701 0.93x pybedtools 916.711575 919.974811 918.154834 0.03x genomicranges 479.214112 487.832054 484.579554 0.06x"},{"location":"supplement/#exec-1--nearest_1","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 2.116922 2.169534 2.139006 32.13x bioframe 68.581465 68.992651 68.725495 1.00x pyranges0 1.381964 1.508513 1.424446 48.25x pyranges1 2.697684 2.728407 2.717532 25.29x pybedtools 35.528719 35.876667 35.699544 1.93x"},{"location":"supplement/#exec-1--count-overlaps_1","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.445467 1.484052 1.46225 58.77x bioframe 85.632767 86.26148 85.935955 1.00x pyranges0 9.674847 9.833233 9.753982 8.81x pyranges1 10.170249 10.254359 10.201813 8.42x pybedtools 33.101592 33.966188 33.423595 2.57x genomicranges 488.972732 490.395787 489.548184 0.18x"},{"location":"supplement/#exec-1--coverage_1","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.195279 1.205765 1.199323 20.45x bioframe 24.423391 24.682901 24.525909 1.00x pyranges0 11.093644 11.328071 11.220416 2.19x pyranges1 11.987003 12.147925 12.066045 2.03x pybedtools 59.699275 60.04087 59.84965 0.41x genomicranges 500.041974 503.31936 502.043072 0.05x"},{"location":"supplement/#exec-1--100-1p","title":"100-1p","text":""},{"location":"supplement/#exec-1--overlap_2","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.002471 0.006262 0.003855 0.54x bioframe 0.001374 0.002735 0.002067 1.00x pyranges0 0.000977 0.001952 0.001337 1.55x pyranges1 0.002276 0.003591 0.002739 0.75x pybedtools 0.006856 0.010064 0.008032 0.26x genomicranges 0.001784 0.002115 0.001938 1.07x pygenomics 0.000475 0.000541 0.000509 4.06x"},{"location":"supplement/#exec-1--nearest_2","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.002802 0.007312 0.004371 0.51x bioframe 0.00157 0.00347 0.002251 1.00x pyranges0 0.00135 0.004085 0.002281 0.99x pyranges1 0.002084 0.003622 0.002633 0.85x pybedtools 0.005288 0.023073 0.011717 0.19x"},{"location":"supplement/#exec-1--count-overlaps_2","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.001892 0.006355 0.003397 0.52x bioframe 0.001563 0.002165 0.001775 1.00x pyranges1 0.00181 0.002209 0.001972 0.90x pybedtools 0.020892 0.062978 0.036866 0.05x genomicranges 0.001896 0.002057 0.001957 0.91x"},{"location":"supplement/#exec-1--coverage_2","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.001911 0.006057 0.003343 1.03x bioframe 0.003065 0.00411 0.003452 1.00x pyranges1 0.004455 0.005845 0.005021 0.69x pybedtools 0.02477 0.059532 0.037421 0.09x"},{"location":"supplement/#exec-1--1000-1p","title":"1000-1p","text":""},{"location":"supplement/#exec-1--overlap_3","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.00262 0.004367 0.003278 0.71x bioframe 0.001909 0.002988 0.002313 1.00x pyranges0 0.001361 0.00182 0.001543 1.50x pyranges1 0.002678 0.003166 0.002927 0.79x pybedtools 0.037238 0.039737 0.038453 0.06x genomicranges 0.019265 0.019945 0.01957 0.12x pygenomics 0.006876 0.006994 0.006949 0.33x"},{"location":"supplement/#exec-1--nearest_3","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.003048 0.0083 0.00553 0.65x bioframe 0.003269 0.004119 0.003604 1.00x pyranges0 0.002514 0.003506 0.003099 1.16x pyranges1 0.003722 0.00418 0.003935 0.92x pybedtools 0.00881 0.011281 0.009729 0.37x"},{"location":"supplement/#exec-1--count-overlaps_3","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.001854 0.004714 0.002898 1.00x bioframe 0.002523 0.003547 0.002898 1.00x pyranges1 0.002302 0.002838 0.002498 1.16x pybedtools 0.032681 0.047822 0.037981 0.08x genomicranges 0.020029 0.02029 0.020192 0.14x"},{"location":"supplement/#exec-1--coverage_3","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.002202 0.003516 0.002696 1.77x bioframe 0.004238 0.005691 0.004758 1.00x pyranges1 0.004909 0.005934 0.005284 0.90x pybedtools 0.030735 0.045004 0.03646 0.13x"},{"location":"supplement/#exec-1--10000-1p","title":"10000-1p","text":""},{"location":"supplement/#exec-1--overlap_4","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004603 0.008294 0.006073 1.81x bioframe 0.010529 0.011367 0.011014 1.00x pyranges0 0.006498 0.007306 0.006811 1.62x pyranges1 0.01096 0.012611 0.011684 0.94x pybedtools 0.94646 0.94995 0.948121 0.01x genomicranges 0.198868 0.200266 0.199428 0.06x pygenomics 0.080325 0.08121 0.080663 0.14x"},{"location":"supplement/#exec-1--nearest_4","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004851 0.007782 0.005908 4.50x bioframe 0.025947 0.027779 0.026584 1.00x pyranges0 0.00501 0.005703 0.00526 5.05x pyranges1 0.007517 0.007937 0.00769 3.46x pybedtools 0.040749 0.043864 0.041889 0.63x"},{"location":"supplement/#exec-1--count-overlaps_4","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.003283 0.008069 0.005083 3.12x bioframe 0.014669 0.016689 0.015834 1.00x pyranges1 0.007637 0.008979 0.008178 1.94x pybedtools 0.720797 0.730655 0.725407 0.02x genomicranges 0.202131 0.209398 0.204628 0.08x"},{"location":"supplement/#exec-1--coverage_4","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.002756 0.004613 0.003377 3.06x bioframe 0.009849 0.011243 0.010339 1.00x pyranges1 0.01326 0.015308 0.013973 0.74x pybedtools 0.727294 0.733098 0.73116 0.01x"},{"location":"supplement/#exec-1--100000-1p","title":"100000-1p","text":""},{"location":"supplement/#exec-1--overlap_5","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.030583 0.038892 0.033394 3.33x bioframe 0.108358 0.115233 0.111059 1.00x pyranges0 0.059633 0.065599 0.061791 1.80x pyranges1 0.100074 0.105947 0.102267 1.09x pybedtools 13.434458 13.602339 13.496321 0.01x genomicranges 2.030365 2.052434 2.039897 0.05x pygenomics 1.001974 1.018231 1.009213 0.11x"},{"location":"supplement/#exec-1--nearest_5","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.03013 0.036718 0.03339 10.61x bioframe 0.352786 0.356839 0.354241 1.00x pyranges0 0.032403 0.034701 0.033667 10.52x pyranges1 0.044958 0.046169 0.045629 7.76x pybedtools 0.369122 0.379131 0.3729 0.95x"},{"location":"supplement/#exec-1--count-overlaps_5","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.021035 0.026894 0.023802 13.86x bioframe 0.308013 0.347919 0.329806 1.00x pyranges1 0.076199 0.085019 0.079372 4.16x pybedtools 11.056327 11.280248 11.149039 0.03x genomicranges 2.057607 2.07651 2.067998 0.16x"},{"location":"supplement/#exec-1--coverage_5","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.013263 0.014998 0.013874 5.68x bioframe 0.077717 0.081116 0.078865 1.00x pyranges1 0.094753 0.114552 0.10257 0.77x pybedtools 11.374602 11.428316 11.393849 0.01x"},{"location":"supplement/#exec-1--1000000-1p","title":"1000000-1p","text":""},{"location":"supplement/#exec-1--overlap_6","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.482548 0.538737 0.507383 2.55x bioframe 1.26082 1.35031 1.296195 1.00x pyranges0 0.775969 0.828801 0.810501 1.60x pyranges1 1.272326 1.29706 1.28585 1.01x"},{"location":"supplement/#exec-1--nearest_6","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.439544 0.488414 0.458975 14.86x bioframe 6.592501 7.111734 6.818208 1.00x pyranges0 0.398173 0.413055 0.406623 16.77x pyranges1 0.51649 0.520946 0.518407 13.15x"},{"location":"supplement/#exec-1--count-overlaps_6","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.257781 0.305275 0.28525 17.65x bioframe 4.640915 5.437883 5.033454 1.00x pyranges1 0.916714 0.925945 0.920594 5.47x"},{"location":"supplement/#exec-1--coverage_6","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.128241 0.137198 0.132474 7.71x bioframe 0.996542 1.065777 1.021738 1.00x pyranges1 1.115134 1.247674 1.172964 0.87x"},{"location":"supplement/#exec-1--10000000-1p","title":"10000000-1p","text":""},{"location":"supplement/#exec-1--overlap_7","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 8.532137 9.738828 8.978132 2.20x bioframe 19.276665 20.295566 19.708064 1.00x pyranges0 14.819439 15.339048 15.092611 1.31x pyranges1 20.153432 22.654892 21.56345 0.91x"},{"location":"supplement/#exec-1--nearest_7","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 7.12779 7.490779 7.263011 22.17x bioframe 156.356696 169.531002 160.989714 1.00x pyranges0 6.402183 6.879779 6.62806 24.29x pyranges1 7.526236 8.176338 7.857803 20.49x"},{"location":"supplement/#exec-1--count-overlaps_7","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 4.887937 5.553197 5.165014 20.21x bioframe 102.637625 105.903506 104.389343 1.00x pyranges1 13.35283 15.167609 14.19713 7.35x"},{"location":"supplement/#exec-1--coverage_7","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.627897 1.683304 1.655288 9.86x bioframe 15.586487 16.774274 16.316676 1.00x pyranges1 16.99118 17.447484 17.195844 0.95x"},{"location":"supplement/#exec-1--gcp-linux","title":"gcp-linux","text":""},{"location":"supplement/#exec-1--1-2_1","title":"1-2","text":""},{"location":"supplement/#exec-1--overlap_8","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.045943 0.064732 0.054234 1.66x bioframe 0.084137 0.099481 0.090107 1.00x pyranges0 0.056206 0.065654 0.061844 1.46x pyranges1 0.09908 0.119018 0.106228 0.85x pybedtools 0.38246 0.406379 0.39153 0.23x genomicranges 1.19939 1.224621 1.208255 0.07x"},{"location":"supplement/#exec-1--nearest_8","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.057012 0.073822 0.064665 2.49x bioframe 0.158764 0.165707 0.161273 1.00x pyranges0 0.172297 0.176259 0.17363 0.93x pyranges1 0.217619 0.234088 0.22335 0.72x pybedtools 0.845945 0.84898 0.847447 0.19x"},{"location":"supplement/#exec-1--count-overlaps_8","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.035631 0.043555 0.04066 2.74x bioframe 0.108015 0.116522 0.111266 1.00x pyranges0 0.077336 0.080282 0.07844 1.42x pyranges1 0.100883 0.106671 0.103181 1.08x pybedtools 0.745958 0.759006 0.754393 0.15x genomicranges 1.154942 1.164158 1.158506 0.10x"},{"location":"supplement/#exec-1--coverage_8","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.036476 0.040001 0.037897 5.10x bioframe 0.189201 0.20046 0.193401 1.00x pyranges0 0.141659 0.14424 0.143188 1.35x pyranges1 0.206033 0.224902 0.213089 0.91x pybedtools 0.773732 0.780424 0.776934 0.25x genomicranges 1.186341 1.194172 1.189255 0.16x"},{"location":"supplement/#exec-1--8-7_1","title":"8-7","text":""},{"location":"supplement/#exec-1--overlap_9","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 6.235223 9.61441 7.723144 6.54x bioframe 50.319263 50.956633 50.537202 1.00x pyranges0 36.371926 36.581642 36.448645 1.39x pyranges1 63.336711 63.455435 63.40654 0.80x pybedtools 1149.001487 1152.127068 1150.070659 0.04x genomicranges 597.951648 599.960895 599.002871 0.08x"},{"location":"supplement/#exec-1--nearest_9","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.576373 3.679698 3.633697 15.54x bioframe 56.301865 56.776617 56.464305 1.00x pyranges0 2.45308 2.60494 2.505172 22.54x pyranges1 4.975662 5.011008 4.997007 11.30x pybedtools 44.181913 44.79409 44.386971 1.27x"},{"location":"supplement/#exec-1--count-overlaps_9","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 2.052196 2.104447 2.075706 38.15x bioframe 79.174164 79.234115 79.194209 1.00x pyranges0 18.797436 18.851941 18.824498 4.21x pyranges1 20.399172 20.436149 20.418562 3.88x pybedtools 35.850631 36.142479 36.041115 2.20x genomicranges 612.985873 613.52087 613.229997 0.13x"},{"location":"supplement/#exec-1--coverage_9","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.829478 1.838981 1.834999 15.44x bioframe 28.29136 28.361417 28.326821 1.00x pyranges0 18.611247 20.021441 19.473105 1.45x pyranges1 22.118838 22.210733 22.161329 1.28x pybedtools 74.477086 74.868659 74.618066 0.38x genomicranges 623.865655 623.94955 623.896645 0.05x"},{"location":"supplement/#exec-1--100-1p_1","title":"100-1p","text":""},{"location":"supplement/#exec-1--overlap_10","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004992 0.01456 0.008429 0.47x bioframe 0.003258 0.005112 0.00392 1.00x pyranges0 0.002368 0.003408 0.002777 1.41x pyranges1 0.005606 0.006547 0.005975 0.66x pybedtools 0.005909 0.006483 0.006194 0.63x genomicranges 0.003124 0.003404 0.003233 1.21x pygenomics 0.000777 0.000879 0.000818 4.79x"},{"location":"supplement/#exec-1--nearest_10","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.039758 0.157059 0.082499 0.06x bioframe 0.004496 0.005139 0.004808 1.00x pyranges1 0.005232 0.006285 0.005613 0.86x pybedtools 0.002655 0.002957 0.002758 1.74x"},{"location":"supplement/#exec-1--count-overlaps_10","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004349 0.072032 0.027109 0.16x bioframe 0.003966 0.004761 0.004247 1.00x pyranges0 0.002885 0.00314 0.002973 1.43x pyranges1 0.004525 0.004943 0.004694 0.90x pybedtools 0.002502 0.002934 0.0027 1.57x genomicranges 0.003229 0.003376 0.003278 1.30x"},{"location":"supplement/#exec-1--coverage_10","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004251 0.062087 0.0237 0.37x bioframe 0.007449 0.011114 0.008755 1.00x pyranges1 0.010586 0.012078 0.011134 0.79x pybedtools 0.002555 0.002829 0.002686 3.26x"},{"location":"supplement/#exec-1--1000-1p_1","title":"1000-1p","text":""},{"location":"supplement/#exec-1--overlap_11","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.005234 0.008876 0.006523 0.77x bioframe 0.004581 0.005864 0.005016 1.00x pyranges0 0.003191 0.003455 0.003296 1.52x pyranges1 0.008031 0.008103 0.008074 0.62x pybedtools 0.053782 0.054005 0.053929 0.09x genomicranges 0.032026 0.032674 0.032265 0.16x pygenomics 0.010626 0.01142 0.010918 0.46x"},{"location":"supplement/#exec-1--nearest_11","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.005791 0.006665 0.006123 1.01x bioframe 0.005982 0.006628 0.00621 1.00x pyranges0 0.006279 0.006752 0.006447 0.96x pyranges1 0.009039 0.009504 0.009217 0.67x pybedtools 0.007826 0.007978 0.007917 0.78x"},{"location":"supplement/#exec-1--count-overlaps_11","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004343 0.007692 0.005481 0.98x bioframe 0.005139 0.005735 0.005359 1.00x pyranges1 0.005589 0.005976 0.005719 0.94x pybedtools 0.01436 0.014635 0.014456 0.37x genomicranges 0.032931 0.03307 0.033016 0.16x"},{"location":"supplement/#exec-1--coverage_11","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.004259 0.005305 0.004947 2.08x bioframe 0.009969 0.010782 0.010297 1.00x pyranges1 0.011982 0.012304 0.012103 0.85x pybedtools 0.014775 0.015246 0.014956 0.69x"},{"location":"supplement/#exec-1--10000-1p_1","title":"10000-1p","text":""},{"location":"supplement/#exec-1--overlap_12","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.01015 0.018572 0.013027 1.84x bioframe 0.02268 0.025605 0.023968 1.00x pyranges0 0.016065 0.018936 0.017143 1.40x pyranges1 0.030509 0.031181 0.030868 0.78x pybedtools 1.335037 1.358509 1.345311 0.02x genomicranges 0.322956 0.326403 0.324169 0.07x pygenomics 0.136783 0.141169 0.13853 0.17x"},{"location":"supplement/#exec-1--nearest_12","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.009616 0.011293 0.010447 3.08x bioframe 0.031761 0.032938 0.032167 1.00x pyranges0 0.010939 0.011387 0.01109 2.90x pyranges1 0.015275 0.015676 0.015419 2.09x pybedtools 0.059244 0.059899 0.059542 0.54x"},{"location":"supplement/#exec-1--count-overlaps_12","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.007028 0.007725 0.007363 2.50x bioframe 0.018051 0.019179 0.018436 1.00x pyranges1 0.014252 0.014683 0.014423 1.28x pybedtools 0.926946 1.012523 0.973852 0.02x genomicranges 0.330064 0.33175 0.331123 0.06x"},{"location":"supplement/#exec-1--coverage_12","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.005994 0.006967 0.006396 2.78x bioframe 0.017402 0.018389 0.017779 1.00x pyranges1 0.022651 0.023034 0.022779 0.78x pybedtools 0.952175 1.000698 0.97678 0.02x"},{"location":"supplement/#exec-1--100000-1p_1","title":"100000-1p","text":""},{"location":"supplement/#exec-1--overlap_13","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.059271 0.08788 0.070483 3.02x bioframe 0.209074 0.218512 0.21252 1.00x pyranges0 0.144653 0.164863 0.151749 1.40x pyranges1 0.228314 0.247017 0.234636 0.91x pybedtools 19.263571 19.313483 19.286741 0.01x genomicranges 3.290473 3.294306 3.291987 0.06x pygenomics 1.881858 1.924059 1.896222 0.11x"},{"location":"supplement/#exec-1--nearest_13","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.054573 0.060741 0.057958 6.31x bioframe 0.363422 0.368554 0.365524 1.00x pyranges0 0.062446 0.06448 0.06321 5.78x pyranges1 0.084614 0.086633 0.085545 4.27x pybedtools 0.570352 0.57555 0.572301 0.64x"},{"location":"supplement/#exec-1--count-overlaps_13","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.034675 0.047883 0.039593 7.85x bioframe 0.309819 0.311936 0.310958 1.00x pyranges1 0.113469 0.114316 0.113866 2.73x pybedtools 15.265868 16.802575 16.206183 0.02x genomicranges 3.369224 3.374411 3.371411 0.09x"},{"location":"supplement/#exec-1--coverage_13","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.02543 0.026808 0.026079 4.08x bioframe 0.104575 0.1096 0.106393 1.00x pyranges1 0.147505 0.151673 0.149512 0.71x pybedtools 16.382024 17.619212 16.802475 0.01x"},{"location":"supplement/#exec-1--1000000-1p_1","title":"1000000-1p","text":""},{"location":"supplement/#exec-1--overlap_14","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.947673 1.10915 1.003667 2.49x bioframe 2.490142 2.513556 2.499533 1.00x pyranges0 2.119717 2.178453 2.148959 1.16x pyranges1 3.274957 3.298976 3.288601 0.76x"},{"location":"supplement/#exec-1--nearest_14","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.771199 0.783292 0.777746 6.96x bioframe 5.394265 5.434618 5.411728 1.00x pyranges0 0.874484 0.932857 0.901145 6.01x pyranges1 1.127032 1.149141 1.140538 4.74x"},{"location":"supplement/#exec-1--count-overlaps_14","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.501775 0.530884 0.514401 8.01x bioframe 4.117035 4.131015 4.121744 1.00x pyranges1 1.583204 1.678121 1.631619 2.53x"},{"location":"supplement/#exec-1--coverage_14","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.247626 0.266565 0.256522 4.86x bioframe 1.243608 1.250394 1.246153 1.00x pyranges1 1.916323 2.005555 1.949487 0.64x"},{"location":"supplement/#exec-1--10000000-1p_1","title":"10000000-1p","text":""},{"location":"supplement/#exec-1--overlap_15","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 18.531273 18.806266 18.632293 1.62x bioframe 30.074841 30.116671 30.097846 1.00x pyranges0 29.579651 30.536834 29.904783 1.01x pyranges1 42.196037 42.278681 42.232728 0.71x"},{"location":"supplement/#exec-1--nearest_15","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 14.43136 14.548645 14.496101 5.56x bioframe 80.443039 80.705181 80.548879 1.00x pyranges0 13.64936 14.330292 13.882901 5.80x pyranges1 17.384461 17.654503 17.561143 4.59x"},{"location":"supplement/#exec-1--count-overlaps_15","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 9.812223 9.925855 9.856571 6.23x bioframe 61.348815 61.558393 61.444649 1.00x pyranges1 24.969282 25.069392 25.029806 2.45x"},{"location":"supplement/#exec-1--coverage_15","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.188742 3.31096 3.235061 6.11x bioframe 19.748385 19.802079 19.778009 1.00x pyranges1 30.304058 30.446378 30.353857 0.65x"},{"location":"supplement/#parallel-performance","title":"Parallel performance","text":"<p>Results for parallel operations with 1, 2, 4, 6 and 8 threads.</p> <p></p>"},{"location":"supplement/#exec-2--apple-m3-max","title":"apple-m3-max","text":""},{"location":"supplement/#exec-2--8-7-8p","title":"8-7-8p","text":""},{"location":"supplement/#exec-2--overlap","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.247022 3.803021 3.370889 1.00x polars_bio-2 1.798569 1.848162 1.811417 1.86x polars_bio-4 1.140229 1.158243 1.147355 2.94x polars_bio-6 0.959703 0.968725 0.962915 3.50x polars_bio-8 0.694637 0.710492 0.701048 4.81x"},{"location":"supplement/#exec-2--nearest","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 2.186354 2.248171 2.220822 1.00x polars_bio-2 1.162969 1.222115 1.187505 1.87x polars_bio-4 0.708508 0.735763 0.720115 3.08x polars_bio-6 0.632877 0.652955 0.642816 3.45x polars_bio-8 0.456674 0.476473 0.465284 4.77x"},{"location":"supplement/#exec-2--count-overlaps","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.502551 1.534006 1.515078 1.00x polars_bio-2 0.811236 0.821365 0.815682 1.86x polars_bio-4 0.440628 0.46778 0.455358 3.33x polars_bio-6 0.331317 0.338207 0.334638 4.53x polars_bio-8 0.280465 0.282707 0.281311 5.39x"},{"location":"supplement/#exec-2--coverage","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.181806 1.185549 1.183889 1.00x polars_bio-2 0.644288 0.645076 0.644587 1.84x polars_bio-4 0.362752 0.363411 0.363036 3.26x polars_bio-6 0.258583 0.272702 0.264111 4.48x polars_bio-8 0.222888 0.234884 0.229052 5.17x"},{"location":"supplement/#exec-2--1000000-8p","title":"1000000-8p","text":""},{"location":"supplement/#exec-2--overlap_1","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.468442 0.523065 0.494609 1.00x polars_bio-2 0.262861 0.26828 0.265028 1.87x polars_bio-4 0.1629 0.166657 0.164536 3.01x polars_bio-6 0.137724 0.146893 0.143772 3.44x polars_bio-8 0.111952 0.11465 0.113521 4.36x"},{"location":"supplement/#exec-2--nearest_1","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.393067 0.415076 0.404032 1.00x polars_bio-2 0.234559 0.235746 0.235051 1.72x polars_bio-4 0.158996 0.167352 0.16349 2.47x polars_bio-6 0.14634 0.14935 0.148215 2.73x polars_bio-8 0.125472 0.128158 0.126606 3.19x"},{"location":"supplement/#exec-2--count-overlaps_1","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.267875 0.296727 0.277677 1.00x polars_bio-2 0.163662 0.170045 0.165917 1.67x polars_bio-4 0.111136 0.114835 0.112891 2.46x polars_bio-6 0.097944 0.104607 0.101477 2.74x polars_bio-8 0.099474 0.117493 0.106059 2.62x"},{"location":"supplement/#exec-2--coverage_1","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.128377 0.131261 0.129598 1.00x polars_bio-2 0.081762 0.085104 0.08324 1.56x polars_bio-4 0.064151 0.066197 0.064851 2.00x polars_bio-6 0.066926 0.06892 0.06768 1.91x polars_bio-8 0.072767 0.074339 0.073589 1.76x"},{"location":"supplement/#exec-2--10000000-8p","title":"10000000-8p","text":""},{"location":"supplement/#exec-2--overlap_2","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 9.081732 9.388126 9.203018 1.00x polars_bio-2 4.696455 4.912478 4.793254 1.92x polars_bio-4 2.885023 2.902893 2.896218 3.18x polars_bio-6 2.196605 2.217945 2.209839 4.16x polars_bio-8 1.813586 1.860947 1.833498 5.02x"},{"location":"supplement/#exec-2--nearest_2","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 7.299887 7.659385 7.495962 1.00x polars_bio-2 4.01928 4.158504 4.069511 1.84x polars_bio-4 2.683383 2.720981 2.704975 2.77x polars_bio-6 2.141075 2.162109 2.150595 3.49x polars_bio-8 1.859186 1.865634 1.862653 4.02x"},{"location":"supplement/#exec-2--count-overlaps_2","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 5.30938 5.450332 5.381068 1.00x polars_bio-2 2.893766 2.91378 2.906401 1.85x polars_bio-4 1.748771 1.797485 1.768895 3.04x polars_bio-6 1.352671 1.385655 1.369312 3.93x polars_bio-8 1.178559 1.199971 1.192577 4.51x"},{"location":"supplement/#exec-2--coverage_2","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 1.638818 1.678156 1.655573 1.00x polars_bio-2 0.994195 0.996554 0.995701 1.66x polars_bio-4 0.678722 0.701234 0.689151 2.40x polars_bio-6 0.620289 0.662175 0.639026 2.59x polars_bio-8 0.570659 0.582937 0.57688 2.87x"},{"location":"supplement/#exec-2--gcp-linux","title":"gcp-linux","text":""},{"location":"supplement/#exec-2--8-7-8p_1","title":"8-7-8p","text":""},{"location":"supplement/#exec-2--overlap_3","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 6.325617 8.185275 7.005925 1.00x polars_bio-2 3.920645 4.617084 4.198055 1.67x polars_bio-4 3.036273 3.060781 3.0452 2.30x polars_bio-6 2.127994 2.134505 2.131016 3.29x polars_bio-8 1.731485 1.789347 1.752986 4.00x"},{"location":"supplement/#exec-2--nearest_3","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 4.047329 4.439016 4.198198 1.00x polars_bio-2 2.624132 2.722843 2.682361 1.57x polars_bio-4 1.809028 1.917798 1.871763 2.24x polars_bio-6 1.309557 1.362131 1.333989 3.15x polars_bio-8 1.066945 1.113168 1.087907 3.86x"},{"location":"supplement/#exec-2--count-overlaps_3","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 2.426441 2.456318 2.439266 1.00x polars_bio-2 1.22516 1.272066 1.245401 1.96x polars_bio-4 0.711421 0.744023 0.724315 3.37x polars_bio-6 0.563797 0.607321 0.580574 4.20x polars_bio-8 0.459308 0.493886 0.479126 5.09x"},{"location":"supplement/#exec-2--coverage_3","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 2.212958 2.23035 2.222531 1.00x polars_bio-2 1.132056 1.15405 1.146413 1.94x polars_bio-4 0.645737 0.661564 0.652277 3.41x polars_bio-6 0.50589 0.511256 0.50839 4.37x polars_bio-8 0.439503 0.450924 0.447075 4.97x"},{"location":"supplement/#exec-2--1000000-8p_1","title":"1000000-8p","text":""},{"location":"supplement/#exec-2--overlap_4","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.903831 1.098046 0.974229 1.00x polars_bio-2 0.50099 0.512259 0.504852 1.93x polars_bio-4 0.300453 0.328605 0.318188 3.06x polars_bio-6 0.257792 0.278203 0.268718 3.63x polars_bio-8 0.22321 0.243244 0.230621 4.22x"},{"location":"supplement/#exec-2--nearest_4","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.758815 0.78919 0.769877 1.00x polars_bio-2 0.465192 0.47484 0.468824 1.64x polars_bio-4 0.332101 0.336953 0.334461 2.30x polars_bio-6 0.276071 0.29266 0.281794 2.73x polars_bio-8 0.237269 0.263256 0.254046 3.03x"},{"location":"supplement/#exec-2--count-overlaps_4","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.496938 0.517659 0.505043 1.00x polars_bio-2 0.295325 0.313859 0.302686 1.67x polars_bio-4 0.194371 0.20433 0.200853 2.51x polars_bio-6 0.175505 0.181913 0.178222 2.83x polars_bio-8 0.15672 0.163036 0.160701 3.14x"},{"location":"supplement/#exec-2--coverage_4","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 0.245895 0.250118 0.247479 1.00x polars_bio-2 0.167378 0.173578 0.171251 1.45x polars_bio-4 0.122749 0.126635 0.124491 1.99x polars_bio-6 0.11385 0.119157 0.116185 2.13x polars_bio-8 0.108127 0.110327 0.10942 2.26x"},{"location":"supplement/#exec-2--10000000-8p_1","title":"10000000-8p","text":""},{"location":"supplement/#exec-2--overlap_5","title":"overlap","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 18.215782 19.091392 18.510207 1.00x polars_bio-2 9.399565 9.680242 9.566631 1.93x polars_bio-4 5.303647 5.555487 5.442898 3.40x polars_bio-6 4.022274 4.066371 4.051045 4.57x polars_bio-8 3.369559 3.416123 3.388564 5.46x"},{"location":"supplement/#exec-2--nearest_5","title":"nearest","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 14.325736 14.444885 14.39027 1.00x polars_bio-2 8.095907 8.178189 8.136852 1.77x polars_bio-4 5.096407 5.15379 5.122893 2.81x polars_bio-6 3.986362 4.205706 4.128561 3.49x polars_bio-8 3.491618 3.711814 3.577309 4.02x"},{"location":"supplement/#exec-2--count-overlaps_5","title":"count-overlaps","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 9.701679 9.796148 9.740035 1.00x polars_bio-2 5.346433 5.399117 5.370757 1.81x polars_bio-4 3.150557 3.203458 3.178719 3.06x polars_bio-6 2.485947 2.56386 2.52768 3.85x polars_bio-8 2.156472 2.176608 2.163483 4.50x"},{"location":"supplement/#exec-2--coverage_5","title":"coverage","text":"Library Min (s) Max (s) Mean (s) Speedup polars_bio 3.091184 3.216964 3.135982 1.00x polars_bio-2 1.998423 2.041581 2.01331 1.56x polars_bio-4 1.412483 1.45218 1.426102 2.20x polars_bio-6 1.281432 1.328666 1.301256 2.41x polars_bio-8 1.176944 1.193294 1.18414 2.65x"},{"location":"supplement/#end-to-end-tests","title":"End to end tests","text":"<p>Results for an end-to-end test with calculating overlaps, nearest, coverage and count overlaps and saving results to a CSV file.</p> <p>Note</p> <p>Please note that in case of <code>pyranges0</code> we were unable to export the results of coverage and count-overlaps operations to a CSV file, so the results are not presented here.</p> <p></p>"},{"location":"supplement/#exec-3--apple-m3-max","title":"apple-m3-max","text":""},{"location":"supplement/#exec-3--1-2","title":"1-2","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.042378 0.130957 0.071929 3.10x 285.468 polars_bio_streaming 0.035498 0.037438 0.036653 6.09x 274.093 bioframe 0.208548 0.251457 0.223219 1.00x 300.75 pyranges0 0.409707 0.415361 0.412135 0.54x 329.968 pyranges1 0.47518 0.491508 0.482739 0.46x 324.468"},{"location":"supplement/#exec-3--e2e-nearest-csv","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.053349 0.058382 0.055362 9.14x 321.062 polars_bio_streaming 0.051385 0.053979 0.052764 9.59x 311.422 bioframe 0.503887 0.510257 0.506123 1.00x 316.969 pyranges0 1.135469 1.183369 1.151801 0.44x 364.594 pyranges1 1.327935 1.334101 1.331346 0.38x 357.734"},{"location":"supplement/#exec-3--e2e-coverage-csv","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.034756 0.038718 0.036421 13.40x 290.078 polars_bio_streaming 0.03607 0.037332 0.036534 13.35x 274.344 bioframe 0.48449 0.492328 0.487891 1.00x 419.312 pyranges1 0.971084 0.980085 0.975012 0.50x 407.562"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.03452 0.037714 0.035927 9.27x 294.266 polars_bio_streaming 0.035863 0.036756 0.036414 9.14x 278.438 bioframe 0.328145 0.338734 0.332951 1.00x 306.234 pyranges1 0.532739 0.544914 0.538646 0.62x 328.328"},{"location":"supplement/#exec-3--8-7","title":"8-7","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_1","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 22.781745 23.916568 23.161559 16.64x 14677.0468 polars_bio_streaming 18.501279 18.797602 18.676707 20.63x 555.109 bioframe 383.108514 387.500069 385.309331 1.00x 33806.062 pyranges0 276.421312 279.839508 277.845198 1.39x 29777.312 pyranges1 355.703878 367.680249 360.875151 1.07x 34526.859"},{"location":"supplement/#exec-3--e2e-nearest-csv_1","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 2.597955 2.760537 2.674482 32.02x 1060.031 polars_bio_streaming 2.65088 2.685157 2.665171 32.13x 560.453 bioframe 85.238305 86.131916 85.644961 1.00x 6894.062 pyranges0 13.530549 13.705834 13.620471 6.29x 3031.797 pyranges1 16.290782 16.385961 16.322671 5.25x 3509.984"},{"location":"supplement/#exec-3--e2e-coverage-csv_1","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 1.523833 1.555472 1.541038 21.41x 717.984 polars_bio_streaming 1.336613 1.397324 1.364051 24.19x 411.703 bioframe 32.294844 33.421618 32.99334 1.00x 16651.922 pyranges1 26.382409 27.382901 27.020202 1.22x 6119.125"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_1","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 1.806838 1.845584 1.82594 54.33x 729.078 polars_bio_streaming 1.681187 1.767811 1.714943 57.85x 416.094 bioframe 97.91802 101.736351 99.210461 1.00x 23029.219 pyranges1 19.498264 19.676838 19.561322 5.07x 5270.234"},{"location":"supplement/#exec-3--100-1p","title":"100-1p","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_2","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.009118 0.077181 0.032054 1.55x 248.594 polars_bio_streaming 0.003382 0.004769 0.003853 12.92x 247.562 bioframe 0.030154 0.088667 0.049769 1.00x 231.641 pyranges0 0.045764 0.051035 0.047857 1.04x 228.516 pyranges1 0.053751 0.072545 0.060221 0.83x 228.609"},{"location":"supplement/#exec-3--e2e-nearest-csv_2","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.009145 0.038799 0.019201 2.24x 253.156 polars_bio_streaming 0.003964 0.005051 0.004504 9.53x 248.188 bioframe 0.033372 0.061107 0.042931 1.00x 229.906 pyranges0 0.049586 0.057381 0.052364 0.82x 231.812 pyranges1 0.054496 0.059205 0.056362 0.76x 231.688"},{"location":"supplement/#exec-3--e2e-coverage-csv_2","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.005492 0.020652 0.012584 5.20x 245.578 polars_bio_streaming 0.003059 0.003746 0.003397 19.25x 243.5 bioframe 0.060684 0.074157 0.065378 1.00x 230.953 pyranges1 0.093668 0.096265 0.094567 0.69x 243.5"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_2","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.005291 0.008843 0.006568 5.53x 249.406 polars_bio_streaming 0.003279 0.003697 0.003447 10.53x 245.672 bioframe 0.032914 0.042309 0.036302 1.00x 234.141 pyranges1 0.045085 0.045477 0.045224 0.80x 232.703"},{"location":"supplement/#exec-3--10000000-1p","title":"10000000-1p","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_3","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 11.109423 11.871893 11.397992 10.38x 7064.312 polars_bio_streaming 12.049206 12.327491 12.191582 9.71x 1505.109 bioframe 117.701516 119.51073 118.356016 1.00x 16380.234 pyranges0 235.484308 243.216406 239.726101 0.49x 14245.203 pyranges1 109.722359 112.326873 111.23273 1.06x 19423.172"},{"location":"supplement/#exec-3--e2e-nearest-csv_3","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 7.842314 8.84828 8.510181 21.04x 2301.0 polars_bio_streaming 7.589706 8.153016 7.842404 22.83x 1327.531 bioframe 174.790383 183.458906 179.035999 1.00x 10996.234 pyranges0 32.793505 32.826686 32.809101 5.46x 4882.656 pyranges1 18.866156 19.570609 19.142653 9.35x 5253.281"},{"location":"supplement/#exec-3--e2e-coverage-csv_3","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 1.901833 1.957711 1.928367 12.15x 956.844 polars_bio_streaming 1.797332 1.802527 1.800497 13.01x 651.266 bioframe 23.269774 23.55838 23.430125 1.00x 6493.234 pyranges1 26.370249 27.172173 26.879266 0.87x 10397.531"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_3","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 5.025462 5.234103 5.129963 20.79x 1036.734 polars_bio_streaming 4.956087 5.076052 5.014242 21.27x 968.719 bioframe 105.322287 107.758078 106.64158 1.00x 12803.828 pyranges1 22.079391 23.069931 22.618209 4.71x 10039.297"},{"location":"supplement/#exec-3--gcp-linux","title":"gcp-linux","text":""},{"location":"supplement/#exec-3--1-2_1","title":"1-2","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_4","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.072393 0.151871 0.09916 2.80x 314.234 polars_bio_streaming 0.064092 0.067914 0.066202 4.19x 288.621 bioframe 0.258278 0.31288 0.277225 1.00x 287.101 pyranges0 0.591745 0.599954 0.595204 0.47x 307.218 pyranges1 0.683388 0.702289 0.690362 0.40x 327.863"},{"location":"supplement/#exec-3--e2e-nearest-csv_4","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.123656 1.702108 0.659015 1.99x 331.398 polars_bio_streaming 0.111801 0.762227 0.328874 3.98x 308.738 bioframe 0.881782 2.161628 1.309551 1.00x 297.695 pyranges0 1.728053 2.579086 2.030527 0.64x 308.93 pyranges1 1.953048 2.161655 2.049615 0.64x 337.352"},{"location":"supplement/#exec-3--e2e-coverage-csv_4","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.064626 0.146983 0.093048 8.11x 299.094 polars_bio_streaming 0.065193 0.072839 0.068651 10.99x 280.387 bioframe 0.704155 0.791049 0.754463 1.00x 328.184 pyranges1 1.41166 1.432833 1.42261 0.53x 352.582"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_4","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.063012 0.207803 0.113156 4.03x 309.176 polars_bio_streaming 0.062735 0.071474 0.065886 6.92x 286.336 bioframe 0.436935 0.491839 0.455688 1.00x 303.07 pyranges1 0.785823 0.786847 0.786487 0.58x 316.227"},{"location":"supplement/#exec-3--8-7_1","title":"8-7","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_5","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 44.539766 45.543038 45.196903 12.55x 14575.14 polars_bio_streaming 34.007093 35.972075 35.309756 16.06x 480.207 bioframe 566.167037 567.617695 567.13069 1.00x 43295.378 pyranges0 417.291061 421.875539 419.571591 1.35x 22915.917 pyranges1 538.365637 548.624613 543.918168 1.04x 43408.699"},{"location":"supplement/#exec-3--e2e-nearest-csv_5","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 6.565142 7.696104 6.973448 12.21x 1070.016 polars_bio_streaming 5.840416 6.828222 6.203 13.73x 527.008 bioframe 84.30831 86.512823 85.150539 1.00x 2418.629 pyranges0 20.679566 21.424632 20.949203 4.06x 2239.047 pyranges1 25.352803 27.604137 26.544063 3.21x 2534.629"},{"location":"supplement/#exec-3--e2e-coverage-csv_5","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 3.532309 3.660049 3.579428 12.53x 738.887 polars_bio_streaming 3.167344 3.169622 3.168694 14.15x 416.164 bioframe 41.150587 51.89725 44.839673 1.00x 14297.098 pyranges1 40.065526 41.350493 40.892187 1.10x 3096.812"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_5","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 3.827717 3.83517 3.830823 25.47x 737.059 polars_bio_streaming 3.346898 3.388796 3.372987 28.93x 428.422 bioframe 97.272988 97.790775 97.572564 1.00x 25981.051 pyranges1 30.021737 30.181438 30.124339 3.24x 3102.84"},{"location":"supplement/#exec-3--100-1p_1","title":"100-1p","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_6","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.012022 0.433918 0.153077 0.55x 262.656 polars_bio_streaming 0.007427 0.153294 0.056144 1.49x 259.039 bioframe 0.039406 0.172494 0.08386 1.00x 229.824 pyranges0 0.059086 0.075573 0.06466 1.30x 231.199 pyranges1 0.069077 0.088036 0.075488 1.11x 230.684"},{"location":"supplement/#exec-3--e2e-nearest-csv_6","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.012814 0.408332 0.145315 1.24x 263.16 polars_bio_streaming 0.007605 0.007975 0.00779 23.20x 260.242 bioframe 0.044222 0.45263 0.180742 1.00x 230.684 pyranges0 0.066032 0.074886 0.068992 2.62x 231.195 pyranges1 0.07111 0.075383 0.072851 2.48x 230.68"},{"location":"supplement/#exec-3--e2e-coverage-csv_6","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.008954 0.106466 0.041616 2.35x 258.184 polars_bio_streaming 0.006726 0.007524 0.007124 13.72x 255.258 bioframe 0.07866 0.135591 0.097742 1.00x 230.68 pyranges1 0.120404 0.12302 0.121487 0.80x 231.023"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_6","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 0.008886 0.095835 0.038506 1.53x 262.312 polars_bio_streaming 0.006988 0.008915 0.007637 7.71x 259.555 bioframe 0.043766 0.08625 0.058895 1.00x 230.852 pyranges1 0.060574 0.060725 0.06064 0.97x 231.195"},{"location":"supplement/#exec-3--10000000-1p_1","title":"10000000-1p","text":""},{"location":"supplement/#exec-3--e2e-overlap-csv_7","title":"e2e-overlap-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 35.783773 37.155414 36.274578 4.73x 6926.227 polars_bio_streaming 28.364026 33.834447 32.005189 5.37x 1172.484 bioframe 170.321558 173.826371 171.750864 1.00x 17544.5 pyranges0 374.384106 377.106338 375.972726 0.46x 12951.133 pyranges1 174.205234 176.465726 174.996859 0.98x 23198.973"},{"location":"supplement/#exec-3--e2e-nearest-csv_7","title":"e2e-nearest-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 16.577973 16.599008 16.591114 5.88x 2208.477 polars_bio_streaming 14.957252 15.214483 15.115055 6.45x 1202.555 bioframe 96.638005 98.21701 97.559755 1.00x 7832.391 pyranges0 54.678927 55.140916 54.905002 1.78x 3125.051 pyranges1 31.874441 33.028755 32.303297 3.02x 4447.332"},{"location":"supplement/#exec-3--e2e-coverage-csv_7","title":"e2e-coverage-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 4.184608 4.403694 4.281924 6.97x 768.75 polars_bio_streaming 3.792566 3.917329 3.838723 7.77x 591.812 bioframe 29.609636 29.972788 29.838014 1.00x 4040.508 pyranges1 41.671912 42.238756 41.949904 0.71x 8503.844"},{"location":"supplement/#exec-3--e2e-count-overlaps-csv_7","title":"e2e-count-overlaps-csv","text":"Library Min (s) Max (s) Mean (s) Speedup Peak memory (MB) polars_bio 11.003474 11.126526 11.052697 6.35x 1012.105 polars_bio_streaming 9.939793 10.434084 10.264927 6.83x 696.078 bioframe 70.00646 70.300308 70.14716 1.00x 8315.176 pyranges1 33.521685 33.726979 33.593637 2.09x 8495.672"},{"location":"supplement/#memory-profiles","title":"Memory profiles","text":"<p>### apple-m3-max #### 1-2 </p>Operation: overlap for dataset: 1-2 on platform: apple-m3-max 2025-10-25T19:17:19.263496 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:19.470785 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:19.682195 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:19.901869 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:20.116166 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 1-2 on platform: apple-m3-max 2025-10-25T19:17:20.321420 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:20.527793 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:20.741678 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:20.951615 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:21.161028 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 1-2 on platform: apple-m3-max 2025-10-25T19:17:21.371279 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:21.570018 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:21.765065 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:21.966768 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 1-2 on platform: apple-m3-max 2025-10-25T19:17:22.197903 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:22.413269 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:22.612387 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:22.816990 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     #### 8-7 Operation: overlap for dataset: 8-7 on platform: apple-m3-max 2025-10-25T19:17:23.027971 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:23.410204 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:23.641449 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:23.939091 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:24.203558 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 8-7 on platform: apple-m3-max 2025-10-25T19:17:24.495153 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:24.720473 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:24.929286 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:25.153323 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:25.366398 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 8-7 on platform: apple-m3-max 2025-10-25T19:17:25.583788 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:25.793862 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:25.987221 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:26.210186 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 8-7 on platform: apple-m3-max 2025-10-25T19:17:26.449556 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:26.660927 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:26.857305 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:27.092299 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     #### 100-1p Operation: overlap for dataset: 100-1p on platform: apple-m3-max 2025-10-25T19:17:27.311847 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:27.503023 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:27.706649 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:27.897321 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:28.110396 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 100-1p on platform: apple-m3-max 2025-10-25T19:17:28.314277 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:28.509964 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:28.706883 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:28.902694 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:29.093846 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 100-1p on platform: apple-m3-max 2025-10-25T19:17:29.287550 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:29.485645 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:29.687760 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:29.894819 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 100-1p on platform: apple-m3-max 2025-10-25T19:17:30.310714 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:30.486076 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:30.688092 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:30.881657 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     #### 10000000-1p Operation: overlap for dataset: 10000000-1p on platform: apple-m3-max 2025-10-25T19:17:31.075860 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:31.290552 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:31.509559 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:31.744511 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:32.004636 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 10000000-1p on platform: apple-m3-max 2025-10-25T19:17:32.245843 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:32.446321 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:32.655522 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:32.896784 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:33.104508 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 10000000-1p on platform: apple-m3-max 2025-10-25T19:17:33.298034 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:33.497354 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:33.701868 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:33.912704 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 10000000-1p on platform: apple-m3-max 2025-10-25T19:17:34.119148 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:34.318965 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:34.532848 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:34.762251 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     ### gcp-linux #### 1-2 Operation: overlap for dataset: 1-2 on platform: gcp-linux 2025-10-25T19:17:34.955265 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:35.156648 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:35.372599 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:35.576535 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:35.783231 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 1-2 on platform: gcp-linux 2025-10-25T19:17:35.998688 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:36.224532 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:36.432500 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:36.643797 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:36.852869 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 1-2 on platform: gcp-linux 2025-10-25T19:17:37.064686 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:37.268144 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:37.473807 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:37.698393 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 1-2 on platform: gcp-linux 2025-10-25T19:17:37.913300 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:38.133448 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:38.636160 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:38.847950 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     #### 8-7 Operation: overlap for dataset: 8-7 on platform: gcp-linux 2025-10-25T19:17:39.065172 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:39.278239 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:39.516326 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:39.815544 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:40.101546 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 8-7 on platform: gcp-linux 2025-10-25T19:17:40.388237 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:40.617289 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:40.824120 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:41.037088 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:41.250539 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 8-7 on platform: gcp-linux 2025-10-25T19:17:41.472196 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:41.674251 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:41.866460 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:42.094467 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 8-7 on platform: gcp-linux 2025-10-25T19:17:42.316808 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:42.527573 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:42.724990 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:42.943424 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     #### 100-1p Operation: overlap for dataset: 100-1p on platform: gcp-linux 2025-10-25T19:17:43.174912 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:43.391305 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:43.614239 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:43.816404 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:44.019027 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 100-1p on platform: gcp-linux 2025-10-25T19:17:44.235636 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:44.446150 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:44.655595 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:44.865914 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:45.092129 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 100-1p on platform: gcp-linux 2025-10-25T19:17:45.309176 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:45.520583 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:45.734366 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:45.929378 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 100-1p on platform: gcp-linux 2025-10-25T19:17:46.125249 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:46.340422 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:46.539176 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:46.741429 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/     #### 10000000-1p Operation: overlap for dataset: 10000000-1p on platform: gcp-linux 2025-10-25T19:17:46.948922 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:47.175092 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:47.403102 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:47.677860 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:47.967303 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: nearest for dataset: 10000000-1p on platform: gcp-linux 2025-10-25T19:17:48.213122 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:48.420059 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:48.649044 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:48.879100 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:49.093421 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: coverage for dataset: 10000000-1p on platform: gcp-linux 2025-10-25T19:17:49.309048 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:49.903555 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:50.106350 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:50.341498 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ Operation: count-overlaps for dataset: 10000000-1p on platform: gcp-linux 2025-10-25T19:17:50.539310 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:50.751487 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:50.977365 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ 2025-10-25T19:17:51.212927 image/svg+xml Matplotlib v3.9.4, https://matplotlib.org/ <p></p>"},{"location":"supplement/#comparison-of-the-output-schemas-and-data-types","title":"Comparison of the output schemas and data types","text":"<p><code>polars-bio</code> tries to preserve the output schema of the <code>bioframe</code> package, <code>pyranges</code> uses its own internal representation that can be converted to a Pandas dataframe. It is also worth mentioning that <code>pyranges</code> always uses <code>int64</code> for start/end positions representation (polars-bio and bioframe determine it adaptively based on the input file formats/DataFrames datatypes used. polars-bio does not support interval operations on chromosomes longer than 2Gp(issue)). However, in the analyzed test case (<code>8-7</code>) input/output data structures have similar memory requirements. Please compare the following schema and memory size estimates of the input and output DataFrames for <code>8-7</code> test case: </p><pre><code>import bioframe as bf\nimport polars_bio as pb\nimport pandas as pd\nimport polars as pl\nimport pyranges0 as pr0\n\n\nDATA_DIR=\"/Users/mwiewior/research/polars-bio-benchmarking/data/\"\ndf_1 = f\"{DATA_DIR}/ex-anno/*.parquet\"\ndf_2 = f\"{DATA_DIR}/ex-rna/*.parquet\"\ndf1 = pd.read_parquet(df_1.replace(\"*.parquet\", \"\"))\ndf2 = pd.read_parquet(df_2.replace(\"*.parquet\", \"\"))\ncols = [\"contig\", \"pos_start\", \"pos_end\"]\n\ndef df2pr0(df):\n    return pr0.PyRanges(\n        chromosomes=df.contig,\n        starts=df.pos_start,\n        ends=df.pos_end,\n    )\n</code></pre><p></p>"},{"location":"supplement/#input-datasets-sizes-and-schemas","title":"Input datasets sizes and schemas","text":"<pre><code>df1.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1194285 entries, 0 to 1194284\nData columns (total 3 columns):\n#   Column     Non-Null Count    Dtype\n---  ------     --------------    -----\n0   contig     1194285 non-null  object\n1   pos_start  1194285 non-null  int32\n2   pos_end    1194285 non-null  int32\ndtypes: int32(2), object(1)\nmemory usage: 18.2+ MB\n</code></pre> <pre><code>df2.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 9944559 entries, 0 to 9944558\nData columns (total 3 columns):\n #   Column     Dtype\n---  ------     -----\n 0   contig     object\n 1   pos_start  int32\n 2   pos_end    int32\ndtypes: int32(2), object(1)\nmemory usage: 151.7+ MB\n</code></pre>"},{"location":"supplement/#polars-bio-output-dataframes-schema-and-memory-used-polars-and-pandas","title":"polars-bio output DataFrames schema and memory used (Polars and Pandas)","text":"<pre><code>df_pb = pb.overlap(df_1, df_2, cols1=cols, cols2=cols, use_zero_based=True)\ndf_pb.count().collect()\n</code></pre> <pre><code>307184634\n</code></pre> <pre><code>df_pb.collect_schema()\n</code></pre> <pre><code>Schema([('contig_1', String),\n        ('pos_start_1', Int32),\n        ('pos_end_1', Int32),\n        ('contig_2', String),\n        ('pos_start_2', Int32),\n        ('pos_end_2', Int32)])\n</code></pre> <pre><code>df_pb.collect().estimated_size(\"mb\")\n</code></pre> <pre><code>7360.232946395874\n</code></pre> <pre><code>df_pb.collect().to_pandas().info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 307184634 entries, 0 to 307184633\nData columns (total 6 columns):\n #   Column       Dtype\n---  ------       -----\n 0   contig_1     object\n 1   pos_start_1  int32\n 2   pos_end_1    int32\n 3   contig_2     object\n 4   pos_start_2  int32\n 5   pos_end_2    int32\ndtypes: int32(4), object(2)\nmemory usage: 9.2+ GB\n</code></pre>"},{"location":"supplement/#bioframe-output-dataframe-schema-and-memory-used-pandas","title":"bioframe output DataFrame schema and memory used (Pandas)","text":"<pre><code>df_bf = bf.overlap(df1, df2, cols1=cols, cols2=cols, how=\"inner\")\nlen(df_bf)\n</code></pre> <pre><code>307184634\n</code></pre> <pre><code>df_bf.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 307184634 entries, 0 to 307184633\nData columns (total 6 columns):\n #   Column      Dtype\n---  ------      -----\n 0   contig      object\n 1   pos_start   int32\n 2   pos_end     int32\n 3   contig_     object\n 4   pos_start_  int32\n 5   pos_end_    int32\ndtypes: int32(4), object(2)\nmemory usage: 9.2+ GB\n</code></pre>"},{"location":"supplement/#pyranges0-output-dataframe-schema-and-memory-used-pandas","title":"pyranges0 output DataFrame schema and memory used (Pandas)","text":"<pre><code>df_pr0_1 = df2pr0(df1)\ndf_pr0_2 = df2pr0(df2)\n</code></pre> <pre><code>df_pr0_1.df.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1194285 entries, 0 to 1194284\nData columns (total 3 columns):\n #   Column      Non-Null Count    Dtype\n---  ------      --------------    -----\n 0   Chromosome  1194285 non-null  category\n 1   Start       1194285 non-null  int64\n 2   End         1194285 non-null  int64\ndtypes: category(1), int64(2)\nmemory usage: 19.4 MB\n</code></pre> <pre><code>df_pr0_2.df.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 9944559 entries, 0 to 9944558\nData columns (total 3 columns):\n #   Column      Dtype\n---  ------      -----\n 0   Chromosome  category\n 1   Start       int64\n 2   End         int64\ndtypes: category(1), int64(2)\nmemory usage: 161.2 MB\n</code></pre> <pre><code>df_pr0 = df_pr0_1.join(df_pr0_2)\nlen(df_pr0)\n</code></pre> <pre><code>307184634\n</code></pre> <pre><code>df_pr0.df.info()\n</code></pre> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 307184634 entries, 0 to 307184633\nData columns (total 5 columns):\n #   Column      Dtype\n---  ------      -----\n 0   Chromosome  category\n 1   Start       int64\n 2   End         int64\n 3   Start_b     int64\n 4   End_b       int64\ndtypes: category(1), int64(4)\nmemory usage: 9.4 GB\n</code></pre> <p>Note</p> <p>Please note that <code>pyranges</code> unlike bioframe and polars-bio returns only one chromosome column but uses <code>int64</code> data types for encoding start and end positions even if input datasets use <code>int32</code>.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/","title":"Interval operations benchmark \u2014 update September 2025","text":""},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#interval-operations-benchmark-update-september-2025","title":"Interval operations benchmark \u2014 update September 2025","text":""},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#introduction","title":"Introduction","text":"<p>Benchmarking isn\u2019t a one-and-done exercise\u2014it\u2019s a moving target. As tools evolve, new versions can shift performance profiles in meaningful ways, so keeping results current is just as important as the first round of measurements.</p> <p>Recently, three novel libraries that have started to gain traction: pyranges1, GenomicRanges and polars-bio </p> <p>shipped major updates:</p> <ul> <li>pyranges1 adopted a new Rust backend (ruranges),</li> <li>GenomicRanges switched its interval core to a Nested Containment List (NCLS) and added multithreaded execution,</li> <li>polars-bio migrated to the new Polars streaming engine and added support for new interval data structures. As of version <code>0.12.0</code> it supports:<ul> <li>COITrees</li> <li>IITree</li> <li>AVL-tree</li> <li>rust-lapper</li> <li>superintervals</li> </ul> </li> </ul> <p>Each of these changes has the potential to meaningfully alter performance and memory characteristics for common genomic interval tasks.</p> <p>In this post, we revisit our benchmarks with those releases in mind. We focus on three everyday operations:</p> <ul> <li>overlap detection,</li> <li>nearest feature queries</li> <li>overlap counting.</li> </ul> <p>For comparability, we use the same AIList dataset from our previous write-up, so you can see exactly how the new backends and data structures change the picture. Let\u2019s dive in and see what\u2019s faster, what\u2019s leaner, and where the trade-offs now live.</p>"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#setup","title":"Setup","text":""},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#benchmark-test-cases","title":"Benchmark test cases","text":"Dataset pairs Size # of overlaps (1-based) 1-2 &amp; 2-1 Small 54,246 7-3 &amp; 3-7 Medium 4,408,383 8-7 &amp; 7-8 Large 307,184,634"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#software-versions","title":"Software versions","text":"Library Version polars_bio 0.13.1 pyranges 0.1.14 genomicranges 0.7.2"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#results","title":"Results","text":""},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#polars-bio-interval-data-structures-performance-comparison","title":"polars-bio interval data structures performance comparison","text":"<p>Key takeaways:</p> <ul> <li>Superintervals seems to be the best default. Across all three test cases, it is consistently the fastest or tied for fastest, delivering 1.25\u20131.44x speedups over the polars-bio default (COITrees) and avoiding worst\u2011case behavior.</li> <li>Lapper caveat: performs well on 1\u20112 and 8\u20117, but collapses on 7\u20113 (\u224825x slower than default), so it\u2019s risky as a general\u2011purpose algorithm.</li> <li>Intervaltree/Arrayintervaltree: reliable but slower. They trail superintervals by 20\u201370% depending on the case.</li> </ul>"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#all-operations-comparison","title":"All operations comparison","text":"<p>Key takeaways:</p> <ul> <li>Overlap: GenomicRanges wins on small inputs (1\u20112, 2\u20111) by ~2.1\u20132.3x, but polars\u2011bio takes over from medium size onward and dominates on large (7\u20118, 8\u20117), where PyRanges falls far behind. Interesting case of 7-8 vs 8-7 when swapping inputs can significantly affect performance of GenomicRanges.</li> <li>Nearest: polars\u2011bio leads decisively at every size; speedups over the others grow with input size (orders of magnitude on large datasets).</li> <li>Count overlaps: GenomicRanges edges out polars\u2011bio on the smallest inputs, while polars\u2011bio is faster on medium and substantially faster on large inputs.</li> </ul>"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#all-operations-parallel-execution","title":"All operations parallel execution","text":"<p>Key takeaways:</p> <ul> <li>Thread scaling: both libraries (GenomicRanges and polars-bio) benefit from additional threads, but the absolute gap favors polars\u2011bio for medium/large datasets across overlap, nearest, and count overlaps.</li> <li>Small overlaps: GenomicRanges remains &gt;2x faster at 1\u20138 threads; on medium/large pairs its relative speed drops below 1x.</li> <li>Nearest: polars\u2011bio stays on the 1x reference line; GenomicRanges is typically 10\u2013100x slower (log scale) even with more threads.</li> <li>Count overlaps: small inputs slightly favor GenomicRanges; for larger inputs polars\u2011bio maintains 2\u201310x advantage with stable scaling.</li> </ul>"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#end-to-end-data-proecesing","title":"End to-end data proecesing","text":"<p>Here we compare end-to-end performance including data loading, overlap operation, and saving results to CSV.</p> <p>Info</p> <ol> <li><code>POLARS_MAX_THREADS=1</code> was set to ensure fair comparison with single-threaded PyRanges.</li> <li>Since GenomicRanges supports Polars DataFrames as input and output, we used them instead of Pandas to again ensure fair comparison with polars-bio.</li> <li>GenomicRanges find_overlaps method returns hits-only table (indices of genomic intervals instead of genomic coordinates), we also benchmarked an extended version with additional lookup of intervals (<code>full rows</code>, code) for fair comparison.</li> </ol> <p></p> <p>Key takeaways:</p> <ul> <li>Wall time: GenomicRanges (hits\u2011only) is the fastest end\u2011to\u2011end here (~1.16x vs polars_bio) by avoiding full materialization of genomic intervals (unlike PyRanges and polars-bio that return pairs of genomic interval coordinates for each overlap); PyRanges is far slower; GenomicRanges (full rows, so with the output comparable with PyRanges and polars-bio) is much slower.</li> <li>Memory: polars-bio (streaming) minimizes peak RAM (~0.7 GB) while keeping speed comparable to polars-bio. GenomicRanges (full rows) peaks at ~40 GB; hits\u2011only sits in the middle (~8.2 GB) as it only returns DataFrame with pairs of indices not full genomic coordinates.</li> </ul>"},{"location":"blog/2025/09/05/interval-operations-benchmark--update-september-2025/#summary","title":"Summary","text":"<p>For small and medium datasets, all tools perform well; at large scale, polars-bio excels with better scalability and memory efficiency, achieving an ultra\u2011low footprint in streaming mode.</p>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/","title":"GFF File Reading Performance Enhancements in polars-bio 0.15.0","text":""},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#gff-file-reading-performance-enhancements-in-polars-bio-0150","title":"GFF File Reading Performance Enhancements in polars-bio 0.15.0","text":"<p>We're excited to announce significant performance improvements to GFF file reading in polars-bio <code>0.15.0</code>. This release introduces two major optimizations that dramatically improve both speed and memory efficiency when working with GFF files:</p>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#key-enhancements","title":"Key Enhancements","text":"<p>Projection Pushdown: Only the columns you need are read from disk, reducing I/O overhead and memory usage. This is particularly beneficial when working with wide GFF files that contain many optional attributes.</p> <p>Predicate Pushdown: Row filtering is applied during the file reading process, eliminating the need to load irrelevant data into memory. This allows for lightning-fast queries on large GFF datasets.</p> <p>Fully Streamed Parallel Reads: BGZF-compressed files can now be read in parallel with true streaming, enabling out-of-core processing of massive genomic datasets without memory constraints.</p>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#benchmark-methodology","title":"Benchmark Methodology","text":"<p>To evaluate these improvements, we conducted comprehensive benchmarks comparing three popular data processing libraries:</p> <ul> <li>Pandas: The traditional Python data analysis library</li> <li>Polars: High-performance DataFrame library with lazy evaluation</li> <li>polars-bio: Our specialized genomic data processing library built on Polars and Apache DataFusion</li> </ul> <p>All benchmarks were performed on a large GFF file (~7.7 million records, file and index needed for parallel reading) with both full scan and filtered query scenarios to demonstrate real-world performance gains.</p> <p>For pandas and polars reading, we used the following methods (thanks to @urineri for the Polars code). Since Polars decompresses compressed CSV/TSV files completely in memory as highlighted here, we also used <code>polars_streaming_csv_decompression</code>, a great plugin developed by @ghuls to enable streaming decompression in Polars.</p> <p>Test query used for filtered benchmarks (Polars and polars-bio):</p> <pre><code> result = (\n        lf.filter(\n            (pl.col(\"seqid\") == \"chrY\")\n            &amp; (pl.col(\"start\") &lt; 500000)\n            &amp; (pl.col(\"end\") &gt; 510000)\n        )\n        .select([\"seqid\", \"start\", \"end\", \"type\"])\n        .collect()\n    )\n</code></pre> <p>The above query is very selective and returns only two rows from the entire dataset.</p>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#results","title":"Results","text":"<p>Complete benchmark code and results are available in the polars-bio repository.</p>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#single-threaded-performance","title":"Single-threaded performance","text":"<p>Key takeaways:</p> <ul> <li>polars-bio delivers comparable performance to standard Polars for full scan operations and both significantly outperform Pandas.</li> <li>In the case of filtered queries, we can see further performance improvements with Polars and polars-bio thanks to predicate and projection pushdown optimizations. polars-bio is 2.5x faster than standard Polars.</li> </ul>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#memory-usage","title":"Memory usage","text":"<p>Key takeaways:</p> <ul> <li>Polars and polars-bio use significantly less memory than Pandas for all operations.</li> <li>polars-bio and Polars with <code>polars_streaming_csv_decompression</code> can use more than 20x less memory than vanilla Polars and more than two orders of magnitude less memory than Pandas for operations involving filtering.</li> </ul>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#thread-scalability","title":"Thread scalability","text":"<p>Key takeaways:</p> <ul> <li>polars-bio achieves near-linear scaling up to 8 threads for full scan operations, reaching 9.5x speedup at 16 threads compared to single-threaded performance.</li> <li>Filtered operations show excellent parallelization with polars-bio reaching 11x speedup at 16 threads, significantly outperforming other libraries. There is, however, non-negligible overhead due to parallelism at 1 thread (2.25s vs 4.2s, compared to the single-threaded benchmark).</li> <li>polars-streaming shows diminishing returns at higher thread counts due to the overhead of spawning decompression program threads (in the default configuration, this is capped at 4), while polars-bio maintains consistent scaling benefits.</li> </ul>"},{"location":"blog/2025/09/08/gff-file-reading-performance-enhancements-in-polars-bio-0150/#summary","title":"Summary","text":"<p>The benchmarks demonstrate that polars-bio <code>0.15.0</code> delivers significant performance improvements for GFF file processing. These optimizations, combined with near-linear thread scaling and fully streamed parallel reads, make polars-bio an ideal choice for high-performance genomic data analysis workflows.</p> <p>If you haven't tried polars-bio yet, now is a great time to explore its capabilities for efficient genomic data processing with Python! Join our upcoming seminar on September 15, 2025, to learn more about polars-bio and its applications in genomics. </p>"},{"location":"notebooks/tutorial/","title":"\ud83d\udcdaTutorial","text":"In\u00a0[1]: Copied! <pre>import polars_bio as pb\nimport pandas as pd\nimport polars as pl\nimport bioframe as bf\n</pre> import polars_bio as pb import pandas as pd import polars as pl import bioframe as bf In\u00a0[2]: Copied! <pre>cols = [\"contig\", \"pos_start\", \"pos_end\"]\n</pre> cols = [\"contig\", \"pos_start\", \"pos_end\"] In\u00a0[6]: Copied! <pre>df1 = pd.DataFrame(\n    [[\"chr1\", 1, 5], [\"chr1\", 3, 8], [\"chr1\", 8, 10], [\"chr1\", 12, 14]],\n    columns=[\"chrom\", \"start\", \"end\"],\n)\n\ndf2 = pd.DataFrame(\n    [[\"chr1\", 4, 8], [\"chr1\", 10, 11]], columns=[\"chrom\", \"start\", \"end\"]\n)\n</pre> df1 = pd.DataFrame(     [[\"chr1\", 1, 5], [\"chr1\", 3, 8], [\"chr1\", 8, 10], [\"chr1\", 12, 14]],     columns=[\"chrom\", \"start\", \"end\"], )  df2 = pd.DataFrame(     [[\"chr1\", 4, 8], [\"chr1\", 10, 11]], columns=[\"chrom\", \"start\", \"end\"] ) In\u00a0[7]: Copied! <pre>display(df1)\n</pre> display(df1) chrom start end 0 chr1 1 5 1 chr1 3 8 2 chr1 8 10 3 chr1 12 14 In\u00a0[8]: Copied! <pre>display(df2)\n</pre> display(df2) chrom start end 0 chr1 4 8 1 chr1 10 11 In\u00a0[9]: Copied! <pre>overlapping_intervals = pb.overlap(df1, df2, output_type=\"pandas.DataFrame\")\n</pre> overlapping_intervals = pb.overlap(df1, df2, output_type=\"pandas.DataFrame\") In\u00a0[10]: Copied! <pre>display(overlapping_intervals)\n</pre> display(overlapping_intervals) chrom_1 start_1 end_1 chrom_2 start_2 end_2 0 chr1 1 5 chr1 4 8 1 chr1 3 8 chr1 4 8 2 chr1 8 10 chr1 4 8 3 chr1 8 10 chr1 10 11 In\u00a0[11]: Copied! <pre>pb.visualize_intervals(overlapping_intervals)\n</pre> pb.visualize_intervals(overlapping_intervals) In\u00a0[12]: Copied! <pre>nearest_intervals = pb.nearest(df1, df2, output_type=\"pandas.DataFrame\")\n</pre> nearest_intervals = pb.nearest(df1, df2, output_type=\"pandas.DataFrame\") In\u00a0[13]: Copied! <pre>display(nearest_intervals)\n</pre> display(nearest_intervals) chrom_1 start_1 end_1 chrom_2 start_2 end_2 distance 0 chr1 1 5 chr1 4 8 0 1 chr1 3 8 chr1 4 8 0 2 chr1 8 10 chr1 4 8 0 3 chr1 12 14 chr1 10 11 1 In\u00a0[14]: Copied! <pre>pb.visualize_intervals(nearest_intervals, \"nearest pair\")\n</pre> pb.visualize_intervals(nearest_intervals, \"nearest pair\") In\u00a0[15]: Copied! <pre>count_overlaps = pb.count_overlaps(df1, df2, output_type=\"pandas.DataFrame\")\n</pre> count_overlaps = pb.count_overlaps(df1, df2, output_type=\"pandas.DataFrame\") In\u00a0[16]: Copied! <pre>display(count_overlaps)\n</pre> display(count_overlaps) chrom start end count 0 chr1 1 5 1 1 chr1 3 8 1 2 chr1 8 10 2 3 chr1 12 14 0 In\u00a0[17]: Copied! <pre>coverage = pb.coverage(df1, df2, output_type=\"pandas.DataFrame\")\n</pre> coverage = pb.coverage(df1, df2, output_type=\"pandas.DataFrame\") In\u00a0[18]: Copied! <pre>display(coverage)\n</pre> display(coverage) chrom start end coverage 0 chr1 1 5 2 1 chr1 3 8 4 2 chr1 8 10 2 3 chr1 12 14 0 In\u00a0[19]: Copied! <pre>merge = pb.merge(df1,output_type=\"pandas.DataFrame\")\n</pre> merge = pb.merge(df1,output_type=\"pandas.DataFrame\") In\u00a0[20]: Copied! <pre>display(merge)\n</pre> display(merge) chrom start end n_intervals 0 chr1 1 10 3 1 chr1 12 14 1 In\u00a0[21]: Copied! <pre>gff = pb.scan_gff(\"data/example.gff3.bgz\")\n</pre> gff = pb.scan_gff(\"data/example.gff3.bgz\") In\u00a0[22]: Copied! <pre>gff.limit(3).collect()\n</pre> gff.limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[22]: shape: (3, 9)chromstartendtypesourcescorestrandphaseattributesstru32u32strstrf32stru32list[struct[2]]\"chr1\"1186914409\"gene\"\"HAVANA\"null\"+\"null[{\"ID\",\"ENSG00000223972.5\"}, {\"gene_id\",\"ENSG00000223972.5\"}, \u2026 {\"havana_gene\",\"OTTHUMG00000000961.2\"}]\"chr1\"1186914409\"transcript\"\"HAVANA\"null\"+\"null[{\"ID\",\"ENST00000456328.2\"}, {\"Parent\",\"ENSG00000223972.5\"}, \u2026 {\"havana_transcript\",\"OTTHUMT00000362751.1\"}]\"chr1\"1186912227\"exon\"\"HAVANA\"null\"+\"null[{\"ID\",\"exon:ENST00000456328.2:1\"}, {\"Parent\",\"ENST00000456328.2\"}, \u2026 {\"havana_transcript\",\"OTTHUMT00000362751.1\"}] In\u00a0[23]: Copied! <pre>gff = pb.scan_gff(\"data/example.gff3.bgz\").select([\"start\", \"end\", \"ID\", \"havana_transcript\"])\n</pre> gff = pb.scan_gff(\"data/example.gff3.bgz\").select([\"start\", \"end\", \"ID\", \"havana_transcript\"]) In\u00a0[24]: Copied! <pre>gff.limit(3).collect()\n</pre> gff.limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[24]: shape: (3, 4)startendIDhavana_transcriptu32u32strstr1186914409\"ENSG00000223972.5\"null1186914409\"ENST00000456328.2\"\"OTTHUMT00000362751.1\"1186912227\"exon:ENST00000456328.2:1\"\"OTTHUMT00000362751.1\" In\u00a0[25]: Copied! <pre>pb.scan_vcf(\"data/example.vcf\").limit(3).collect()\n</pre> pb.scan_vcf(\"data/example.vcf\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[25]: shape: (2, 9)chromstartendidrefaltqualfiltercsqstru32u32strstrstrf64strlist[str]\"chr21\"2696007026960070\"rs116645811\"\"G\"\"A\"null\"\"[\"A|missense_variant|MODERATE|MRPL39|ENSG00000154719|Transcript|ENST00000307301|protein_coding|10/11||||1043|1001|334|T/M|aCg/aTg|||-1||HGNC|14027\", \"A|intron_variant|MODIFIER|MRPL39|ENSG00000154719|Transcript|ENST00000352957|protein_coding||9/9||||||||||-1||HGNC|14027\", \"A|upstream_gene_variant|MODIFIER|LINC00515|ENSG00000260583|Transcript|ENST00000567517|antisense|||||||||||4432|-1||HGNC|16019\"]\"chr21\"2696514826965148\"rs1135638\"\"G\"\"A\"null\"\"[\"A|synonymous_variant|LOW|MRPL39|ENSG00000154719|Transcript|ENST00000307301|protein_coding|8/11||||939|897|299|G|ggC/ggT|||-1||HGNC|14027\", \"A|synonymous_variant|LOW|MRPL39|ENSG00000154719|Transcript|ENST00000352957|protein_coding|8/10||||939|897|299|G|ggC/ggT|||-1||HGNC|14027\", \"A|synonymous_variant|LOW|MRPL39|ENSG00000154719|Transcript|ENST00000419219|protein_coding|8/8||||876|867|289|G|ggC/ggT|||-1|cds_end_NF|HGNC|14027\"] In\u00a0[26]: Copied! <pre>pb.describe_vcf(\"data/example.vcf\").sort(\"name\")\n</pre> pb.describe_vcf(\"data/example.vcf\").sort(\"name\") Out[26]: shape: (1, 3)nametypedescriptionstrstrstr\"CSQ\"\"String\"\"Consequence annotations from E\u2026 In\u00a0[27]: Copied! <pre>pb.scan_vcf(\"data/example.vcf\", info_fields=[\"CSQ\"]).limit(3).collect()\n</pre> pb.scan_vcf(\"data/example.vcf\", info_fields=[\"CSQ\"]).limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[27]: shape: (2, 9)chromstartendidrefaltqualfiltercsqstru32u32strstrstrf64strlist[str]\"chr21\"2696007026960070\"rs116645811\"\"G\"\"A\"null\"\"[\"A|missense_variant|MODERATE|MRPL39|ENSG00000154719|Transcript|ENST00000307301|protein_coding|10/11||||1043|1001|334|T/M|aCg/aTg|||-1||HGNC|14027\", \"A|intron_variant|MODIFIER|MRPL39|ENSG00000154719|Transcript|ENST00000352957|protein_coding||9/9||||||||||-1||HGNC|14027\", \"A|upstream_gene_variant|MODIFIER|LINC00515|ENSG00000260583|Transcript|ENST00000567517|antisense|||||||||||4432|-1||HGNC|16019\"]\"chr21\"2696514826965148\"rs1135638\"\"G\"\"A\"null\"\"[\"A|synonymous_variant|LOW|MRPL39|ENSG00000154719|Transcript|ENST00000307301|protein_coding|8/11||||939|897|299|G|ggC/ggT|||-1||HGNC|14027\", \"A|synonymous_variant|LOW|MRPL39|ENSG00000154719|Transcript|ENST00000352957|protein_coding|8/10||||939|897|299|G|ggC/ggT|||-1||HGNC|14027\", \"A|synonymous_variant|LOW|MRPL39|ENSG00000154719|Transcript|ENST00000419219|protein_coding|8/8||||876|867|289|G|ggC/ggT|||-1|cds_end_NF|HGNC|14027\"] In\u00a0[28]: Copied! <pre>pb.scan_fastq(\"data/example.fastq.gz\").limit(3).collect()\n</pre> pb.scan_fastq(\"data/example.fastq.gz\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[28]: shape: (3, 4)namedescriptionsequencequality_scoresstrstrstrstr\"SRR9130495.1\"\"D00236:723:HG32CBCX2:1:1108:13\u2026\"NCAATACAAAAGCAATATGGGAGAAGCTAC\u2026\"#4BDFDFFHGHGGJJJHIIIIGGIIJGJJG\u2026\"SRR9130495.2\"\"D00236:723:HG32CBCX2:1:1108:14\u2026\"NGTCAAAGATAAGATCAAAAGGCACTGGCT\u2026\"#1=DDDDD&gt;DHFH@EFHHGHGGFGIIIGIG\u2026\"SRR9130495.3\"\"D00236:723:HG32CBCX2:1:1108:17\u2026\"GTTTTCCTCTGGTTATTTCTAGGTACACTG\u2026\"@@@DDDFFHHHFHBHIIGJIJIIJIIIEHG\u2026 In\u00a0[29]: Copied! <pre>pb.scan_bam(\"data/example.bam\").limit(3).collect()\n</pre> pb.scan_bam(\"data/example.bam\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[29]: shape: (3, 11)namechromstartendflagscigarmapping_qualitymate_chrommate_startsequencequality_scoresstrstru32u32u32stru32stru32strstr\"20FUKAAXX100202:1:21:2075:1360\u2026\"chr1\"11011187\"101M\"0\"chr1\"178\"TAACCCTAACCCTAACCCTAACCCTAACCC\u2026\"?&gt;=&gt;?@CBC@BBCCDABACCDABBB9:788\u2026\"20FUKAAXX100202:1:21:2733:1836\u2026\"chr1\"11011123\"101M\"0\"chr1\"183\"TAACCCTAACCCTAACCCTAACCCTAACCC\u2026\"CCDACCDCDABBDCDABBDCDABBDCDABB\u2026\"20FUKAAXX100202:1:22:19822:802\u2026\"chr1\"1101163\"101M\"4\"chr1\"35\"TAACCCTAACCCTAACCCTAACCCTAACCC\u2026\"@CC?@@CBC@BBCCDABBCCDABBCCDABB\u2026 In\u00a0[30]: Copied! <pre>pb.scan_bed(\"data/example.bed.bgz\").limit(3).collect()\n</pre> pb.scan_bed(\"data/example.bed.bgz\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[30]: shape: (3, 4)chromstartendnamestru32u32str\"chr16\"1480000116800000\"FRA16A\"\"chr16\"6670000170800000\"FRA16B\"\"chr16\"6391750363934965\"FRA16C\" In\u00a0[31]: Copied! <pre>pb.register_gff(\"data/example.gff3.bgz\", \"example_gff\")\n</pre> pb.register_gff(\"data/example.gff3.bgz\", \"example_gff\") In\u00a0[32]: Copied! <pre>pb.sql(\"SHOW TABLES\").collect()\n</pre> pb.sql(\"SHOW TABLES\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[32]: shape: (18, 4)table_catalogtable_schematable_nametable_typestrstrstrstr\"datafusion\"\"public\"\"count_overlaps_coverage\"\"LOCAL TEMPORARY\"\"datafusion\"\"public\"\"example_gz\"\"BASE TABLE\"\"datafusion\"\"public\"\"vcf_schema_975224660\"\"BASE TABLE\"\"datafusion\"\"public\"\"s2\"\"BASE TABLE\"\"datafusion\"\"public\"\"example_gff\"\"BASE TABLE\"\u2026\u2026\u2026\u2026\"datafusion\"\"information_schema\"\"columns\"\"VIEW\"\"datafusion\"\"information_schema\"\"df_settings\"\"VIEW\"\"datafusion\"\"information_schema\"\"schemata\"\"VIEW\"\"datafusion\"\"information_schema\"\"routines\"\"VIEW\"\"datafusion\"\"information_schema\"\"parameters\"\"VIEW\" In\u00a0[33]: Copied! <pre>pb.sql(\"DESCRIBE example_gff\").collect()\n</pre> pb.sql(\"DESCRIBE example_gff\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[33]: shape: (9, 3)column_namedata_typeis_nullablestrstrstr\"chrom\"\"Utf8\"\"NO\"\"start\"\"UInt32\"\"NO\"\"end\"\"UInt32\"\"NO\"\"type\"\"Utf8\"\"NO\"\"source\"\"Utf8\"\"NO\"\"score\"\"Float32\"\"YES\"\"strand\"\"Utf8\"\"NO\"\"phase\"\"UInt32\"\"YES\"\"attributes\"\"List(Field { name: \"item\", dat\u2026\"YES\" In\u00a0[34]: Copied! <pre>pb.sql(\"SELECT start, end, type FROM example_gff WHERE end = 14409\").collect()\n</pre> pb.sql(\"SELECT start, end, type FROM example_gff WHERE end = 14409\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[34]: shape: (2, 3)startendtypeu32u32str1186914409\"gene\"1186914409\"transcript\" In\u00a0[35]: Copied! <pre>pb.register_view(\"v_example_gff\", \"SELECT start, end, type FROM example_gff WHERE end = 14409\")\n</pre> pb.register_view(\"v_example_gff\", \"SELECT start, end, type FROM example_gff WHERE end = 14409\") In\u00a0[36]: Copied! <pre>pb.sql(\"SELECT * FROM v_example_gff\").collect()\n</pre> pb.sql(\"SELECT * FROM v_example_gff\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[36]: shape: (2, 3)startendtypeu32u32str1186914409\"gene\"1186914409\"transcript\" In\u00a0[38]: Copied! <pre>pb.describe_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\").filter(pl.col(\"description\").str.contains(r\"Latino.* allele frequency\"))\n</pre> pb.describe_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\").filter(pl.col(\"description\").str.contains(r\"Latino.* allele frequency\")) Out[38]: shape: (3, 3)nametypedescriptionstrstrstr\"AF_amr\"\"Float\"\"Latino allele frequency (biall\u2026\"AF_amr_XY\"\"Float\"\"Latino XY allele frequency (bi\u2026\"AF_amr_XX\"\"Float\"\"Latino XX allele frequency (bi\u2026 In\u00a0[39]: Copied! <pre>pb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad\", info_fields=['AF_amr'])\nquery = \"\"\"\n    SELECT\n        chrom,\n        start,\n        end,\n        alt,\n        array_element(af_amr,1) AS af_amr\n    FROM gnomad\n    WHERE\n        filter = 'HIGH_NCR'\n    AND\n        alt = '&lt;DUP&gt;'\n\"\"\"\npb.sql(f\"{query} LIMIT 3\").collect()\n</pre> pb.register_vcf(\"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\", \"gnomad\", info_fields=['AF_amr']) query = \"\"\"     SELECT         chrom,         start,         end,         alt,         array_element(af_amr,1) AS af_amr     FROM gnomad     WHERE         filter = 'HIGH_NCR'     AND         alt = '' \"\"\" pb.sql(f\"{query} LIMIT 3\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[39]: shape: (3, 5)chromstartendaltaf_amrstru32u32strf32\"chr1\"10000295666\"&lt;DUP&gt;\"0.000293\"chr1\"138000144000\"&lt;DUP&gt;\"0.000166\"chr1\"160500172100\"&lt;DUP&gt;\"0.002639 In\u00a0[40]: Copied! <pre>pb.register_vcf(\"s3://gnomad-public-us-east-1/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr1.vcf.bgz\", \"gnomad_sites_chr1\", info_fields=[])\n</pre> pb.register_vcf(\"s3://gnomad-public-us-east-1/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr1.vcf.bgz\", \"gnomad_sites_chr1\", info_fields=[]) In\u00a0[41]: Copied! <pre>pb.sql(\"SELECT chrom, start, end, alt FROM gnomad_sites_chr1 LIMIT 10\").collect()\n</pre> pb.sql(\"SELECT chrom, start, end, alt FROM gnomad_sites_chr1 LIMIT 10\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[41]: shape: (10, 4)chromstartendaltstru32u32str\"chr1\"1199411994\"C\"\"chr1\"1201612016\"A\"\"chr1\"1206012065\"C\"\"chr1\"1207412074\"C\"\"chr1\"1210212102\"A\"\"chr1\"1210612106\"G\"\"chr1\"1213812138\"A\"\"chr1\"1215812158\"T\"\"chr1\"1216512165\"A\"\"chr1\"1216812168\"G\" In\u00a0[42]: Copied! <pre>pb.register_view(\"v_gnomad_sites_chr1\", \"SELECT * FROM gnomad_sites_chr1 LIMIT 20\")\n</pre> pb.register_view(\"v_gnomad_sites_chr1\", \"SELECT * FROM gnomad_sites_chr1 LIMIT 20\") In\u00a0[43]: Copied! <pre>pb.sql(\"SELECT * FROM v_gnomad_sites_chr1\").collect()\n</pre> pb.sql(\"SELECT * FROM v_gnomad_sites_chr1\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[43]: shape: (20, 8)chromstartendidrefaltqualfilterstru32u32strstrstrf64str\"chr1\"1199411994\"\"\"T\"\"C\"null\"AC0;AS_VQSR\"\"chr1\"1201612016\"\"\"G\"\"A\"null\"AC0;AS_VQSR\"\"chr1\"1206012065\"\"\"CTGGAG\"\"C\"null\"AC0;AS_VQSR\"\"chr1\"1207412074\"\"\"T\"\"C\"null\"AC0;AS_VQSR\"\"chr1\"1210212102\"\"\"G\"\"A\"null\"AC0;AS_VQSR\"\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\"chr1\"1219812198\"rs62635282\"\"G\"\"C\"null\"AS_VQSR\"\"chr1\"1220112201\"\"\"C\"\"G\"null\"AS_VQSR\"\"chr1\"1221412214\"rs202068986\"\"C\"\"G\"null\"AC0\"\"chr1\"1222512225\"\"\"C\"\"T\"null\"AS_VQSR\"\"chr1\"1223512235\"\"\"G\"\"A\"null\"AS_VQSR\" In\u00a0[44]: Copied! <pre>df = pl.DataFrame({\n    \"chrom\": [\"chr1\", \"chr1\"],\n    \"start\": [11993, 12102],\n    \"end\": [11996, 12200],\n    \"annotation\": [\"ann1\", \"ann2\"]\n})\npb.from_polars(\"test_annotation\", df)\npb.sql(\"SELECT * FROM test_annotation\").collect()\n</pre> df = pl.DataFrame({     \"chrom\": [\"chr1\", \"chr1\"],     \"start\": [11993, 12102],     \"end\": [11996, 12200],     \"annotation\": [\"ann1\", \"ann2\"] }) pb.from_polars(\"test_annotation\", df) pb.sql(\"SELECT * FROM test_annotation\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[44]: shape: (2, 4)chromstartendannotationstri64i64str\"chr1\"1199311996\"ann1\"\"chr1\"1210212200\"ann2\" In\u00a0[45]: Copied! <pre>pb.overlap(\"v_gnomad_sites_chr1\",\"test_annotation\").limit(3).collect()\n</pre> pb.overlap(\"v_gnomad_sites_chr1\",\"test_annotation\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[45]: shape: (3, 12)chrom_1start_1end_1chrom_2start_2end_2annotation_1id_2ref_2alt_2qual_2filter_2stru32u32stri64i64strstrstrstrf64str\"chr1\"1199411994\"chr1\"1199311996\"ann1\"\"\"\"T\"\"C\"null\"AC0;AS_VQSR\"\"chr1\"1210212102\"chr1\"1210212200\"ann2\"\"\"\"G\"\"A\"null\"AC0;AS_VQSR\"\"chr1\"1210612106\"chr1\"1210212200\"ann2\"\"\"\"T\"\"G\"null\"AC0;AS_VQSR\" <p>These demo datasets are from databio.zip benchmark.</p> In\u00a0[46]: Copied! <pre>pb.set_option(\"datafusion.execution.target_partitions\", \"1\")\n</pre> pb.set_option(\"datafusion.execution.target_partitions\", \"1\") In\u00a0[47]: Copied! <pre>%%time\npb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).collect().count()\n</pre> %%time pb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).collect().count() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 3.13 s, sys: 566 ms, total: 3.69 s\nWall time: 3.72 s\n</pre> Out[47]: shape: (1, 6)contig_1pos_start_1pos_end_1contig_2pos_start_2pos_end_2u32u32u32u32u32u32164214743164214743164214743164214743164214743164214743 In\u00a0[48]: Copied! <pre>pb.set_option(\"datafusion.execution.target_partitions\", \"2\")\n</pre> pb.set_option(\"datafusion.execution.target_partitions\", \"2\") In\u00a0[50]: Copied! <pre>%%time\npb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).collect().count()\n</pre> %%time pb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).collect().count() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 3.2 s, sys: 556 ms, total: 3.76 s\nWall time: 1.95 s\n</pre> Out[50]: shape: (1, 6)contig_1pos_start_1pos_end_1contig_2pos_start_2pos_end_2u32u32u32u32u32u32164214743164214743164214743164214743164214743164214743 In\u00a0[51]: Copied! <pre>%%bash\ngsutil cat gs://genomics-public-data/platinum-genomes/fastq/ERR194146.fastq.gz | gunzip -c  | bgzip -c &gt; /tmp/ERR194146.fastq.bgz\ncd /tmp &amp;&amp; bgzip -r /tmp/ERR194146.fastq.bgz\n</pre> %%bash gsutil cat gs://genomics-public-data/platinum-genomes/fastq/ERR194146.fastq.gz | gunzip -c  | bgzip -c &gt; /tmp/ERR194146.fastq.bgz cd /tmp &amp;&amp; bgzip -r /tmp/ERR194146.fastq.bgz <pre>/opt/homebrew/share/google-cloud-sdk/platform/gsutil/third_party/google-auth-library-python/google/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  import pkg_resources\n</pre> In\u00a0[\u00a0]: Copied! <pre>pb.set_option(\"datafusion.execution.target_partitions\", \"1\")\n</pre> pb.set_option(\"datafusion.execution.target_partitions\", \"1\") In\u00a0[59]: Copied! <pre>%%time\npb.scan_fastq(\"/tmp/ERR194146.fastq.bgz\", parallel=True).count().collect()\n</pre> %%time pb.scan_fastq(\"/tmp/ERR194146.fastq.bgz\", parallel=True).count().collect() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 3.71 s, sys: 242 ms, total: 3.95 s\nWall time: 3.77 s\n</pre> Out[59]: shape: (1, 4)namedescriptionsequencequality_scoresu32u32u32u328657652865765286576528657652 In\u00a0[53]: Copied! <pre>pb.set_option(\"datafusion.execution.target_partitions\", \"2\")\n</pre> pb.set_option(\"datafusion.execution.target_partitions\", \"2\") In\u00a0[55]: Copied! <pre>%%time\npb.scan_fastq(\"/tmp/ERR194146.fastq.bgz\", parallel=True).count().collect()\n</pre> %%time pb.scan_fastq(\"/tmp/ERR194146.fastq.bgz\", parallel=True).count().collect() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 3.83 s, sys: 344 ms, total: 4.17 s\nWall time: 2.03 s\n</pre> Out[55]: shape: (1, 4)namedescriptionsequencequality_scoresu32u32u32u328657652865765286576528657652 In\u00a0[60]: Copied! <pre>pb.set_option(\"datafusion.execution.target_partitions\", \"4\")\n</pre> pb.set_option(\"datafusion.execution.target_partitions\", \"4\") In\u00a0[61]: Copied! <pre>%%time\npb.scan_fastq(\"/tmp/ERR194146.fastq.bgz\", parallel=True).count().collect()\n</pre> %%time pb.scan_fastq(\"/tmp/ERR194146.fastq.bgz\", parallel=True).count().collect() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 3.86 s, sys: 397 ms, total: 4.26 s\nWall time: 1.23 s\n</pre> Out[61]: shape: (1, 4)namedescriptionsequencequality_scoresu32u32u32u328657652865765286576528657652 In\u00a0[62]: Copied! <pre>pb.set_option(\"datafusion.execution.target_partitions\", \"1\")\n</pre> pb.set_option(\"datafusion.execution.target_partitions\", \"1\") <p>Make sure you restart the kernel before running the next cells. memory-profiler is required.</p> In\u00a0[3]: Copied! <pre>%load_ext memory_profiler\n</pre> %load_ext memory_profiler In\u00a0[4]: Copied! <pre>%memit pb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).sink_parquet(\"/tmp/overlap.parquet\")\n</pre> %memit pb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).sink_parquet(\"/tmp/overlap.parquet\") <pre>0rows [00:00, ?rows/s]</pre> <pre>peak memory: 1399.36 MiB, increment: 1186.92 MiB\n</pre> In\u00a0[65]: Copied! <pre>%memit pb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).collect().write_parquet(\"/tmp/overlap.parquet\")\n</pre> %memit pb.overlap(\"data/ex-rna/*.parquet\", \"data/chainRn4/*.parquet\",  cols1=cols, cols2=cols).collect().write_parquet(\"/tmp/overlap.parquet\")  <pre>0rows [00:00, ?rows/s]</pre> <pre>peak memory: 17261.36 MiB, increment: 4621.69 MiB\n</pre> In\u00a0[5]: Copied! <pre>BIO_PD_DF1 = pd.read_parquet(f\"data/exons/\")\nBIO_PD_DF2 = pd.read_parquet(f\"data/fBrain-DS14718/\")\n</pre> BIO_PD_DF1 = pd.read_parquet(f\"data/exons/\") BIO_PD_DF2 = pd.read_parquet(f\"data/fBrain-DS14718/\") In\u00a0[6]: Copied! <pre>bf_overlap = bf.overlap(\n    BIO_PD_DF1,\n    BIO_PD_DF2,\n    cols1=cols,\n    cols2=cols,\n    suffixes=(\"_1\", \"_2\"),\n    how=\"inner\",\n)\n</pre> bf_overlap = bf.overlap(     BIO_PD_DF1,     BIO_PD_DF2,     cols1=cols,     cols2=cols,     suffixes=(\"_1\", \"_2\"),     how=\"inner\", ) In\u00a0[7]: Copied! <pre>pb_overlap = pb.overlap(\n    BIO_PD_DF1,\n    BIO_PD_DF2,\n    cols1=cols,\n    cols2=cols,\n    output_type=\"pandas.DataFrame\",\n    suffixes=(\"_1\", \"_2\"),\n)\n</pre> pb_overlap = pb.overlap(     BIO_PD_DF1,     BIO_PD_DF2,     cols1=cols,     cols2=cols,     output_type=\"pandas.DataFrame\",     suffixes=(\"_1\", \"_2\"), ) <p>Since polars-bio is one-based, the assertion will fail.</p> In\u00a0[8]: Copied! <pre>assert len(bf_overlap) == len(pb_overlap)\n</pre> assert len(bf_overlap) == len(pb_overlap) <pre>---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 assert len(bf_overlap) == len(pb_overlap)\n\nAssertionError: </pre> <p>To use polars-bio with zero-based coordinates, set <code>use_zero_based=True</code>:</p> In\u00a0[9]: Copied! <pre>pb_overlap = pb.overlap(\n    BIO_PD_DF1,\n    BIO_PD_DF2,\n    cols1=cols,\n    cols2=cols,\n    output_type=\"pandas.DataFrame\",\n    suffixes=(\"_1\", \"_2\"),\n    use_zero_based=True,\n)\n</pre> pb_overlap = pb.overlap(     BIO_PD_DF1,     BIO_PD_DF2,     cols1=cols,     cols2=cols,     output_type=\"pandas.DataFrame\",     suffixes=(\"_1\", \"_2\"),     use_zero_based=True, ) <pre>WARNING:polars_bio:0-based coordinate system was selected. Please ensure that both datasets follow this coordinate system.\n</pre> In\u00a0[10]: Copied! <pre>assert len(bf_overlap) == len(pb_overlap)\n</pre> assert len(bf_overlap) == len(pb_overlap) In\u00a0[11]: Copied! <pre>import polars_bio as pb\nimport polars as pl\n</pre> import polars_bio as pb import polars as pl In\u00a0[12]: Copied! <pre>gcs_vcf_path = (\n    \"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\"\n)\n</pre> gcs_vcf_path = (     \"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\" ) In\u00a0[15]: Copied! <pre># we need to override the compression type as the file is bgzipped not gzipped as the extension suggests\npb.scan_vcf(gcs_vcf_path, info_fields=[]).limit(3).collect()\n</pre> # we need to override the compression type as the file is bgzipped not gzipped as the extension suggests pb.scan_vcf(gcs_vcf_path, info_fields=[]).limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[15]: shape: (3, 8)chromstartendidrefaltqualfilterstru32u32strstrstrf64str\"chr1\"10000295666\"gnomAD-SV_v3_DUP_chr1_01c2781c\"\"N\"\"&lt;DUP&gt;\"134.0\"HIGH_NCR\"\"chr1\"1043410434\"gnomAD-SV_v3_BND_chr1_1a45f73a\"\"N\"\"&lt;BND&gt;\"260.0\"HIGH_NCR;UNRESOLVED\"\"chr1\"1044010440\"gnomAD-SV_v3_BND_chr1_3fa36917\"\"N\"\"&lt;BND&gt;\"198.0\"HIGH_NCR;UNRESOLVED\" In\u00a0[16]: Copied! <pre>pb.describe_vcf(gcs_vcf_path).sort(\"name\").limit(5)\n</pre> pb.describe_vcf(gcs_vcf_path).sort(\"name\").limit(5) Out[16]: shape: (5, 3)nametypedescriptionstrstrstr\"AC\"\"Integer\"\"Number of non-reference allele\u2026\"AC_XX\"\"Integer\"\"Number of non-reference XX all\u2026\"AC_XY\"\"Integer\"\"Number of non-reference XY all\u2026\"AC_afr\"\"Integer\"\"Number of non-reference Africa\u2026\"AC_afr_XX\"\"Integer\"\"Number of non-reference Africa\u2026 In\u00a0[17]: Copied! <pre># here we can use automatic compression detection\naws_s3_vcf_path = \"s3://gnomad-public-us-east-1/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\"\n</pre> # here we can use automatic compression detection aws_s3_vcf_path = \"s3://gnomad-public-us-east-1/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\" In\u00a0[18]: Copied! <pre>pb.scan_vcf(aws_s3_vcf_path, chunk_size=8, concurrent_fetches=1, info_fields=[]).limit(3).collect()\n</pre> pb.scan_vcf(aws_s3_vcf_path, chunk_size=8, concurrent_fetches=1, info_fields=[]).limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[18]: shape: (3, 8)chromstartendidrefaltqualfilterstru32u32strstrstrf64str\"chr21\"50319055031905\"\"\"C\"\"A\"null\"AC0;AS_VQSR\"\"chr21\"50319055031905\"\"\"C\"\"T\"null\"AC0;AS_VQSR\"\"chr21\"50319095031909\"\"\"T\"\"C\"null\"AC0;AS_VQSR\" In\u00a0[19]: Copied! <pre>vcf_info_fields = [\"SVTYPE\", \"SVLEN\"]\npb.scan_vcf(gcs_vcf_path, info_fields=vcf_info_fields).limit(3).collect()\n</pre> vcf_info_fields = [\"SVTYPE\", \"SVLEN\"] pb.scan_vcf(gcs_vcf_path, info_fields=vcf_info_fields).limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[19]: shape: (3, 10)chromstartendidrefaltqualfiltersvtypesvlenstru32u32strstrstrf64strstri32\"chr1\"10000295666\"gnomAD-SV_v3_DUP_chr1_01c2781c\"\"N\"\"&lt;DUP&gt;\"134.0\"HIGH_NCR\"\"DUP\"285666\"chr1\"1043410434\"gnomAD-SV_v3_BND_chr1_1a45f73a\"\"N\"\"&lt;BND&gt;\"260.0\"HIGH_NCR;UNRESOLVED\"\"BND\"-1\"chr1\"1044010440\"gnomAD-SV_v3_BND_chr1_3fa36917\"\"N\"\"&lt;BND&gt;\"198.0\"HIGH_NCR;UNRESOLVED\"\"BND\"-1 In\u00a0[20]: Copied! <pre>! gsutil -m  cp  $gcs_vcf_path /tmp/gnomad.v4.1.sv.sites.vcf.gz &amp;&gt; /dev/null\n</pre> ! gsutil -m  cp  $gcs_vcf_path /tmp/gnomad.v4.1.sv.sites.vcf.gz &amp;&gt; /dev/null In\u00a0[22]: Copied! <pre>%%time\npb.scan_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", thread_num=1, info_fields=[]).count().collect()\n</pre> %%time pb.scan_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", thread_num=1, info_fields=[]).count().collect() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 11.8 s, sys: 2.07 s, total: 13.8 s\nWall time: 9.99 s\n</pre> Out[22]: shape: (1, 8)chromstartendidrefaltqualfilteru32u32u32u32u32u32u32u3221544862154486215448621544862154486215448621536972154486 In\u00a0[23]: Copied! <pre>%%time\npb.scan_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", thread_num=4,info_fields=[]).count().collect()\n</pre> %%time pb.scan_vcf(\"/tmp/gnomad.v4.1.sv.sites.vcf.gz\", thread_num=4,info_fields=[]).count().collect() <pre>0rows [00:00, ?rows/s]</pre> <pre>CPU times: user 11.4 s, sys: 1.63 s, total: 13 s\nWall time: 3.09 s\n</pre> Out[23]: shape: (1, 8)chromstartendidrefaltqualfilteru32u32u32u32u32u32u32u3221544862154486215448621544862154486215448621536972154486 In\u00a0[24]: Copied! <pre>vcf_1 = \"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\"\nvcf_2 = \"gs://gcp-public-data--gnomad/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\"\n</pre> vcf_1 = \"gs://gcp-public-data--gnomad/release/4.1/genome_sv/gnomad.v4.1.sv.sites.vcf.gz\" vcf_2 = \"gs://gcp-public-data--gnomad/release/4.1/vcf/exomes/gnomad.exomes.v4.1.sites.chr21.vcf.bgz\" In\u00a0[25]: Copied! <pre>object_storage_options = pb.ObjectStorageOptions(\n    allow_anonymous=True,\n    enable_request_payer=False,\n    chunk_size=64,\n    concurrent_fetches=8,\n    max_retries=5,\n    timeout=10,\n    compression_type=\"bgz\",\n)\nvcf_read_options_1 = pb.VcfReadOptions(\n    info_fields=[\"SVTYPE\", \"SVLEN\"],\n    thread_num=1,\n    object_storage_options=object_storage_options,\n)\nvcf_read_options_2 = pb.VcfReadOptions(\n    object_storage_options=object_storage_options,\n)\nread_options_1 = pb.ReadOptions(vcf_read_options=vcf_read_options_1)\nread_options_2 = pb.ReadOptions(vcf_read_options=vcf_read_options_2)\n</pre> object_storage_options = pb.ObjectStorageOptions(     allow_anonymous=True,     enable_request_payer=False,     chunk_size=64,     concurrent_fetches=8,     max_retries=5,     timeout=10,     compression_type=\"bgz\", ) vcf_read_options_1 = pb.VcfReadOptions(     info_fields=[\"SVTYPE\", \"SVLEN\"],     thread_num=1,     object_storage_options=object_storage_options, ) vcf_read_options_2 = pb.VcfReadOptions(     object_storage_options=object_storage_options, ) read_options_1 = pb.ReadOptions(vcf_read_options=vcf_read_options_1) read_options_2 = pb.ReadOptions(vcf_read_options=vcf_read_options_2)  In\u00a0[26]: Copied! <pre>pb.overlap(vcf_1, vcf_2, read_options1=read_options_1, read_options2=read_options_2).sink_csv(\n    \"/tmp/streaming_run.csv\"\n)\n</pre> pb.overlap(vcf_1, vcf_2, read_options1=read_options_1, read_options2=read_options_2).sink_csv(     \"/tmp/streaming_run.csv\" ) <pre>0rows [00:00, ?rows/s]</pre> In\u00a0[27]: Copied! <pre>pl.read_csv(\"/tmp/streaming_run.csv\").limit(3)\n</pre> pl.read_csv(\"/tmp/streaming_run.csv\").limit(3) Out[27]: shape: (3, 18)chrom_1start_1end_1id_1ref_1alt_1qual_1filter_1svtype_1svlen_1chrom_2start_2end_2id_2ref_2alt_2qual_2filter_2stri64i64stri64i64strstrstrstrstrstrstrstrf64strstri64\"chr21\"50191505047500\"chr21\"50361835036183\"\"\"A\"\"C\"null\"AC0;AS_VQSR\"\"gnomAD-SV_v3_DUP_chr21_029eb66\u2026\"N\"\"&lt;DUP&gt;\"34.0\"PASS\"\"DUP\"28350\"chr21\"50191505047500\"chr21\"50361845036184\"\"\"G\"\"A\"null\"AS_VQSR\"\"gnomAD-SV_v3_DUP_chr21_029eb66\u2026\"N\"\"&lt;DUP&gt;\"34.0\"PASS\"\"DUP\"28350\"chr21\"50191505047500\"chr21\"50361855036185\"\"\"G\"\"A\"null\"AS_VQSR\"\"gnomAD-SV_v3_DUP_chr21_029eb66\u2026\"N\"\"&lt;DUP&gt;\"34.0\"PASS\"\"DUP\"28350 In\u00a0[28]: Copied! <pre>pb.overlap(vcf_1, vcf_2, read_options1=read_options_1, read_options2=read_options_2).collect().count()\n</pre> pb.overlap(vcf_1, vcf_2, read_options1=read_options_1, read_options2=read_options_2).collect().count() <pre>0rows [00:00, ?rows/s]</pre> Out[28]: shape: (1, 18)chrom_1start_1end_1chrom_2start_2end_2id_1ref_1alt_1qual_1filter_1id_2ref_2alt_2qual_2filter_2svtype_2svlen_2u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u3217882545178825451788254517882545178825451788254517882545178825451788254501788254517882545178825451788254517793674178825451788254517882545 In\u00a0[29]: Copied! <pre>gcs_vcf_path = \"gs://genomics-public-data/platinum-genomes/vcf/NA12878_S1.genome.vcf\"\n</pre> gcs_vcf_path = \"gs://genomics-public-data/platinum-genomes/vcf/NA12878_S1.genome.vcf\" In\u00a0[30]: Copied! <pre>info_fields=[\"AC\", \"AF\"]\n</pre> info_fields=[\"AC\", \"AF\"] In\u00a0[31]: Copied! <pre>pb.scan_vcf(gcs_vcf_path, info_fields=info_fields).limit(3).collect()\n</pre> pb.scan_vcf(gcs_vcf_path, info_fields=info_fields).limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[31]: shape: (3, 10)chromstartendidrefaltqualfilteracafstru32u32strstrstrf64strlist[i32]list[f32]\"chrM\"11\"\"\"G\"\"\"null\"PASS\"nullnull\"chrM\"272\"\"\"A\"\"\"null\"PASS\"nullnull\"chrM\"7373\"\"\"G\"\"A\"8752.780273\"TruthSensitivityTranche99.90to\u2026[2][1.0] <p>Check SQL reference for details.</p> In\u00a0[32]: Copied! <pre>pb.register_vcf(vcf_1, \"gnomad_sv\", thread_num=1, info_fields=[\"SVTYPE\", \"SVLEN\"])\n</pre> pb.register_vcf(vcf_1, \"gnomad_sv\", thread_num=1, info_fields=[\"SVTYPE\", \"SVLEN\"]) In\u00a0[33]: Copied! <pre>pb.sql(\"SELECT chrom, svtype  FROM gnomad_sv\").limit(3).collect()\n</pre> pb.sql(\"SELECT chrom, svtype  FROM gnomad_sv\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[33]: shape: (3, 2)chromsvtypestrstr\"chr1\"\"DUP\"\"chr1\"\"BND\"\"chr1\"\"BND\" In\u00a0[34]: Copied! <pre>pb.sql(\"SELECT * FROM gnomad_sv WHERE SVTYPE = 'DEL' AND SVLEN &gt; 1000\").limit(3).collect()\n</pre> pb.sql(\"SELECT * FROM gnomad_sv WHERE SVTYPE = 'DEL' AND SVLEN &gt; 1000\").limit(3).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[34]: shape: (3, 10)chromstartendidrefaltqualfiltersvtypesvlenstru32u32strstrstrf64strstri32\"chr1\"2200030000\"gnomAD-SV_v3_DEL_chr1_fa103016\"\"N\"\"&lt;DEL&gt;\"999.0\"HIGH_NCR\"\"DEL\"8000\"chr1\"4000047000\"gnomAD-SV_v3_DEL_chr1_b26f63f7\"\"N\"\"&lt;DEL&gt;\"145.0\"PASS\"\"DEL\"7000\"chr1\"7908688118\"gnomAD-SV_v3_DEL_chr1_733c4ef0\"\"N\"\"&lt;DEL:ME:LINE1&gt;\"344.0\"UNRESOLVED\"\"DEL\"9032 In\u00a0[35]: Copied! <pre>pb.sql(\"SELECT alt, count(*) as cnt FROM gnomad_sv group by alt\").collect_schema()\n</pre> pb.sql(\"SELECT alt, count(*) as cnt FROM gnomad_sv group by alt\").collect_schema() Out[35]: <pre>Schema([('alt', String), ('cnt', Int64)])</pre> In\u00a0[36]: Copied! <pre>pb.sql(\"SELECT alt, count(*) as cnt FROM gnomad_sv group by alt\").collect()\n</pre> pb.sql(\"SELECT alt, count(*) as cnt FROM gnomad_sv group by alt\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[36]: shape: (13, 2)altcntstri64\"&lt;DUP&gt;\"269326\"&lt;BND&gt;\"356035\"&lt;CNV&gt;\"721\"&lt;DEL&gt;\"1197080\"&lt;INS&gt;\"83441\u2026\u2026\"&lt;INS:ME:SVA&gt;\"17607\"&lt;CPX&gt;\"15189\"&lt;INV&gt;\"2193\"&lt;DEL:ME:HERVK&gt;\"693\"&lt;CTX&gt;\"99 In\u00a0[37]: Copied! <pre>pb.sql(\"SELECT chrom, count(*) as cnt FROM gnomad_sv GROUP BY chrom ORDER BY chrom\").collect()\n</pre> pb.sql(\"SELECT chrom, count(*) as cnt FROM gnomad_sv GROUP BY chrom ORDER BY chrom\").collect() <pre>0rows [00:00, ?rows/s]</pre> Out[37]: shape: (24, 2)chromcntstri64\"chr1\"182804\"chr10\"96755\"chr11\"95690\"chr12\"97655\"chr13\"63839\u2026\u2026\"chr7\"131866\"chr8\"101224\"chr9\"87748\"chrX\"78076\"chrY\"12488 In\u00a0[38]: Copied! <pre>pb.sql(\"SELECT * FROM gnomad_sv WHERE chrom='chr1'\").sink_csv(\"/tmp/gnomad_chr1.csv\")\n</pre> pb.sql(\"SELECT * FROM gnomad_sv WHERE chrom='chr1'\").sink_csv(\"/tmp/gnomad_chr1.csv\") <pre>0rows [00:00, ?rows/s]</pre> In\u00a0[39]: Copied! <pre>pl.read_csv(\"/tmp/gnomad_chr1.csv\").count()\n</pre> pl.read_csv(\"/tmp/gnomad_chr1.csv\").count() Out[39]: shape: (1, 10)chromstartendidrefaltqualfiltersvtypesvlenu32u32u32u32u32u32u32u32u32u32182804182804182804182804182804182804182765182804182804182804 In\u00a0[40]: Copied! <pre>pb.register_vcf(vcf_2, \"gnomad_exomes\", info_fields=[\"AC\", \"AF\"])\n</pre> pb.register_vcf(vcf_2, \"gnomad_exomes\", info_fields=[\"AC\", \"AF\"]) In\u00a0[41]: Copied! <pre>pb.sql(\"SELECT replace(chrom,'chr','') AS chrom, start, ac,af  FROM gnomad_exomes WHERE array_element(af,1)&gt;0.01\").limit(10).collect()\n</pre> pb.sql(\"SELECT replace(chrom,'chr','') AS chrom, start, ac,af  FROM gnomad_exomes WHERE array_element(af,1)&gt;0.01\").limit(10).collect() <pre>0rows [00:00, ?rows/s]</pre> Out[41]: shape: (10, 4)chromstartacafstru32list[i32]list[f32]\"21\"5033364[372992][0.337086]\"21\"5033539[1107064][0.996312]\"21\"5034629[15145][0.020082]\"21\"5035021[1811][0.307888]\"21\"5035108[2][0.010989]\"21\"5035658[255555][0.336447]\"21\"5035846[37233][0.286906]\"21\"5035921[1682][0.010757]\"21\"5116593[4032][0.018626]\"21\"5116760[101][0.014914] In\u00a0[42]: Copied! <pre>pb.overlap(\"gnomad_sv\", \"gnomad_exomes\").collect().count()\n</pre> pb.overlap(\"gnomad_sv\", \"gnomad_exomes\").collect().count() <pre>0rows [00:00, ?rows/s]</pre> Out[42]: shape: (1, 20)chrom_1start_1end_1chrom_2start_2end_2id_1ref_1alt_1qual_1filter_1ac_1af_1id_2ref_2alt_2qual_2filter_2svtype_2svlen_2u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32u32178825451788254517882545178825451788254517882545178825451788254517882545017882545178825451758750317882545178825451788254517793674178825451788254517882545"},{"location":"notebooks/tutorial/#introduction-to-polars-bio-features","title":"Introduction to polars-bio features\u00b6","text":""},{"location":"notebooks/tutorial/#interval-operations-illustrated","title":"Interval operations illustrated\u00b6","text":"<p>Please note that for visualizaiton of the intervals we used plot_intervals method from Bioframe package.</p>"},{"location":"notebooks/tutorial/#overlap","title":"Overlap\u00b6","text":""},{"location":"notebooks/tutorial/#nearest","title":"Nearest\u00b6","text":""},{"location":"notebooks/tutorial/#count-overlaps","title":"Count overlaps\u00b6","text":""},{"location":"notebooks/tutorial/#coverage","title":"Coverage\u00b6","text":""},{"location":"notebooks/tutorial/#merge","title":"Merge\u00b6","text":""},{"location":"notebooks/tutorial/#reading-bioinformatics-data","title":"Reading bioinformatics data\u00b6","text":""},{"location":"notebooks/tutorial/#gff","title":"GFF\u00b6","text":""},{"location":"notebooks/tutorial/#basic-reading-with-attributes-unnesting","title":"Basic reading with attributes unnesting\u00b6","text":""},{"location":"notebooks/tutorial/#unnesting-attributes","title":"Unnesting attributes\u00b6","text":""},{"location":"notebooks/tutorial/#vcf","title":"VCF\u00b6","text":""},{"location":"notebooks/tutorial/#get-info-fields-available-in-the-vcf-file","title":"Get info fields available in the VCF file\u00b6","text":""},{"location":"notebooks/tutorial/#fastq","title":"FASTQ\u00b6","text":""},{"location":"notebooks/tutorial/#bam","title":"BAM\u00b6","text":""},{"location":"notebooks/tutorial/#bed","title":"BED\u00b6","text":""},{"location":"notebooks/tutorial/#sql-processing","title":"SQL processing\u00b6","text":""},{"location":"notebooks/tutorial/#registering-tables","title":"Registering tables\u00b6","text":""},{"location":"notebooks/tutorial/#querying-registered-tables","title":"Querying registered tables\u00b6","text":""},{"location":"notebooks/tutorial/#registering-views","title":"Registering views\u00b6","text":""},{"location":"notebooks/tutorial/#working-with-cloud-storage","title":"Working with cloud storage\u00b6","text":""},{"location":"notebooks/tutorial/#overlapping-with-a-local-dataframe","title":"Overlapping with a local dataframe\u00b6","text":""},{"location":"notebooks/tutorial/#parallel-processing","title":"Parallel processing\u00b6","text":""},{"location":"notebooks/tutorial/#parallel-reading-of-bgzf-compressed-fastq-files","title":"Parallel reading of BGZF compressed FASTQ files\u00b6","text":""},{"location":"notebooks/tutorial/#streaming","title":"Streaming\u00b6","text":""},{"location":"notebooks/tutorial/#overlap-in-the-streaming-mode","title":"Overlap in the streaming mode\u00b6","text":""},{"location":"notebooks/tutorial/#overlap-with-materialization","title":"Overlap with materialization\u00b6","text":""},{"location":"notebooks/tutorial/#working-with-zero-based-coordinates","title":"Working with zero-based coordinates\u00b6","text":""},{"location":"notebooks/tutorial/#compatibility-with-zero-based-coordinates-software-for-example-bioframe","title":"Compatibility with zero-based coordinates software, for example bioframe.\u00b6","text":""},{"location":"notebooks/tutorial/#example-gnomad-vcf-file-reading","title":"Example - gnomAD VCF file reading\u00b6","text":""},{"location":"notebooks/tutorial/#1-how-to-read-gnomad-vcf-files-from-google-cloud-storage-or-aws-s3","title":"1. How to read gnomAD VCF files from Google Cloud Storage or AWS S3\u00b6","text":""},{"location":"notebooks/tutorial/#google-cloud-storage","title":"Google Cloud Storage\u00b6","text":""},{"location":"notebooks/tutorial/#aws-s3","title":"AWS S3\u00b6","text":""},{"location":"notebooks/tutorial/#2-how-to-specify-additional-vcf-info-fields-to-be-parsed","title":"2. How to specify additional VCF INFO fields to be parsed\u00b6","text":""},{"location":"notebooks/tutorial/#3-how-to-speed-up-reading-local-compresed-vcf-files-with-multiple-threads","title":"3. How to speed up reading local compresed VCF files with multiple threads\u00b6","text":""},{"location":"notebooks/tutorial/#4-how-to-perform-an-overlap-operation-on-two-remote-vcf-files-in-streaming-mode","title":"4. How to perform an overlap operation on two remote VCF files in streaming mode\u00b6","text":""},{"location":"notebooks/tutorial/#5-how-to-read-a-vcf-from-google-life-sciences","title":"5. How to read a VCF from Google Life Sciences\u00b6","text":""},{"location":"notebooks/tutorial/#6-sql-data-processing","title":"6. SQL data processing\u00b6","text":""},{"location":"notebooks/tutorial/","title":"\u00b6","text":""},{"location":"blog/category/performance/","title":"performance","text":""},{"location":"blog/category/performance/#performance","title":"performance","text":""},{"location":"blog/category/benchmarks/","title":"benchmarks","text":""},{"location":"blog/category/benchmarks/#benchmarks","title":"benchmarks","text":""},{"location":"blog/category/file-formats/","title":"file formats","text":""},{"location":"blog/category/file-formats/#file-formats","title":"file formats","text":""}]}